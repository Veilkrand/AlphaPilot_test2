{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scene Understanding using Deep Learning\n",
    "## Introduction\n",
    "\n",
    "This Notebook was written for demonstrating scene understanding for the Lockheed Martin drone challange. The code consists of three pipelines pre-processing, FCN and post processing  The project is a corner stone for  \n",
    "\n",
    "\\<img style=\"float: center;\" src=\"readme_imgs/Img_groundtruth.png\">\n",
    "\n",
    "## Data Pre-processing \n",
    "\n",
    "We have implemented camera calibration routine to the video file.Each image was normalized and then smoothed with a Gaussian filter. The images were randomly processed with a brightness filter to help the network generalize to different lighting conditions. \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## FCN\n",
    "\n",
    " \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "##  Jaccard similarity coefficient \n",
    "\n",
    "In evaluating the model I've investigated several metrics including the Mean IU, Intersection over Union, and the Jaccard coefficient. The idea is to maximize the overlap between the predicted region and the ground truth bounding box.\n",
    " \n",
    "We eventually decided to use the Jaccard coeef. The Jaccard similarity coefficient is defined as the size of the intersection divided by the size of the union of two regions. This metric is used to compare the predicted labels to a set of labels in y_true  \n",
    "\n",
    "The coefficients are given by \n",
    "\n",
    "#### J(A,B) = |A∩B| / |A∪B|=|A∩B|/|A|+|B|-|A∩B| \n",
    "\n",
    "(If A and B are both empty, we define J(A,B) = 1.)\n",
    "\n",
    "<img style=\"float: center;\" src=\"readme_imgs/Intersection_of_sets_A_and_B.png\">\n",
    "<img style=\"float: center;\" src=\"readme_imgs/Intersection_of_sets_A_and_B_2.png\">\n",
    " \n",
    "\n",
    "## Training\n",
    "\n",
    "The Autti dataset was used and can be obtained from https://github.com/udacity/self-driving-car/tree/master/annotations .  \n",
    "\n",
    "## Results\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "import pandas as pd\n",
    "#import keras.backend as K\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    " \n",
    "import time\n",
    "import numpy\n",
    "from PIL import Image, ImageDraw\n",
    "import re\n",
    "from shapely.geometry import Polygon\n",
    "from pprint import pprint\n",
    "import PIL.ImageDraw\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "#add a note for the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and processing the wkt json format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>img_path</th>\n",
       "      <th>raw_inner_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_5677.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[532, 354, 772, 357, 768, 594, 533, 592]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_7088 (1).JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[451, 226, 831, 247, 836, 623, 437, 622]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_0260.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[480, 373, 698, 374, 698, 599, 471, 594]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_4609.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[495, 309, 668, 285, 672, 554, 499, 533]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_2994.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[490, 190, 637, 345, 644, 686, 475, 679]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             images                                           img_path  \\\n",
       "0      IMG_5677.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  IMG_7088 (1).JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2      IMG_0260.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3      IMG_4609.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4      IMG_2994.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                             raw_inner_poly  \n",
       "0  [532, 354, 772, 357, 768, 594, 533, 592]  \n",
       "1  [451, 226, 831, 247, 836, 623, 437, 622]  \n",
       "2  [480, 373, 698, 374, 698, 599, 471, 594]  \n",
       "3  [495, 309, 668, 285, 672, 554, 499, 533]  \n",
       "4  [490, 190, 637, 345, 644, 686, 475, 679]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df is the dataset that we are annotating\n",
    "#raw_df is the dataset that the organizers provided\n",
    "#adding path for json anf image folders respectively\n",
    "provided_data_file_dir='/media/a/D/lockheed-martin/dataset/LM_dataset/csv/training_GT_labels_v2.json'#json provided by the organizers of the challange\n",
    "our_data_file_dir='/media/a/D/lockheed-martin/dataset/LM_dataset/csv/data_wkt_v3.json'#our annotated dataset\n",
    "img_file_dir='/media/a/D/lockheed-martin/dataset/LM_dataset/Data_Training/'#folder where images are stored\n",
    "provided_df = pd.read_json(provided_data_file_dir)\n",
    "df = pd.read_json(our_data_file_dir)\n",
    "\n",
    " \n",
    "#adding a complete path for the image \n",
    "df['External ID']= [img_file_dir + u for u in df['External ID']]#iris_data_dir + new_df['parcel_id'].astype(str) + '.jpg'\n",
    "\n",
    "df['images']=[u.split('/',8)[8] for u in df['External ID']]\n",
    "raw_df=pd.DataFrame()\n",
    "raw_df['images']=list(provided_df.columns.values)\n",
    "raw_df['img_path']=[img_file_dir +  u for u in raw_df['images']]\n",
    "\n",
    "raw_df['raw_inner_poly']=[ provided_df[u][0] for u in raw_df['images']]\n",
    "\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_4609.JPG\n"
     ]
    }
   ],
   "source": [
    "#remove white spaces from image path\n",
    "s=raw_df['images'][3]\n",
    "print(re.sub(r\"\\s+\", \"\", s))  # \\s matches all white spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#remove white space from image name in the folder containing the images\n",
    "\n",
    "#go to img directory and run python fix.py. Here is the file\n",
    "\n",
    "#remove white space from image name in the folder containing the images\n",
    "import os\n",
    "import re\n",
    "\n",
    "\"\"\" \n",
    "Renames the filenames within the same directory to be Unix friendly\n",
    "(1) Changes spaces to nothing\n",
    "(2) Makes lowercase (not a Unix requirement, just looks better ;)\n",
    "Usage:\n",
    "python rename.py\n",
    "\"\"\"\n",
    "path =  os.getcwd()\n",
    " \n",
    "filenames = os.listdir(path)\n",
    "\n",
    "for filename in filenames:\n",
    "    print('img name befor',filename)\n",
    "    fixed_filename=re.sub(r\"\\s+\", \"\", filename)\n",
    "    print('img name after',fixed_filename)\n",
    "    os.rename(filename, fixed_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agreement</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Created By</th>\n",
       "      <th>DataRow ID</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>External ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Labeled Data</th>\n",
       "      <th>Project Name</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Seconds to Label</th>\n",
       "      <th>View Label</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:35:37.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5r9p7w0anvd23j1pgg</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxucjqqkbd0b47j8vcjsua</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((997 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.832</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0015.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:36:22.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p800anv2xkrhfkw</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxvb54qkw90b47dwa8uupg</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((894 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>44.299</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0158.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:36:55.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p840anv7ly4rt5s</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxw0feqs9n08984nfshogi</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((848 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>31.955</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0244.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:17:15.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p880anvyjs4m1oj</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzrm18i8ga08983qewu7rq</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((597 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.032</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0367.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:18:01.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8c0anvcve1d63y</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzslxpi69j0b4753lkl3ju</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((359 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>46.003</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0374.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Agreement                Created At               Created By  \\\n",
       "0        NaN  2019-02-06T08:35:37.000Z  alberto.galet@gmail.com   \n",
       "1        NaN  2019-02-06T08:36:22.000Z  alberto.galet@gmail.com   \n",
       "2        NaN  2019-02-06T08:36:55.000Z  alberto.galet@gmail.com   \n",
       "3        NaN  2019-02-07T02:17:15.000Z  alberto.galet@gmail.com   \n",
       "4        NaN  2019-02-07T02:18:01.000Z  alberto.galet@gmail.com   \n",
       "\n",
       "                  DataRow ID         Dataset Name  \\\n",
       "0  cjrsurb5r9p7w0anvd23j1pgg  Test2 AlphaPilot #2   \n",
       "1  cjrsurb5v9p800anv2xkrhfkw  Test2 AlphaPilot #2   \n",
       "2  cjrsurb5v9p840anv7ly4rt5s  Test2 AlphaPilot #2   \n",
       "3  cjrsurb5v9p880anvyjs4m1oj  Test2 AlphaPilot #2   \n",
       "4  cjrsurb5v9p8c0anvcve1d63y  Test2 AlphaPilot #2   \n",
       "\n",
       "                                         External ID  \\\n",
       "0  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                          ID  \\\n",
       "0  cjrsxucjqqkbd0b47j8vcjsua   \n",
       "1  cjrsxvb54qkw90b47dwa8uupg   \n",
       "2  cjrsxw0feqs9n08984nfshogi   \n",
       "3  cjrtzrm18i8ga08983qewu7rq   \n",
       "4  cjrtzslxpi69j0b4753lkl3ju   \n",
       "\n",
       "                                               Label  \\\n",
       "0  {'Outer Border': [{'geometry': 'POLYGON ((997 ...   \n",
       "1  {'Outer Border': [{'geometry': 'POLYGON ((894 ...   \n",
       "2  {'Outer Border': [{'geometry': 'POLYGON ((848 ...   \n",
       "3  {'Outer Border': [{'geometry': 'POLYGON ((597 ...   \n",
       "4  {'Outer Border': [{'geometry': 'POLYGON ((359 ...   \n",
       "\n",
       "                                        Labeled Data      Project Name  \\\n",
       "0  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "1  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "2  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "3  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "4  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "\n",
       "  Reviews  Seconds to Label  \\\n",
       "0      []            33.832   \n",
       "1      []            44.299   \n",
       "2      []            31.955   \n",
       "3      []            39.032   \n",
       "4      []            46.003   \n",
       "\n",
       "                                          View Label        images  \n",
       "0  https://image-segmentation-v4.labelbox.com?pro...  IMG_0015.JPG  \n",
       "1  https://image-segmentation-v4.labelbox.com?pro...  IMG_0158.JPG  \n",
       "2  https://image-segmentation-v4.labelbox.com?pro...  IMG_0244.JPG  \n",
       "3  https://image-segmentation-v4.labelbox.com?pro...  IMG_0367.JPG  \n",
       "4  https://image-segmentation-v4.labelbox.com?pro...  IMG_0374.JPG  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agreement</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Created By</th>\n",
       "      <th>DataRow ID</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>External ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Labeled Data</th>\n",
       "      <th>Project Name</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Seconds to Label</th>\n",
       "      <th>View Label</th>\n",
       "      <th>images</th>\n",
       "      <th>img_path</th>\n",
       "      <th>raw_inner_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:35:37.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5r9p7w0anvd23j1pgg</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxucjqqkbd0b47j8vcjsua</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((997 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.832</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0015.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[504, 191, 902, 177, 915, 580, 495, 584]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:36:22.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p800anv2xkrhfkw</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxvb54qkw90b47dwa8uupg</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((894 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>44.299</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0158.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[454, 212, 803, 221, 808, 552, 454, 566]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:36:55.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p840anv7ly4rt5s</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxw0feqs9n08984nfshogi</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((848 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>31.955</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0244.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[590, 376, 791, 371, 794, 589, 577, 601]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:17:15.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p880anvyjs4m1oj</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzrm18i8ga08983qewu7rq</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((597 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.032</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0367.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[836, 385, 641, 387, 635, 582, 841, 582]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:18:01.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8c0anvcve1d63y</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzslxpi69j0b4753lkl3ju</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((359 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>46.003</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0374.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[470, 221, 848, 231, 851, 613, 457, 609]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:18:42.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8g0anv2ji1v57l</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzth7bi7210b47l0yydz0t</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((567 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.919</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0396.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[585, 338, 684, 354, 672, 523, 592, 532]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:19:13.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8k0anv1auzm8e0</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzu5bziasw0898zn0xuaez</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((343 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>30.653</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0861.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[378, 468, 533, 480, 537, 646, 369, 646]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:19:47.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8o0anv56veqecf</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzuvrni8r10b47jq56iqvh</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((753 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.630</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_1128.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[509, 319, 705, 255, 705, 632, 506, 616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:20:22.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8s0anvm6kjs3ge</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzvm6xibyq089861ts75g5</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((585 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.653</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_1546.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[620, 444, 756, 452, 760, 606, 623, 606]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:20:56.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8w0anvcfa1y38p</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzwcfmi9t30b47ily7qitc</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((471 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.376</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_1580.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[511, 433, 710, 438, 706, 630, 508, 632]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Agreement                Created At               Created By  \\\n",
       "0        NaN  2019-02-06T08:35:37.000Z  alberto.galet@gmail.com   \n",
       "1        NaN  2019-02-06T08:36:22.000Z  alberto.galet@gmail.com   \n",
       "2        NaN  2019-02-06T08:36:55.000Z  alberto.galet@gmail.com   \n",
       "3        NaN  2019-02-07T02:17:15.000Z  alberto.galet@gmail.com   \n",
       "4        NaN  2019-02-07T02:18:01.000Z  alberto.galet@gmail.com   \n",
       "5        NaN  2019-02-07T02:18:42.000Z  alberto.galet@gmail.com   \n",
       "6        NaN  2019-02-07T02:19:13.000Z  alberto.galet@gmail.com   \n",
       "7        NaN  2019-02-07T02:19:47.000Z  alberto.galet@gmail.com   \n",
       "8        NaN  2019-02-07T02:20:22.000Z  alberto.galet@gmail.com   \n",
       "9        NaN  2019-02-07T02:20:56.000Z  alberto.galet@gmail.com   \n",
       "\n",
       "                  DataRow ID         Dataset Name  \\\n",
       "0  cjrsurb5r9p7w0anvd23j1pgg  Test2 AlphaPilot #2   \n",
       "1  cjrsurb5v9p800anv2xkrhfkw  Test2 AlphaPilot #2   \n",
       "2  cjrsurb5v9p840anv7ly4rt5s  Test2 AlphaPilot #2   \n",
       "3  cjrsurb5v9p880anvyjs4m1oj  Test2 AlphaPilot #2   \n",
       "4  cjrsurb5v9p8c0anvcve1d63y  Test2 AlphaPilot #2   \n",
       "5  cjrsurb5v9p8g0anv2ji1v57l  Test2 AlphaPilot #2   \n",
       "6  cjrsurb5v9p8k0anv1auzm8e0  Test2 AlphaPilot #2   \n",
       "7  cjrsurb5v9p8o0anv56veqecf  Test2 AlphaPilot #2   \n",
       "8  cjrsurb5v9p8s0anvm6kjs3ge  Test2 AlphaPilot #2   \n",
       "9  cjrsurb5v9p8w0anvcfa1y38p  Test2 AlphaPilot #2   \n",
       "\n",
       "                                         External ID  \\\n",
       "0  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "5  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "6  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "7  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "8  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "9  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                          ID  \\\n",
       "0  cjrsxucjqqkbd0b47j8vcjsua   \n",
       "1  cjrsxvb54qkw90b47dwa8uupg   \n",
       "2  cjrsxw0feqs9n08984nfshogi   \n",
       "3  cjrtzrm18i8ga08983qewu7rq   \n",
       "4  cjrtzslxpi69j0b4753lkl3ju   \n",
       "5  cjrtzth7bi7210b47l0yydz0t   \n",
       "6  cjrtzu5bziasw0898zn0xuaez   \n",
       "7  cjrtzuvrni8r10b47jq56iqvh   \n",
       "8  cjrtzvm6xibyq089861ts75g5   \n",
       "9  cjrtzwcfmi9t30b47ily7qitc   \n",
       "\n",
       "                                               Label  \\\n",
       "0  {'Outer Border': [{'geometry': 'POLYGON ((997 ...   \n",
       "1  {'Outer Border': [{'geometry': 'POLYGON ((894 ...   \n",
       "2  {'Outer Border': [{'geometry': 'POLYGON ((848 ...   \n",
       "3  {'Outer Border': [{'geometry': 'POLYGON ((597 ...   \n",
       "4  {'Outer Border': [{'geometry': 'POLYGON ((359 ...   \n",
       "5  {'Outer Border': [{'geometry': 'POLYGON ((567 ...   \n",
       "6  {'Outer Border': [{'geometry': 'POLYGON ((343 ...   \n",
       "7  {'Outer Border': [{'geometry': 'POLYGON ((753 ...   \n",
       "8  {'Outer Border': [{'geometry': 'POLYGON ((585 ...   \n",
       "9  {'Outer Border': [{'geometry': 'POLYGON ((471 ...   \n",
       "\n",
       "                                        Labeled Data      Project Name  \\\n",
       "0  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "1  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "2  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "3  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "4  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "5  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "6  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "7  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "8  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "9  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "\n",
       "  Reviews  Seconds to Label  \\\n",
       "0      []            33.832   \n",
       "1      []            44.299   \n",
       "2      []            31.955   \n",
       "3      []            39.032   \n",
       "4      []            46.003   \n",
       "5      []            39.919   \n",
       "6      []            30.653   \n",
       "7      []            33.630   \n",
       "8      []            33.653   \n",
       "9      []            33.376   \n",
       "\n",
       "                                          View Label        images  \\\n",
       "0  https://image-segmentation-v4.labelbox.com?pro...  IMG_0015.JPG   \n",
       "1  https://image-segmentation-v4.labelbox.com?pro...  IMG_0158.JPG   \n",
       "2  https://image-segmentation-v4.labelbox.com?pro...  IMG_0244.JPG   \n",
       "3  https://image-segmentation-v4.labelbox.com?pro...  IMG_0367.JPG   \n",
       "4  https://image-segmentation-v4.labelbox.com?pro...  IMG_0374.JPG   \n",
       "5  https://image-segmentation-v4.labelbox.com?pro...  IMG_0396.JPG   \n",
       "6  https://image-segmentation-v4.labelbox.com?pro...  IMG_0861.JPG   \n",
       "7  https://image-segmentation-v4.labelbox.com?pro...  IMG_1128.JPG   \n",
       "8  https://image-segmentation-v4.labelbox.com?pro...  IMG_1546.JPG   \n",
       "9  https://image-segmentation-v4.labelbox.com?pro...  IMG_1580.JPG   \n",
       "\n",
       "                                            img_path  \\\n",
       "0  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "5  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "6  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "7  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "8  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "9  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                             raw_inner_poly  \n",
       "0  [504, 191, 902, 177, 915, 580, 495, 584]  \n",
       "1  [454, 212, 803, 221, 808, 552, 454, 566]  \n",
       "2  [590, 376, 791, 371, 794, 589, 577, 601]  \n",
       "3  [836, 385, 641, 387, 635, 582, 841, 582]  \n",
       "4  [470, 221, 848, 231, 851, 613, 457, 609]  \n",
       "5  [585, 338, 684, 354, 672, 523, 592, 532]  \n",
       "6  [378, 468, 533, 480, 537, 646, 369, 646]  \n",
       "7  [509, 319, 705, 255, 705, 632, 506, 616]  \n",
       "8  [620, 444, 756, 452, 760, 606, 623, 606]  \n",
       "9  [511, 433, 710, 438, 706, 630, 508, 632]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge the our annotations and provided annotations\n",
    "df_all=pd.merge(df, raw_df, on='images')\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4427\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>img_path</th>\n",
       "      <th>Label</th>\n",
       "      <th>raw_inner_poly</th>\n",
       "      <th>outer_poly</th>\n",
       "      <th>inner_poly</th>\n",
       "      <th>outer_x_min</th>\n",
       "      <th>outer_y_min</th>\n",
       "      <th>outer_x_max</th>\n",
       "      <th>outer_y_max</th>\n",
       "      <th>inner_x_min</th>\n",
       "      <th>inner_y_min</th>\n",
       "      <th>inner_x_max</th>\n",
       "      <th>inner_y_max</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_0015.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((997 ...</td>\n",
       "      <td>[504, 191, 902, 177, 915, 580, 495, 584]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_0158.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((894 ...</td>\n",
       "      <td>[454, 212, 803, 221, 808, 552, 454, 566]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_0244.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((848 ...</td>\n",
       "      <td>[590, 376, 791, 371, 794, 589, 577, 601]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_0367.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((597 ...</td>\n",
       "      <td>[836, 385, 641, 387, 635, 582, 841, 582]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_0374.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((359 ...</td>\n",
       "      <td>[470, 221, 848, 231, 851, 613, 457, 609]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         images                                           img_path  \\\n",
       "0  IMG_0015.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  IMG_0158.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  IMG_0244.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  IMG_0367.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  IMG_0374.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                                               Label  \\\n",
       "0  {'Outer Border': [{'geometry': 'POLYGON ((997 ...   \n",
       "1  {'Outer Border': [{'geometry': 'POLYGON ((894 ...   \n",
       "2  {'Outer Border': [{'geometry': 'POLYGON ((848 ...   \n",
       "3  {'Outer Border': [{'geometry': 'POLYGON ((597 ...   \n",
       "4  {'Outer Border': [{'geometry': 'POLYGON ((359 ...   \n",
       "\n",
       "                             raw_inner_poly outer_poly inner_poly outer_x_min  \\\n",
       "0  [504, 191, 902, 177, 915, 580, 495, 584]                                     \n",
       "1  [454, 212, 803, 221, 808, 552, 454, 566]                                     \n",
       "2  [590, 376, 791, 371, 794, 589, 577, 601]                                     \n",
       "3  [836, 385, 641, 387, 635, 582, 841, 582]                                     \n",
       "4  [470, 221, 848, 231, 851, 613, 457, 609]                                     \n",
       "\n",
       "  outer_y_min outer_x_max outer_y_max inner_x_min inner_y_min inner_x_max  \\\n",
       "0                                                                           \n",
       "1                                                                           \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                                           \n",
       "\n",
       "  inner_y_max class_id  \n",
       "0                       \n",
       "1                       \n",
       "2                       \n",
       "3                       \n",
       "4                       "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "keep_cols=['images', 'img_path','Label','raw_inner_poly']\n",
    "df_all=df_all[keep_cols]\n",
    "df_all['outer_poly']=''\n",
    "df_all['inner_poly']=''\n",
    "df_all['outer_x_min']=''\n",
    "df_all['outer_y_min']=''\n",
    "df_all['outer_x_max']=''\n",
    "df_all['outer_y_max']=''\n",
    "df_all['inner_x_min']=''\n",
    "df_all['inner_y_min']=''\n",
    "df_all['inner_x_max']=''\n",
    "df_all['inner_y_max']=''\n",
    "df_all['class_id']= ''\n",
    "print(len(df_all))\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_inner_poly [511, 247, 850, 271, 853, 609, 506, 616]\n",
      "poly [511, 247, 850, 271, 853, 609, 506, 616]\n",
      "raw_inner_poly [492, 400, 665, 390, 667, 596, 489, 590]\n",
      "poly [492, 400, 665, 390, 667, 596, 489, 590]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking the mask from the provided GT by the organizers\n",
    "\n",
    "\n",
    "\n",
    "#processing the polygone and creating a mask\n",
    "def get_mask_raw_data(img_shape, poly,display=False):\n",
    "    output_mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    print('poly',poly)\n",
    "\n",
    "    coords =  zip(*[iter(poly)] * 2) \n",
    "     \n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "    x = []\n",
    "    y = []\n",
    "    polygons = []\n",
    "\n",
    "    for pt in coords:\n",
    "        a = (int(pt[0]), int(pt[1]))\n",
    "        polygons.append(a)\n",
    "        init_x = (int(pt[0]))\n",
    "        init_y = (int(pt[1]))\n",
    "\n",
    "        x.append(init_x)\n",
    "        y.append(init_y)\n",
    "    proc_polygons=np.vstack((x,y)).T\n",
    "    x,y,w,h = cv2.boundingRect(proc_polygons) \n",
    "    draw.polygon(xy=polygons, outline=1, fill=1)\n",
    "    mask = np.array(mask, dtype=bool)\n",
    "    if display:\n",
    "        plt.imshow(mask)\n",
    "        plt.show\n",
    "    return mask\n",
    "for i in range(444,446):#len(df)):\n",
    "\n",
    "    img=cv2.imread(df_all['img_path'][i])\n",
    "    row=img.shape[0]\n",
    "    col=img.shape[1]\n",
    "    img_shape = (row,col)\n",
    "    #outer_poly=df['Label'][i] \n",
    "    inner_poly=df_all['raw_inner_poly'][i]\n",
    "    if inner_poly:\n",
    "        print('raw_inner_poly',inner_poly)\n",
    "    #outer_mask=get_mask(img_shape,outer_poly,display=False)\n",
    "        inner_mask=get_mask_raw_data(img_shape,inner_poly,display=False)\n",
    "        inner_mask.dtype='uint8'\n",
    "    #outer_mask.dtype='uint8'\n",
    "    #final_mask=cv2.subtract(outer_mask,inner_mask)\n",
    "        plt.imshow(cv2.bitwise_and(img,img,mask=inner_mask))\n",
    "        plt.show\n",
    "    else:\n",
    "        print('polygon data corruption detected for index:', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_id=1\n",
    "test_poly=df['Label'][test_id]['Outer Border']#df['outer_poly'][1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4427/4427 [00:03<00:00, 1226.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrupt data detected for index: 4264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#convert the polygons into a format that can be convereted to bounding boxes \n",
    "from tqdm import tqdm\n",
    "#preprocessing our_dataset\n",
    "\n",
    "def convert_coordinates(poly):\n",
    "    proc_poly=poly[0]['geometry']\n",
    "    nums =  re.findall(r'\\d+(?:\\.\\d*)?', proc_poly.rpartition(',')[0])\n",
    "    coords =  zip(*[iter(nums)] * 2)\n",
    "    polygons = []\n",
    "    for pt in coords:\n",
    "        a = (int(pt[0]), int(pt[1]))\n",
    "        polygons.append(a)\n",
    "    \n",
    "    return polygons \n",
    "def convert_coordinates_raw(polygon):\n",
    "    poly=[]\n",
    "    polygon =  zip(*[iter(polygon)] * 2)\n",
    "    for p in polygon:\n",
    "        poly.append(p)\n",
    "    return poly\n",
    "def get_bbox(polygon):\n",
    "    polygon=polygon[0]['geometry']\n",
    "    polygon=(polygon)\n",
    "\n",
    "    polygon =  re.findall(r'\\d+(?:\\.\\d*)?', polygon)\n",
    "    polygon =  zip(*[iter(polygon)] * 2)\n",
    "    x = []\n",
    "    y = []\n",
    "    for pt in polygon:\n",
    "        init_x = (int(pt[0]))\n",
    "        init_y = (int(pt[1]))\n",
    "\n",
    "        x.append(init_x)\n",
    "        y.append(init_y)\n",
    "    polygons=np.vstack((x,y)).T\n",
    "   \n",
    "    x,y,w,h = cv2.boundingRect(polygons)\n",
    "    x_min=x\n",
    "    y_min=y\n",
    "    x_max=x+w\n",
    "    y_max=y+h\n",
    "    return x_min,y_min,x_max,y_max\n",
    "    #return x_min,x_max,y_min,y_max\n",
    "def get_bbox_raw_data(polygon):\n",
    "    polygon =  zip(*[iter(polygon)] * 2)\n",
    "    x = []\n",
    "    y = []\n",
    "    for pt in polygon:\n",
    " \n",
    "        init_x = (int(pt[0]))\n",
    "        init_y = (int(pt[1]))\n",
    "\n",
    "        x.append(init_x)\n",
    "        y.append(init_y)\n",
    "    polygons=np.vstack(((x,y))).T\n",
    "    \n",
    "    x,y,w,h = cv2.boundingRect(polygons)\n",
    "    x_min=x\n",
    "    y_min=y\n",
    "    x_max=x+w\n",
    "    y_max=y+h\n",
    "    return x_min,y_min,x_max,y_max\n",
    "    #return x_min,x_max,y_min,y_max\n",
    "for i in tqdm(range(0,len(df_all))):\n",
    "    #remove white spaces from image path\n",
    "   \n",
    "    df_all['img_path'][i]=re.sub(r\"\\s+\", \"\", df_all['img_path'][i]) # \\s matches all white spaces\n",
    "    if df_all['raw_inner_poly'][i]:\n",
    "   \n",
    "        outer_poly=df_all['Label'][i]['Outer Border']\n",
    "        inner_poly=df_all['raw_inner_poly'][i]#df['Label'][i]['inner flyable area']\n",
    "        if inner_poly and outer_poly:\n",
    "            df_all['outer_poly'][i] = convert_coordinates(outer_poly)\n",
    "            df_all['inner_poly'][i] = convert_coordinates_raw(inner_poly)\n",
    "            #df['inner_poly'][i] = convert_coordinates(inner_poly)\n",
    "\n",
    "            df_all['outer_x_min'][i],df_all['outer_y_min'][i], df_all['outer_x_max'][i],df_all['outer_y_max'][i]=get_bbox(outer_poly)\n",
    "            df_all['inner_x_min'][i],df_all['inner_y_min'][i], df_all['inner_x_max'][i],df_all['inner_y_max'][i]=get_bbox_raw_data(inner_poly)\n",
    "            #df_all['outer_x_min'][i],df_all['outer_x_max'][i], df_all['outer_y_min'][i],df_all['outer_y_max'][i]=get_bbox(outer_poly)\n",
    "            #df_all['inner_x_min'][i],df_all['inner_x_max'][i], df_all['inner_y_min'][i],df_all['inner_y_max'][i]=get_bbox_raw_data(inner_poly) \n",
    "    else:\n",
    "        print('corrupt data detected for index:', i )\n",
    "        continue\n",
    "    #df['outer_poly']= h\n",
    "   #df['inner_poly']= convert_coordinates(inner_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>img_path</th>\n",
       "      <th>Label</th>\n",
       "      <th>raw_inner_poly</th>\n",
       "      <th>outer_poly</th>\n",
       "      <th>inner_poly</th>\n",
       "      <th>outer_x_min</th>\n",
       "      <th>outer_y_min</th>\n",
       "      <th>outer_x_max</th>\n",
       "      <th>outer_y_max</th>\n",
       "      <th>inner_x_min</th>\n",
       "      <th>inner_y_min</th>\n",
       "      <th>inner_x_max</th>\n",
       "      <th>inner_y_max</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_0015.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((997 ...</td>\n",
       "      <td>[504, 191, 902, 177, 915, 580, 495, 584]</td>\n",
       "      <td>[(997, 65), (1014, 683), (402, 673), (416, 106)]</td>\n",
       "      <td>[(504, 191), (902, 177), (915, 580), (495, 584)]</td>\n",
       "      <td>402</td>\n",
       "      <td>65</td>\n",
       "      <td>1015</td>\n",
       "      <td>684</td>\n",
       "      <td>495</td>\n",
       "      <td>177</td>\n",
       "      <td>916</td>\n",
       "      <td>585</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_0158.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((894 ...</td>\n",
       "      <td>[454, 212, 803, 221, 808, 552, 454, 566]</td>\n",
       "      <td>[(894, 638), (375, 646), (383, 136), (882, 141)]</td>\n",
       "      <td>[(454, 212), (803, 221), (808, 552), (454, 566)]</td>\n",
       "      <td>375</td>\n",
       "      <td>136</td>\n",
       "      <td>895</td>\n",
       "      <td>647</td>\n",
       "      <td>454</td>\n",
       "      <td>212</td>\n",
       "      <td>809</td>\n",
       "      <td>567</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_0244.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((848 ...</td>\n",
       "      <td>[590, 376, 791, 371, 794, 589, 577, 601]</td>\n",
       "      <td>[(848, 312), (851, 649), (533, 639), (538, 328)]</td>\n",
       "      <td>[(590, 376), (791, 371), (794, 589), (577, 601)]</td>\n",
       "      <td>533</td>\n",
       "      <td>312</td>\n",
       "      <td>852</td>\n",
       "      <td>650</td>\n",
       "      <td>577</td>\n",
       "      <td>371</td>\n",
       "      <td>795</td>\n",
       "      <td>602</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_0367.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((597 ...</td>\n",
       "      <td>[836, 385, 641, 387, 635, 582, 841, 582]</td>\n",
       "      <td>[(597, 623), (880, 627), (881, 344), (603, 346)]</td>\n",
       "      <td>[(836, 385), (641, 387), (635, 582), (841, 582)]</td>\n",
       "      <td>597</td>\n",
       "      <td>344</td>\n",
       "      <td>882</td>\n",
       "      <td>628</td>\n",
       "      <td>635</td>\n",
       "      <td>385</td>\n",
       "      <td>842</td>\n",
       "      <td>583</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_0374.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((359 ...</td>\n",
       "      <td>[470, 221, 848, 231, 851, 613, 457, 609]</td>\n",
       "      <td>[(359, 703), (950, 711), (943, 141), (384, 128)]</td>\n",
       "      <td>[(470, 221), (848, 231), (851, 613), (457, 609)]</td>\n",
       "      <td>359</td>\n",
       "      <td>128</td>\n",
       "      <td>951</td>\n",
       "      <td>712</td>\n",
       "      <td>457</td>\n",
       "      <td>221</td>\n",
       "      <td>852</td>\n",
       "      <td>614</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         images                                           img_path  \\\n",
       "0  IMG_0015.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  IMG_0158.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  IMG_0244.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  IMG_0367.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  IMG_0374.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                                               Label  \\\n",
       "0  {'Outer Border': [{'geometry': 'POLYGON ((997 ...   \n",
       "1  {'Outer Border': [{'geometry': 'POLYGON ((894 ...   \n",
       "2  {'Outer Border': [{'geometry': 'POLYGON ((848 ...   \n",
       "3  {'Outer Border': [{'geometry': 'POLYGON ((597 ...   \n",
       "4  {'Outer Border': [{'geometry': 'POLYGON ((359 ...   \n",
       "\n",
       "                             raw_inner_poly  \\\n",
       "0  [504, 191, 902, 177, 915, 580, 495, 584]   \n",
       "1  [454, 212, 803, 221, 808, 552, 454, 566]   \n",
       "2  [590, 376, 791, 371, 794, 589, 577, 601]   \n",
       "3  [836, 385, 641, 387, 635, 582, 841, 582]   \n",
       "4  [470, 221, 848, 231, 851, 613, 457, 609]   \n",
       "\n",
       "                                         outer_poly  \\\n",
       "0  [(997, 65), (1014, 683), (402, 673), (416, 106)]   \n",
       "1  [(894, 638), (375, 646), (383, 136), (882, 141)]   \n",
       "2  [(848, 312), (851, 649), (533, 639), (538, 328)]   \n",
       "3  [(597, 623), (880, 627), (881, 344), (603, 346)]   \n",
       "4  [(359, 703), (950, 711), (943, 141), (384, 128)]   \n",
       "\n",
       "                                         inner_poly outer_x_min outer_y_min  \\\n",
       "0  [(504, 191), (902, 177), (915, 580), (495, 584)]         402          65   \n",
       "1  [(454, 212), (803, 221), (808, 552), (454, 566)]         375         136   \n",
       "2  [(590, 376), (791, 371), (794, 589), (577, 601)]         533         312   \n",
       "3  [(836, 385), (641, 387), (635, 582), (841, 582)]         597         344   \n",
       "4  [(470, 221), (848, 231), (851, 613), (457, 609)]         359         128   \n",
       "\n",
       "  outer_x_max outer_y_max inner_x_min inner_y_min inner_x_max inner_y_max  \\\n",
       "0        1015         684         495         177         916         585   \n",
       "1         895         647         454         212         809         567   \n",
       "2         852         650         577         371         795         602   \n",
       "3         882         628         635         385         842         583   \n",
       "4         951         712         457         221         852         614   \n",
       "\n",
       "  class_id  \n",
       "0           \n",
       "1           \n",
       "2           \n",
       "3           \n",
       "4           "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>outer_x_min</th>\n",
       "      <th>outer_y_min</th>\n",
       "      <th>outer_x_max</th>\n",
       "      <th>outer_y_max</th>\n",
       "      <th>outer_poly</th>\n",
       "      <th>class_id_x</th>\n",
       "      <th>inner_x_min</th>\n",
       "      <th>inner_y_min</th>\n",
       "      <th>inner_x_max</th>\n",
       "      <th>inner_y_max</th>\n",
       "      <th>inner_poly</th>\n",
       "      <th>class_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>402</td>\n",
       "      <td>65</td>\n",
       "      <td>1015</td>\n",
       "      <td>684</td>\n",
       "      <td>[(997, 65), (1014, 683), (402, 673), (416, 106)]</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>177</td>\n",
       "      <td>916</td>\n",
       "      <td>585</td>\n",
       "      <td>[(504, 191), (902, 177), (915, 580), (495, 584)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>375</td>\n",
       "      <td>136</td>\n",
       "      <td>895</td>\n",
       "      <td>647</td>\n",
       "      <td>[(894, 638), (375, 646), (383, 136), (882, 141)]</td>\n",
       "      <td>0</td>\n",
       "      <td>454</td>\n",
       "      <td>212</td>\n",
       "      <td>809</td>\n",
       "      <td>567</td>\n",
       "      <td>[(454, 212), (803, 221), (808, 552), (454, 566)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>533</td>\n",
       "      <td>312</td>\n",
       "      <td>852</td>\n",
       "      <td>650</td>\n",
       "      <td>[(848, 312), (851, 649), (533, 639), (538, 328)]</td>\n",
       "      <td>0</td>\n",
       "      <td>577</td>\n",
       "      <td>371</td>\n",
       "      <td>795</td>\n",
       "      <td>602</td>\n",
       "      <td>[(590, 376), (791, 371), (794, 589), (577, 601)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>597</td>\n",
       "      <td>344</td>\n",
       "      <td>882</td>\n",
       "      <td>628</td>\n",
       "      <td>[(597, 623), (880, 627), (881, 344), (603, 346)]</td>\n",
       "      <td>0</td>\n",
       "      <td>635</td>\n",
       "      <td>385</td>\n",
       "      <td>842</td>\n",
       "      <td>583</td>\n",
       "      <td>[(836, 385), (641, 387), (635, 582), (841, 582)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>359</td>\n",
       "      <td>128</td>\n",
       "      <td>951</td>\n",
       "      <td>712</td>\n",
       "      <td>[(359, 703), (950, 711), (943, 141), (384, 128)]</td>\n",
       "      <td>0</td>\n",
       "      <td>457</td>\n",
       "      <td>221</td>\n",
       "      <td>852</td>\n",
       "      <td>614</td>\n",
       "      <td>[(470, 221), (848, 231), (851, 613), (457, 609)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path outer_x_min outer_y_min  \\\n",
       "0  /media/a/D/lockheed-martin/dataset/LM_dataset/...         402          65   \n",
       "1  /media/a/D/lockheed-martin/dataset/LM_dataset/...         375         136   \n",
       "2  /media/a/D/lockheed-martin/dataset/LM_dataset/...         533         312   \n",
       "3  /media/a/D/lockheed-martin/dataset/LM_dataset/...         597         344   \n",
       "4  /media/a/D/lockheed-martin/dataset/LM_dataset/...         359         128   \n",
       "\n",
       "  outer_x_max outer_y_max                                        outer_poly  \\\n",
       "0        1015         684  [(997, 65), (1014, 683), (402, 673), (416, 106)]   \n",
       "1         895         647  [(894, 638), (375, 646), (383, 136), (882, 141)]   \n",
       "2         852         650  [(848, 312), (851, 649), (533, 639), (538, 328)]   \n",
       "3         882         628  [(597, 623), (880, 627), (881, 344), (603, 346)]   \n",
       "4         951         712  [(359, 703), (950, 711), (943, 141), (384, 128)]   \n",
       "\n",
       "   class_id_x inner_x_min inner_y_min inner_x_max inner_y_max  \\\n",
       "0           0         495         177         916         585   \n",
       "1           0         454         212         809         567   \n",
       "2           0         577         371         795         602   \n",
       "3           0         635         385         842         583   \n",
       "4           0         457         221         852         614   \n",
       "\n",
       "                                         inner_poly  class_id_y  \n",
       "0  [(504, 191), (902, 177), (915, 580), (495, 584)]           1  \n",
       "1  [(454, 212), (803, 221), (808, 552), (454, 566)]           1  \n",
       "2  [(590, 376), (791, 371), (794, 589), (577, 601)]           1  \n",
       "3  [(836, 385), (641, 387), (635, 582), (841, 582)]           1  \n",
       "4  [(470, 221), (848, 231), (851, 613), (457, 609)]           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep only filed required by yolov3. Divide the dataframe into outer and inner bounding boxes and then assign a class to each one of them \n",
    "keep_cols_outer=['img_path', 'outer_x_min', 'outer_y_min', 'outer_x_max', 'outer_y_max','outer_poly','class_id']\n",
    "keep_cols_inner=['img_path', 'inner_x_min', 'inner_y_min', 'inner_x_max', 'inner_y_max', 'inner_poly','class_id']\n",
    "df_outer=df_all[keep_cols_outer]\n",
    "df_inner=df_all[keep_cols_inner]\n",
    "df_outer['class_id']=0\n",
    "df_inner['class_id']=1\n",
    "df_enet=pd.merge(df_outer, df_inner, on='img_path')\n",
    "df_enet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer poly [(537, 272), (903, 291), (909, 659), (535, 669)]\n",
      "inner_poly [(582, 324), (831, 342), (843, 584), (589, 590)]\n",
      "outer poly [(403, 160), (385, 742), (908, 715), (905, 214), (515, 160), (403, 147)]\n",
      "inner_poly [(476, 243), (820, 285), (825, 639), (470, 649)]\n",
      "outer poly [(201, 185), (688, 150), (679, 723), (198, 677)]\n",
      "inner_poly [(279, 255), (603, 247), (597, 627), (278, 604)]\n",
      "outer poly [(411, 255), (732, 269), (735, 585), (408, 589)]\n",
      "inner_poly [(461, 312), (677, 316), (689, 539), (464, 532)]\n",
      "outer poly [(234, 13), (831, 147), (858, 726), (171, 739)]\n",
      "inner_poly [(319, 146), (737, 219), (751, 632), (292, 623)]\n",
      "outer poly [(579, 272), (890, 274), (899, 586), (589, 598)]\n",
      "inner_poly [(627, 323), (839, 321), (843, 535), (630, 542)]\n",
      "outer poly [(351, 64), (977, 56), (1003, 693), (337, 700)]\n",
      "inner_poly [(440, 165), (879, 169), (884, 584), (437, 590)]\n",
      "outer poly [(459, 377), (562, 357), (564, 569), (458, 556)]\n",
      "inner_poly [(483, 402), (540, 397), (540, 527), (489, 521)]\n",
      "outer poly [(567, 292), (797, 333), (801, 634), (565, 657)]\n",
      "inner_poly [(608, 355), (767, 374), (763, 577), (604, 594)]\n",
      "outer poly [(589, 294), (709, 179), (713, 706), (592, 655)]\n",
      "inner_poly [(642, 345), (682, 302), (687, 611), (637, 601)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing annotation all together \n",
    "\n",
    "def get_mask(img_shape, poly,display=False):\n",
    "     \n",
    "\n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "    polygons = []\n",
    "    for pt in poly:\n",
    "        a = (int(pt[0]), int(pt[1]))\n",
    "        polygons.append(a)\n",
    "    \n",
    "    draw.polygon(xy=polygons, outline=1, fill=1)\n",
    "    mask = np.array(mask, dtype=bool)\n",
    "    if display:\n",
    "        plt.imshow(mask)\n",
    "        plt.show\n",
    "    return mask\n",
    "#getting the final mask\n",
    "\n",
    "for i in range(100,110):#len(df)): # use one image only for testing\n",
    "\n",
    "    img=cv2.imread(df_enet['img_path'][i])\n",
    "    row=img.shape[0]\n",
    "    col=img.shape[1]\n",
    "    img_shape = (row,col)\n",
    "    outer_poly=df_enet['outer_poly'][i] \n",
    "    print('outer poly',outer_poly)\n",
    "    inner_poly=df_enet['inner_poly'][i]\n",
    "    print('inner_poly', list(inner_poly))\n",
    "    outer_mask=get_mask(img_shape,outer_poly,display=False)\n",
    "    inner_mask=get_mask(img_shape,inner_poly,display=False)\n",
    "    inner_mask.dtype='uint8'\n",
    "    outer_mask.dtype='uint8'\n",
    "    final_mask=cv2.subtract(outer_mask,inner_mask)\n",
    "    plt.imshow(cv2.bitwise_and(img,img,mask=final_mask))\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4427\n"
     ]
    }
   ],
   "source": [
    "print(len(df_enet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ENet model\n",
    "We decided to to split the model to three sub classes:\n",
    "\n",
    "1) Initial block\n",
    "\n",
    "2) RDDNeck - class for regular, downsampling and dilated bottlenecks\n",
    "\n",
    "3) ASNeck - class for asymetric bottlenecks\n",
    "\n",
    "4) UBNeck - class for upsampling bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitialBlock(nn.Module):\n",
    "  \n",
    "  # Initial block of the model:\n",
    "  #         Input\n",
    "  #        /     \\\n",
    "  #       /       \\\n",
    "  #maxpool2d    conv2d-3x3\n",
    "  #       \\       /  \n",
    "  #        \\     /\n",
    "  #      concatenate\n",
    "   \n",
    "    def __init__ (self,in_channels = 3,out_channels = 13):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, \n",
    "                                      stride = 2, \n",
    "                                      padding = 0)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, \n",
    "                                out_channels,\n",
    "                                kernel_size = 3,\n",
    "                                stride = 2, \n",
    "                                padding = 1)\n",
    "\n",
    "        self.prelu = nn.PReLU(16)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        \n",
    "        main = self.conv(x)\n",
    "        main = self.batchnorm(main)\n",
    "        \n",
    "        side = self.maxpool(x)\n",
    "        \n",
    "        # concatenating on the channels axis\n",
    "        x = torch.cat((main, side), dim=1)\n",
    "        x = self.prelu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UBNeck(nn.Module):\n",
    "    \n",
    "  # Upsampling bottleneck:\n",
    "  #     Bottleneck Input\n",
    "  #        /        \\\n",
    "  #       /          \\\n",
    "  # conv2d-1x1     convTrans2d-1x1\n",
    "  #      |             | PReLU\n",
    "  #      |         convTrans2d-3x3\n",
    "  #      |             | PReLU\n",
    "  #      |         convTrans2d-1x1\n",
    "  #      |             |\n",
    "  # maxunpool2d    Regularizer\n",
    "  #       \\           /  \n",
    "  #        \\         /\n",
    "  #      Summing + PReLU\n",
    "  #\n",
    "  #  Params: \n",
    "  #  projection_ratio - ratio between input and output channels\n",
    "  #  relu - if True: relu used as the activation function else: Prelu us used\n",
    "  \n",
    "    def __init__(self, in_channels, out_channels, relu=False, projection_ratio=4):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        self.in_channels = in_channels\n",
    "        self.reduced_depth = int(in_channels / projection_ratio)\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        \n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "        \n",
    "        self.unpool = nn.MaxUnpool2d(kernel_size = 2,\n",
    "                                     stride = 2)\n",
    "        \n",
    "        self.main_conv = nn.Conv2d(in_channels = self.in_channels,\n",
    "                                    out_channels = self.out_channels,\n",
    "                                    kernel_size = 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        \n",
    "        \n",
    "        self.convt1 = nn.ConvTranspose2d(in_channels = self.in_channels,\n",
    "                               out_channels = self.reduced_depth,\n",
    "                               kernel_size = 1,\n",
    "                               padding = 0,\n",
    "                               bias = False)\n",
    "        \n",
    "        \n",
    "        self.prelu1 = activation\n",
    "        \n",
    "        # This layer used for Upsampling\n",
    "        self.convt2 = nn.ConvTranspose2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.reduced_depth,\n",
    "                                  kernel_size = 3,\n",
    "                                  stride = 2,\n",
    "                                  padding = 1,\n",
    "                                  output_padding = 1,\n",
    "                                  bias = False)\n",
    "        \n",
    "        self.prelu2 = activation\n",
    "        \n",
    "        self.convt3 = nn.ConvTranspose2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.out_channels,\n",
    "                                  kernel_size = 1,\n",
    "                                  padding = 0,\n",
    "                                  bias = False)\n",
    "        \n",
    "        self.prelu3 = activation\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "    def forward(self, x, indices):\n",
    "        x_copy = x\n",
    "        \n",
    "        # Side Branch\n",
    "        x = self.convt1(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu1(x)\n",
    "        \n",
    "        x = self.convt2(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu2(x)\n",
    "        \n",
    "        x = self.convt3(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Main Branch\n",
    "        \n",
    "        x_copy = self.main_conv(x_copy)\n",
    "        x_copy = self.unpool(x_copy, indices, output_size=x.size())\n",
    "        \n",
    "        # summing the main and side branches\n",
    "        x = x + x_copy\n",
    "        x = self.prelu3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDDNeck(nn.Module):\n",
    "    def __init__(self, dilation, in_channels, out_channels, down_flag, relu=False, projection_ratio=4, p=0.1):\n",
    "      \n",
    "  # Regular|Dilated|Downsampling bottlenecks:\n",
    "  #\n",
    "  #     Bottleneck Input\n",
    "  #        /        \\\n",
    "  #       /          \\\n",
    "  # maxpooling2d   conv2d-1x1\n",
    "  #      |             | PReLU\n",
    "  #      |         conv2d-3x3\n",
    "  #      |             | PReLU\n",
    "  #      |         conv2d-1x1\n",
    "  #      |             |\n",
    "  #  Padding2d     Regularizer\n",
    "  #       \\           /  \n",
    "  #        \\         /\n",
    "  #      Summing + PReLU\n",
    "  #\n",
    "  # Params: \n",
    "  #  dilation (bool) - if True: creating dilation bottleneck\n",
    "  #  down_flag (bool) - if True: creating downsampling bottleneck\n",
    "  #  projection_ratio - ratio between input and output channels\n",
    "  #  relu - if True: relu used as the activation function else: Prelu us used\n",
    "  #  p - dropout ratio\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        self.dilation = dilation\n",
    "        self.down_flag = down_flag\n",
    "        \n",
    "        # calculating the number of reduced channels\n",
    "        if down_flag:\n",
    "            self.stride = 2\n",
    "            self.reduced_depth = int(in_channels // projection_ratio)\n",
    "        else:\n",
    "            self.stride = 1\n",
    "            self.reduced_depth = int(out_channels // projection_ratio)\n",
    "        \n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 2,\n",
    "                                      stride = 2,\n",
    "                                      padding = 0, return_indices=True)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(p=p)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = self.in_channels,\n",
    "                               out_channels = self.reduced_depth,\n",
    "                               kernel_size = 1,\n",
    "                               stride = 1,\n",
    "                               padding = 0,\n",
    "                               bias = False,\n",
    "                               dilation = 1)\n",
    "        \n",
    "        self.prelu1 = activation\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.reduced_depth,\n",
    "                                  kernel_size = 3,\n",
    "                                  stride = self.stride,\n",
    "                                  padding = self.dilation,\n",
    "                                  bias = True,\n",
    "                                  dilation = self.dilation)\n",
    "                                  \n",
    "        self.prelu2 = activation\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.out_channels,\n",
    "                                  kernel_size = 1,\n",
    "                                  stride = 1,\n",
    "                                  padding = 0,\n",
    "                                  bias = False,\n",
    "                                  dilation = 1)\n",
    "        \n",
    "        self.prelu3 = activation\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        bs = x.size()[0]\n",
    "        x_copy = x\n",
    "        \n",
    "        # Side Branch\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm2(x)\n",
    "                \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Main Branch\n",
    "        if self.down_flag:\n",
    "            x_copy, indices = self.maxpool(x_copy)\n",
    "          \n",
    "        if self.in_channels != self.out_channels:\n",
    "            out_shape = self.out_channels - self.in_channels\n",
    "            \n",
    "            #padding and concatenating in order to match the channels axis of the side and main branches\n",
    "            extras = torch.zeros((bs, out_shape, x.shape[2], x.shape[3]))\n",
    "            if torch.cuda.is_available():\n",
    "                extras = extras.cuda()\n",
    "            x_copy = torch.cat((x_copy, extras), dim = 1)\n",
    "\n",
    "        # Summing main and side branches\n",
    "        x = x + x_copy\n",
    "        x = self.prelu3(x)\n",
    "        \n",
    "        if self.down_flag:\n",
    "            return x, indices\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASNeck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, projection_ratio=4):\n",
    "      \n",
    "  # Asymetric bottleneck:\n",
    "  #\n",
    "  #     Bottleneck Input\n",
    "  #        /        \\\n",
    "  #       /          \\\n",
    "  #      |         conv2d-1x1\n",
    "  #      |             | PReLU\n",
    "  #      |         conv2d-1x5\n",
    "  #      |             |\n",
    "  #      |         conv2d-5x1\n",
    "  #      |             | PReLU\n",
    "  #      |         conv2d-1x1\n",
    "  #      |             |\n",
    "  #  Padding2d     Regularizer\n",
    "  #       \\           /  \n",
    "  #        \\         /\n",
    "  #      Summing + PReLU\n",
    "  #\n",
    "  # Params:    \n",
    "  #  projection_ratio - ratio between input and output channels\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        self.in_channels = in_channels\n",
    "        self.reduced_depth = int(in_channels / projection_ratio)\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = self.in_channels,\n",
    "                               out_channels = self.reduced_depth,\n",
    "                               kernel_size = 1,\n",
    "                               stride = 1,\n",
    "                               padding = 0,\n",
    "                               bias = False)\n",
    "        \n",
    "        self.prelu1 = nn.PReLU()\n",
    "        \n",
    "        self.conv21 = nn.Conv2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.reduced_depth,\n",
    "                                  kernel_size = (1, 5),\n",
    "                                  stride = 1,\n",
    "                                  padding = (0, 2),\n",
    "                                  bias = False)\n",
    "        \n",
    "        self.conv22 = nn.Conv2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.reduced_depth,\n",
    "                                  kernel_size = (5, 1),\n",
    "                                  stride = 1,\n",
    "                                  padding = (2, 0),\n",
    "                                  bias = False)\n",
    "        \n",
    "        self.prelu2 = nn.PReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.out_channels,\n",
    "                                  kernel_size = 1,\n",
    "                                  stride = 1,\n",
    "                                  padding = 0,\n",
    "                                  bias = False)\n",
    "        \n",
    "        self.prelu3 = nn.PReLU()\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.size()[0]\n",
    "        x_copy = x\n",
    "        \n",
    "        # Side Branch\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu1(x)\n",
    "        \n",
    "        x = self.conv21(x)\n",
    "        x = self.conv22(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "                \n",
    "        x = self.dropout(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        # Main Branch\n",
    "        \n",
    "        if self.in_channels != self.out_channels:\n",
    "            out_shape = self.out_channels - self.in_channels\n",
    "            \n",
    "            #padding and concatenating in order to match the channels axis of the side and main branches\n",
    "            extras = torch.zeros((bs, out_shape, x.shape[2], x.shape[3]))\n",
    "            if torch.cuda.is_available():\n",
    "                extras = extras.cuda()\n",
    "            x_copy = torch.cat((x_copy, extras), dim = 1)\n",
    "        \n",
    "        # Summing main and side branches\n",
    "        x = x + x_copy\n",
    "        x = self.prelu3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENet(nn.Module):\n",
    "  \n",
    "  # Creating Enet model!\n",
    "  \n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        # C - number of classes\n",
    "        self.C = C\n",
    "        \n",
    "        # The initial block\n",
    "        self.init = InitialBlock()\n",
    "        \n",
    "        \n",
    "        # The first bottleneck\n",
    "        self.b10 = RDDNeck(dilation=1, \n",
    "                           in_channels=16, \n",
    "                           out_channels=64, \n",
    "                           down_flag=True, \n",
    "                           p=0.01)\n",
    "        \n",
    "        self.b11 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           p=0.01)\n",
    "        \n",
    "        self.b12 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           p=0.01)\n",
    "        \n",
    "        self.b13 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           p=0.01)\n",
    "        \n",
    "        self.b14 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           p=0.01)\n",
    "        \n",
    "        \n",
    "        # The second bottleneck\n",
    "        self.b20 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=128, \n",
    "                           down_flag=True)\n",
    "        \n",
    "        self.b21 = RDDNeck(dilation=1, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b22 = RDDNeck(dilation=2, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b23 = ASNeck(in_channels=128, \n",
    "                          out_channels=128)\n",
    "        \n",
    "        self.b24 = RDDNeck(dilation=4, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b25 = RDDNeck(dilation=1, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b26 = RDDNeck(dilation=8, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b27 = ASNeck(in_channels=128, \n",
    "                          out_channels=128)\n",
    "        \n",
    "        self.b28 = RDDNeck(dilation=16, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        \n",
    "        # The third bottleneck\n",
    "        self.b31 = RDDNeck(dilation=1, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b32 = RDDNeck(dilation=2, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b33 = ASNeck(in_channels=128, \n",
    "                          out_channels=128)\n",
    "        \n",
    "        self.b34 = RDDNeck(dilation=4, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b35 = RDDNeck(dilation=1, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b36 = RDDNeck(dilation=8, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b37 = ASNeck(in_channels=128, \n",
    "                          out_channels=128)\n",
    "        \n",
    "        self.b38 = RDDNeck(dilation=16, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        \n",
    "        # The fourth bottleneck\n",
    "        self.b40 = UBNeck(in_channels=128, \n",
    "                          out_channels=64, \n",
    "                          relu=True)\n",
    "        \n",
    "        self.b41 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           relu=True)\n",
    "        \n",
    "        self.b42 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           relu=True)\n",
    "        \n",
    "        \n",
    "        # The fifth bottleneck\n",
    "        self.b50 = UBNeck(in_channels=64, \n",
    "                          out_channels=16, \n",
    "                          relu=True)\n",
    "        \n",
    "        self.b51 = RDDNeck(dilation=1, \n",
    "                           in_channels=16, \n",
    "                           out_channels=16, \n",
    "                           down_flag=False, \n",
    "                           relu=True)\n",
    "        \n",
    "        \n",
    "        # Final ConvTranspose Layer\n",
    "        self.fullconv = nn.ConvTranspose2d(in_channels=16, \n",
    "                                           out_channels=self.C, \n",
    "                                           kernel_size=3, \n",
    "                                           stride=2, \n",
    "                                           padding=1, \n",
    "                                           output_padding=1,\n",
    "                                           bias=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # The initial block\n",
    "        x = self.init(x)\n",
    "        \n",
    "        # The first bottleneck\n",
    "        x, i1 = self.b10(x)\n",
    "        x = self.b11(x)\n",
    "        x = self.b12(x)\n",
    "        x = self.b13(x)\n",
    "        x = self.b14(x)\n",
    "        \n",
    "        # The second bottleneck\n",
    "        x, i2 = self.b20(x)\n",
    "        x = self.b21(x)\n",
    "        x = self.b22(x)\n",
    "        x = self.b23(x)\n",
    "        x = self.b24(x)\n",
    "        x = self.b25(x)\n",
    "        x = self.b26(x)\n",
    "        x = self.b27(x)\n",
    "        x = self.b28(x)\n",
    "        \n",
    "        # The third bottleneck\n",
    "        x = self.b31(x)\n",
    "        x = self.b32(x)\n",
    "        x = self.b33(x)\n",
    "        x = self.b34(x)\n",
    "        x = self.b35(x)\n",
    "        x = self.b36(x)\n",
    "        x = self.b37(x)\n",
    "        x = self.b38(x)\n",
    "        \n",
    "        # The fourth bottleneck\n",
    "        x = self.b40(x, i2)\n",
    "        x = self.b41(x)\n",
    "        x = self.b42(x)\n",
    "        \n",
    "        # The fifth bottleneck\n",
    "        x = self.b50(x, i1)\n",
    "        x = self.b51(x)\n",
    "        \n",
    "        # Final ConvTranspose Layer\n",
    "        x = self.fullconv(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded a pretrained model\n"
     ]
    }
   ],
   "source": [
    "#Instantiate the ENet model\n",
    "load_pretrained = True\n",
    "enet = ENet(2)\n",
    "if load_pretrained:\n",
    "    state_dict = torch.load('content/ckpt-enet-460.pth')['state_dict']\n",
    "    enet.load_state_dict(state_dict)\n",
    "    print('loaded a pretrained model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there is any gpu available and pass the model to gpu or cpu\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "enet = enet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864, 1296, 3)\n"
     ]
    }
   ],
   "source": [
    "img = plt.imread(df_enet['img_path'][8])\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a generater\n",
    "from ImgAugumentation import ImgAugumentation\n",
    "img_augumentation = ImgAugumentation()\n",
    "def loader(df, batch_size, im_size=(512,512), aug=False):\n",
    "    total_files_s=len(df)\n",
    "    if str(batch_size).lower() == 'all':\n",
    "        batch_size = total_files_s\n",
    "    idx = 0\n",
    "    while(1):\n",
    "      # Choosing random indexes of images and labels\n",
    "        batch_idxs = np.random.randint(0, total_files_s, batch_size)\n",
    "   \n",
    "        \n",
    "        inputs = []\n",
    "        labels = []\n",
    "        \n",
    "        for jj in batch_idxs:\n",
    "          # Reading normalized photo\n",
    "        \n",
    " \n",
    "            img = plt.imread(df['img_path'][jj])\n",
    "            orginal_im_size=img.shape\n",
    "          # Resizing using nearest neighbor method\n",
    "            img = cv2.resize(img, (im_size[0], im_size[1]), cv2.INTER_NEAREST)\n",
    "            \n",
    "          # creating semantic mask \n",
    "            outer_poly=df['outer_poly'][jj] \n",
    "            #print('outer poly',outer_poly)\n",
    "            inner_poly=df['inner_poly'][jj]\n",
    "            #print('inner_poly', list(inner_poly))\n",
    "            outer_mask=get_mask((orginal_im_size[0], orginal_im_size[1]),outer_poly,display=False)\n",
    "            inner_mask=get_mask((orginal_im_size[0], orginal_im_size[1]),inner_poly,display=False)\n",
    "            inner_mask.dtype='uint8'\n",
    "            outer_mask.dtype='uint8'\n",
    "            final_mask=cv2.subtract(outer_mask,inner_mask)\n",
    "          # Resizing using nearest neighbor method\n",
    "            final_mask = cv2.resize(final_mask, (im_size[0], im_size[1]), cv2.INTER_NEAREST)\n",
    "            if aug:\n",
    "                rand_value_augument = np.random.randint(7)\n",
    "                if (rand_value_augument == 0):   \n",
    "                    img, final_mask=img_augumentation.flip_image_horz(img, final_mask)\n",
    "                if (rand_value_augument == 1): \n",
    "                    img, final_mask=img_augumentation.flip_image_ver(img, final_mask)\n",
    "                if (rand_value_augument == 2) or (rand_value_augument == 3): \n",
    "                    img=img_augumentation.brightness_images(img)\n",
    "                if (rand_value_augument == 4): \n",
    "                    img, final_mask =img_augumentation.trans_image(img,final_mask,50)\n",
    "                if (rand_value_augument == 5): \n",
    "                    img, final_mask =img_augumentation.stretch_image(img, final_mask,-100)\n",
    "                if (rand_value_augument == 6): \n",
    "                    img, final_mask =img_augumentation.stretch_image(img, final_mask,-50)\n",
    "                if (rand_value_augument == 7): \n",
    "                    img, final_mask =img_augumentation.stretch_image(img, final_mask,+30)\n",
    "            inputs.append(img)\n",
    "            labels.append(final_mask)\n",
    "\n",
    "        inputs = np.stack(inputs, axis=2)\n",
    "      # Changing image format to C x H x W\n",
    "        inputs = torch.tensor(inputs).transpose(0, 2).transpose(1, 3)\n",
    "        \n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        yield inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([512, 512])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid dimensions for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-48300b59d315>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_img\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2699\u001b[0m         \u001b[0mfilternorm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilternorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilterrad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilterrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimlim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimlim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2700\u001b[0m         resample=resample, url=url, **({\"data\": data} if data is not\n\u001b[0;32m-> 2701\u001b[0;31m         None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2702\u001b[0m     \u001b[0msci\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2703\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mimshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, shape, filternorm, filterrad, imlim, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5492\u001b[0m                               resample=resample, **kwargs)\n\u001b[1;32m   5493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5494\u001b[0;31m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5495\u001b[0m         \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras2/lib/python3.6/site-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mset_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    644\u001b[0m         if not (self._A.ndim == 2\n\u001b[1;32m    645\u001b[0m                 or self._A.ndim == 3 and self._A.shape[-1] in [3, 4]):\n\u001b[0;32m--> 646\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid dimensions for image data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid dimensions for image data"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1152 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test the generater\n",
    "batch_size=10\n",
    "training_gen=loader(df_enet, batch_size, aug=True)\n",
    "batch_img,batch_mask = next(training_gen)\n",
    "print(batch_mask[0].shape)\n",
    "\n",
    "for i in range(0,len(batch_img)):\n",
    " \n",
    "    plt.figure(figsize=(16,16))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(batch_img[i])\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(batch_mask[i])\n",
    "    plt.axis('off')\n",
    "\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(num_classes, c=1.02):\n",
    "    pipe = loader(df_enet, batch_size='all',aug=True)\n",
    "    _, labels = next(pipe)\n",
    "    all_labels = labels.flatten()\n",
    "    each_class = np.bincount(all_labels, minlength=num_classes)\n",
    "    prospensity_score = each_class / len(all_labels)\n",
    "    class_weights = 1 / (np.log(c + prospensity_score))\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = get_class_weights(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "batch_size = 20\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(device))\n",
    "optimizer = torch.optim.Adam(enet.parameters(), \n",
    "                             lr=lr,\n",
    "                             weight_decay=2e-4)\n",
    "\n",
    "print_every = 20\n",
    "eval_every = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_enet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_trn, df_tst = train_test_split(df_enet, test_size=0.03)\n",
    "print(len(df_trn))\n",
    "print(len(df_tst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn.reset_index(drop=True, inplace=True)\n",
    "df_tst.reset_index(drop=True, inplace=True)\n",
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#create overfitting dataset\n",
    "df_trn, df_tst = train_test_split(df_tst, test_size=0.1)\n",
    "print(len(df_trn))\n",
    "print(len(df_tst))\n",
    "df_trn.reset_index(drop=True, inplace=True)\n",
    "df_tst.reset_index(drop=True, inplace=True)\n",
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "bc_train = 100# 1 // batch_size # mini_batch train\n",
    "bc_eval = 77# // batch_size  # mini_batch validation\n",
    "\n",
    "# Define pipeline objects\n",
    "pipe = loader(df_trn, batch_size,aug=True)\n",
    "eval_pipe = loader(df_tst, batch_size)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "# Train loop\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    \n",
    "    \n",
    "    train_loss = 0\n",
    "    print ('-'*15,'Epoch %d' % e, '-'*15)\n",
    "    \n",
    "    enet.train()\n",
    "    \n",
    "    for _ in tqdm(range(bc_train)):\n",
    "        X_batch, mask_batch = next(pipe)\n",
    "        \n",
    "        # assign data to cpu/gpu\n",
    "        X_batch, mask_batch = X_batch.to(device), mask_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = enet(X_batch.float())\n",
    "        #print(out.shape)\n",
    "        # loss calculation\n",
    "        loss = criterion(out, mask_batch.long())\n",
    "        # update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        \n",
    "    print ()\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    if (e+1) % print_every == 0:\n",
    "        print ('Epoch {}/{}...'.format(e, epochs),\n",
    "                'Loss {:6f}'.format(train_loss))\n",
    "    \n",
    "    if e % eval_every == 0:\n",
    "        with torch.no_grad():\n",
    "            enet.eval()\n",
    "            \n",
    "            eval_loss = 0\n",
    "\n",
    "            # Validation loop\n",
    "            for _ in tqdm(range(bc_eval)):\n",
    "                inputs, labels = next(eval_pipe)\n",
    "\n",
    "                inputs=inputs.float()\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    \n",
    "                \n",
    "                out = enet(inputs)\n",
    "                \n",
    "                out = out.data.max(1)[1]\n",
    "                \n",
    "                eval_loss += (labels.long() - out.long()).sum()\n",
    "                \n",
    "            \n",
    "            print ()\n",
    "            print ('Loss {:6f}'.format(eval_loss))\n",
    "            \n",
    "            eval_losses.append(eval_loss)\n",
    "        \n",
    "    if e % print_every == 0:\n",
    "        checkpoint = {\n",
    "            'epochs' : e,\n",
    "            'state_dict' : enet.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, 'content/ckpt-enet-{}-{}.pth'.format(e, train_loss))\n",
    "        print ('Model saved!')\n",
    "\n",
    "print ('Epoch {}/{}...'.format(e, epochs),\n",
    "       'Total Mean Loss: {:6f}'.format(sum(train_losses) / epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_img=70 \n",
    "tmg_ = plt.imread(df_tst['img_path'][sample_img])\n",
    "img_size=tmg_.shape\n",
    "print(img_size)\n",
    "#tmg_ = cv2.resize(tmg_, (img_size[0], img_size[1]), cv2.INTER_NEAREST)\n",
    "tmg = torch.tensor(tmg_).unsqueeze(0).float()\n",
    "tmg = tmg.transpose(2, 3).transpose(1, 2).to(device)\n",
    "\n",
    "enet.to(device)\n",
    "with torch.no_grad():\n",
    "    out1 = enet(tmg.float()).squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "outer_poly=df_tst['outer_poly'][sample_img] \n",
    "#print('outer poly',outer_poly)\n",
    "inner_poly=df_tst['inner_poly'][sample_img]\n",
    "#print('inner_poly', list(inner_poly))\n",
    "outer_mask=get_mask((img_size[0], img_size[1]),outer_poly,display=False)\n",
    "inner_mask=get_mask((img_size[0], img_size[1]),inner_poly,display=False)\n",
    "inner_mask.dtype='uint8'\n",
    "outer_mask.dtype='uint8'\n",
    "final_mask=cv2.subtract(outer_mask,inner_mask)\n",
    "plt.imshow(final_mask)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load a pretrained model if needed\n",
    "enet = ENet(2)\n",
    "state_dict = torch.load('content/ckpt-enet-108-3.242320427671075.pth')['state_dict']\n",
    "enet.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out2 = out1.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mno = 1 # Should be between 0 - n-1 | where n is the number of classes\n",
    "\n",
    "figure = plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Input Image')\n",
    "plt.axis('off')\n",
    "plt.imshow(tmg_)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Output Image')\n",
    "plt.axis('off')\n",
    "plt.imshow(out2[mno, :, :])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_ = out1.data.max(0)[1].cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_segmap(image):\n",
    "    gate = [128, 128, 128]\n",
    "     \n",
    "\n",
    "    label_colours = np.array([gate]).astype(np.uint8)\n",
    "    r = np.zeros_like(image).astype(np.uint8)\n",
    "    g = np.zeros_like(image).astype(np.uint8)\n",
    "    b = np.zeros_like(image).astype(np.uint8)\n",
    "    for l in range(0, 1):\n",
    "        r[image == l] = label_colours[l, 0]\n",
    "        g[image == l] = label_colours[l, 1]\n",
    "        b[image == l] = label_colours[l, 2]\n",
    "\n",
    "    rgb = np.zeros((image.shape[0], image.shape[1], 3)).astype(np.uint8)\n",
    "    rgb[:, :, 0] = b\n",
    "    rgb[:, :, 1] = g\n",
    "    rgb[:, :, 2] = r\n",
    "    return rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_seg = decode_segmap(final_mask)\n",
    "pred_seg = decode_segmap(b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure(figsize=(20, 10))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title('Input Image')\n",
    "plt.axis('off')\n",
    "plt.imshow(tmg_)\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title('Predicted Segmentation')\n",
    "plt.axis('off')\n",
    "plt.imshow(pred_seg)\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title('Ground Truth')\n",
    "plt.axis('off')\n",
    "plt.imshow(true_seg)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing pipeline      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "training_gen = generate_train_batch(cars_15_35GB,1)\n",
    "batch_img,batch_mask = next(training_gen)\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sample_imgs=1 \n",
    "testing_gen = generate_test_batch(cars_15_35GB,sample_imgs)\n",
    "pre_final_predictions= model.predict(batch_img)\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Test on last frames of data\n",
    "start = time.time()\n",
    "batch_img,batch_mask = next(testing_gen)\n",
    "pre_final_predictions= model.predict(batch_img)\n",
    "np.shape(pre_final_predictions)\n",
    "for i in range(sample_imgs):\n",
    "    im=batch_img[i]\n",
    "    pred,im = next_img(im)\n",
    "    im  = np.array(im,dtype= np.uint8)\n",
    "    im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    im_mask = np.array(255*batch_mask[i],dtype=np.uint8)\n",
    "    rgb_mask_true= cv2.cvtColor(im_mask,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_true[:,:,0] = 0*rgb_mask_true[:,:,0]\n",
    "    rgb_mask_true[:,:,2] = 0*rgb_mask_true[:,:,2]\n",
    "    img_true = cv2.addWeighted(rgb_mask_true,0.70,im,0.70,0)\n",
    "    rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "    img_pred = cv2.addWeighted(rgb_mask_pred,0.70,im,1,0)\n",
    "    draw_img = get_BB_new_img(im)\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(img_pred)\n",
    "    plt.title('Segmented')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.title('Predicted')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(img_true)\n",
    "    plt.title('Gtruth')\n",
    "    plt.axis('off')\n",
    "\n",
    "end = time.time()\n",
    "end-start   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = 'scene01021.jpg'\n",
    "im = cv2.imread(test_img)\n",
    "im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "pred,im = next_img(im)\n",
    "im  = np.array(im,dtype= np.uint8)\n",
    "im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "\n",
    "img_pred = cv2.addWeighted(rgb_mask_pred,0.70,im,1,0)\n",
    "\n",
    "draw_img = get_BB_new_img(im)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_pred)\n",
    "plt.title('Segmentated')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Bounding Box')\n",
    "plt.axis('off');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing camera calibration\n",
    "Camera calibration is performed in order to correct the deformation in the images that is caused to the optic lens curvature. The first step is to print a chessboard and take random pictures of it. Then count the chess intersecting squires to provide \"objp\" which holds the (x,y,z) coordinates of these corners. Z=0 here and the object points are the same for all images in the calibration folder. The objpoints will be appended in \"objp\" every time the method successfully detect all chessboard corners in a test image. \"imgpoints\" will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection.\n",
    "\"objpoints\" and \"imgpoints\" were used to compute the camera calibration and distortion coefficients using the \"cv2.calibrateCamera()\" function on a test image in \"cv2.undistort()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare object points. The number of corners are 6x9\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "# Make a list of calibration images, all located in camera_cal\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    # imread reads images in BGR format\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        #Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "        #cv2.imwrite(write_name, img)\n",
    "        #cv2.imshow('img', img)\n",
    "        #cv2.waitKey(500)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform distortion removal on test images¶\n",
    "1. Has the distortion correction been correctly applied to each image?\n",
    "Undistortion is performed on the provided test images before they are used in the pipeline. This also applies to the video frames. \"dst\" holds undistorted frames from \"cv2.undistort\" that were computed using \"mtx\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in glob.glob(\"Frames/*\"):\n",
    "    im = cv2.imread(image_name)\n",
    "    im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "    im = undistort(im,read=False, display = False, write = False)\n",
    "    pred,im = next_img(im)\n",
    "    im  = np.array(im,dtype= np.uint8)\n",
    "    im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "    img_pred = cv2.addWeighted(rgb_mask_pred,0.50,im,1,0)\n",
    "    draw_img = get_BB_new_img(im)\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(img_pred)\n",
    "    plt.title('Segmentated')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.title('Bounding Box')\n",
    "    plt.axis('off');\n",
    "\n",
    "heatmap_10 = [np.zeros((640,960))]*10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_pipeline(image):\n",
    "    #test_img = 'scene01021.jpg'\n",
    "    #im = cv2.imread(im)\n",
    "    #im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "    #img = get_BB_new_img(im)\n",
    "    # Apply bounding box to image\n",
    "    image_bb = np.copy(image)\n",
    "    bbox_cars = get_BB_new(image_bb)\n",
    "    img_size = np.shape(image)\n",
    "    result = image\n",
    "    img_res_shape = result.shape\n",
    "    for bbox in bbox_cars:\n",
    "        cv2.rectangle(result,(np.int32(bbox[0][0]*img_res_shape[1]/960),np.int32(bbox[0][1]*img_res_shape[0]/640)), (np.int32(bbox[1][0]*img_res_shape[1]/960),np.int32(bbox[1][1]*img_res_shape[0]/640)),(0,255,0),6)\n",
    "    #heatmap = get_Unet_mask(image_bb)\n",
    "    #plt.imshow(img)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(video_pipeline) \n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('project_video_output.mp4'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras2]",
   "language": "python",
   "name": "conda-env-keras2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
