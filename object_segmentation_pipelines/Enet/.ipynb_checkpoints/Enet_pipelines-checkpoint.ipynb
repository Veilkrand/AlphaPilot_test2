{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scene Understanding using Deep Learning\n",
    "## Introduction\n",
    "\n",
    "This Notebook was written for demonstrating scene understanding for the Lockheed Martin drone challange. The code consists of three pipelines pre-processing, FCN and post processing  The project is a corner stone for  \n",
    "\n",
    "\\<img style=\"float: center;\" src=\"readme_imgs/Img_groundtruth.png\">\n",
    "\n",
    "## Data Pre-processing \n",
    "\n",
    "We have implemented camera calibration routine to the video file.Each image was normalized and then smoothed with a Gaussian filter. The images were randomly processed with a brightness filter to help the network generalize to different lighting conditions. \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## FCN\n",
    "\n",
    " \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "##  Jaccard similarity coefficient \n",
    "\n",
    "In evaluating the model I've investigated several metrics including the Mean IU, Intersection over Union, and the Jaccard coefficient. The idea is to maximize the overlap between the predicted region and the ground truth bounding box.\n",
    " \n",
    "We eventually decided to use the Jaccard coeef. The Jaccard similarity coefficient is defined as the size of the intersection divided by the size of the union of two regions. This metric is used to compare the predicted labels to a set of labels in y_true  \n",
    "\n",
    "The coefficients are given by \n",
    "\n",
    "#### J(A,B) = |A∩B| / |A∪B|=|A∩B|/|A|+|B|-|A∩B| \n",
    "\n",
    "(If A and B are both empty, we define J(A,B) = 1.)\n",
    "\n",
    "<img style=\"float: center;\" src=\"readme_imgs/Intersection_of_sets_A_and_B.png\">\n",
    "<img style=\"float: center;\" src=\"readme_imgs/Intersection_of_sets_A_and_B_2.png\">\n",
    " \n",
    "\n",
    "## Training\n",
    "\n",
    "The Autti dataset was used and can be obtained from https://github.com/udacity/self-driving-car/tree/master/annotations .  \n",
    "\n",
    "## Results\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "\n",
    "from scipy.ndimage.measurements import label\n",
    "import pandas as pd\n",
    "#import keras.backend as K\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    " \n",
    "import time\n",
    "import numpy\n",
    "from PIL import Image, ImageDraw\n",
    "import re\n",
    "from shapely.geometry import Polygon\n",
    "from pprint import pprint\n",
    "import PIL.ImageDraw\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    " \n",
    "#add a note for the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and processing the wkt json format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>img_path</th>\n",
       "      <th>raw_inner_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_8378.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[616, 278, 948, 290, 945, 616, 609, 627]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_3034.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[502, 255, 663, 373, 673, 696, 492, 677]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_2082.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[504, 165, 829, 224, 819, 580, 489, 590]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_7209 (1).JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[409, 285, 774, 292, 781, 642, 387, 646]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_5207.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[494, 311, 765, 267, 768, 663, 495, 644]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             images                                           img_path  \\\n",
       "0      IMG_8378.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1      IMG_3034.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2      IMG_2082.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  IMG_7209 (1).JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4      IMG_5207.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                             raw_inner_poly  \n",
       "0  [616, 278, 948, 290, 945, 616, 609, 627]  \n",
       "1  [502, 255, 663, 373, 673, 696, 492, 677]  \n",
       "2  [504, 165, 829, 224, 819, 580, 489, 590]  \n",
       "3  [409, 285, 774, 292, 781, 642, 387, 646]  \n",
       "4  [494, 311, 765, 267, 768, 663, 495, 644]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df is the dataset that we are annotating\n",
    "#raw_df is the dataset that the organizers provided\n",
    "#adding path for json anf image folders respectively\n",
    "provided_data_file_dir='/media/a/D/lockheed-martin/dataset/LM_dataset/csv/training_GT_labels.json'#json provided by the organizers of the challange\n",
    "our_data_file_dir='/media/a/D/lockheed-martin/dataset/LM_dataset/csv/data_wkt_v2.json'#our annotated dataset\n",
    "img_file_dir='/media/a/D/lockheed-martin/dataset/LM_dataset/Data_Training/'#folder where images are stored\n",
    "provided_df = pd.read_json(provided_data_file_dir)\n",
    "df = pd.read_json(our_data_file_dir)\n",
    "\n",
    " \n",
    "#adding a complete path for the image \n",
    "df['External ID']= [img_file_dir + u for u in df['External ID']]#iris_data_dir + new_df['parcel_id'].astype(str) + '.jpg'\n",
    "\n",
    "df['images']=[u.split('/',8)[8] for u in df['External ID']]\n",
    "raw_df=pd.DataFrame()\n",
    "raw_df['images']=list(provided_df.columns.values)\n",
    "raw_df['img_path']=[img_file_dir +  u for u in raw_df['images']]\n",
    "\n",
    "raw_df['raw_inner_poly']=[ provided_df[u][0] for u in raw_df['images']]\n",
    "\n",
    "raw_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMG_7209(1).JPG\n"
     ]
    }
   ],
   "source": [
    "#remove white spaces from image path\n",
    "s=raw_df['images'][3]\n",
    "print(re.sub(r\"\\s+\", \"\", s))  # \\s matches all white spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#remove white space from image name in the folder containing the images\n",
    "\n",
    "#go to img directory and run python fix.py. Here is the file\n",
    "\n",
    "#remove white space from image name in the folder containing the images\n",
    "import os\n",
    "import re\n",
    "\n",
    "\"\"\" \n",
    "Renames the filenames within the same directory to be Unix friendly\n",
    "(1) Changes spaces to nothing\n",
    "(2) Makes lowercase (not a Unix requirement, just looks better ;)\n",
    "Usage:\n",
    "python rename.py\n",
    "\"\"\"\n",
    "path =  os.getcwd()\n",
    " \n",
    "filenames = os.listdir(path)\n",
    "\n",
    "for filename in filenames:\n",
    "    print('img name befor',filename)\n",
    "    fixed_filename=re.sub(r\"\\s+\", \"\", filename)\n",
    "    print('img name after',fixed_filename)\n",
    "    os.rename(filename, fixed_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agreement</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Created By</th>\n",
       "      <th>DataRow ID</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>External ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Labeled Data</th>\n",
       "      <th>Project Name</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Seconds to Label</th>\n",
       "      <th>View Label</th>\n",
       "      <th>images</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:35:37.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5r9p7w0anvd23j1pgg</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxucjqqkbd0b47j8vcjsua</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((997 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.832</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0015.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:36:22.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p800anv2xkrhfkw</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxvb54qkw90b47dwa8uupg</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((894 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>44.299</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0158.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:36:55.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p840anv7ly4rt5s</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxw0feqs9n08984nfshogi</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((848 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>31.955</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0244.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:17:15.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p880anvyjs4m1oj</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzrm18i8ga08983qewu7rq</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((597 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.032</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0367.JPG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:18:01.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8c0anvcve1d63y</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzslxpi69j0b4753lkl3ju</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((359 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>46.003</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0374.JPG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Agreement                Created At               Created By  \\\n",
       "0        NaN  2019-02-06T08:35:37.000Z  alberto.galet@gmail.com   \n",
       "1        NaN  2019-02-06T08:36:22.000Z  alberto.galet@gmail.com   \n",
       "2        NaN  2019-02-06T08:36:55.000Z  alberto.galet@gmail.com   \n",
       "3        NaN  2019-02-07T02:17:15.000Z  alberto.galet@gmail.com   \n",
       "4        NaN  2019-02-07T02:18:01.000Z  alberto.galet@gmail.com   \n",
       "\n",
       "                  DataRow ID         Dataset Name  \\\n",
       "0  cjrsurb5r9p7w0anvd23j1pgg  Test2 AlphaPilot #2   \n",
       "1  cjrsurb5v9p800anv2xkrhfkw  Test2 AlphaPilot #2   \n",
       "2  cjrsurb5v9p840anv7ly4rt5s  Test2 AlphaPilot #2   \n",
       "3  cjrsurb5v9p880anvyjs4m1oj  Test2 AlphaPilot #2   \n",
       "4  cjrsurb5v9p8c0anvcve1d63y  Test2 AlphaPilot #2   \n",
       "\n",
       "                                         External ID  \\\n",
       "0  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                          ID  \\\n",
       "0  cjrsxucjqqkbd0b47j8vcjsua   \n",
       "1  cjrsxvb54qkw90b47dwa8uupg   \n",
       "2  cjrsxw0feqs9n08984nfshogi   \n",
       "3  cjrtzrm18i8ga08983qewu7rq   \n",
       "4  cjrtzslxpi69j0b4753lkl3ju   \n",
       "\n",
       "                                               Label  \\\n",
       "0  {'Outer Border': [{'geometry': 'POLYGON ((997 ...   \n",
       "1  {'Outer Border': [{'geometry': 'POLYGON ((894 ...   \n",
       "2  {'Outer Border': [{'geometry': 'POLYGON ((848 ...   \n",
       "3  {'Outer Border': [{'geometry': 'POLYGON ((597 ...   \n",
       "4  {'Outer Border': [{'geometry': 'POLYGON ((359 ...   \n",
       "\n",
       "                                        Labeled Data      Project Name  \\\n",
       "0  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "1  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "2  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "3  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "4  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "\n",
       "  Reviews  Seconds to Label  \\\n",
       "0      []            33.832   \n",
       "1      []            44.299   \n",
       "2      []            31.955   \n",
       "3      []            39.032   \n",
       "4      []            46.003   \n",
       "\n",
       "                                          View Label        images  \n",
       "0  https://image-segmentation-v4.labelbox.com?pro...  IMG_0015.JPG  \n",
       "1  https://image-segmentation-v4.labelbox.com?pro...  IMG_0158.JPG  \n",
       "2  https://image-segmentation-v4.labelbox.com?pro...  IMG_0244.JPG  \n",
       "3  https://image-segmentation-v4.labelbox.com?pro...  IMG_0367.JPG  \n",
       "4  https://image-segmentation-v4.labelbox.com?pro...  IMG_0374.JPG  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agreement</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Created By</th>\n",
       "      <th>DataRow ID</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>External ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Labeled Data</th>\n",
       "      <th>Project Name</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Seconds to Label</th>\n",
       "      <th>View Label</th>\n",
       "      <th>images</th>\n",
       "      <th>img_path</th>\n",
       "      <th>raw_inner_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:35:37.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5r9p7w0anvd23j1pgg</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxucjqqkbd0b47j8vcjsua</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((997 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.832</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0015.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[504, 191, 902, 177, 915, 580, 495, 584]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:36:22.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p800anv2xkrhfkw</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxvb54qkw90b47dwa8uupg</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((894 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>44.299</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0158.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[454, 212, 803, 221, 808, 552, 454, 566]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:36:55.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p840anv7ly4rt5s</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxw0feqs9n08984nfshogi</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((848 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>31.955</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0244.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[590, 376, 791, 371, 794, 589, 577, 601]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:17:15.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p880anvyjs4m1oj</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzrm18i8ga08983qewu7rq</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((597 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.032</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0367.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[836, 385, 641, 387, 635, 582, 841, 582]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:18:01.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8c0anvcve1d63y</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzslxpi69j0b4753lkl3ju</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((359 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>46.003</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0374.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[470, 221, 848, 231, 851, 613, 457, 609]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:18:42.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8g0anv2ji1v57l</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzth7bi7210b47l0yydz0t</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((567 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.919</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0396.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[585, 338, 684, 354, 672, 523, 592, 532]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:19:13.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8k0anv1auzm8e0</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzu5bziasw0898zn0xuaez</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((343 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>30.653</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_0861.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[378, 468, 533, 480, 537, 646, 369, 646]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:19:47.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8o0anv56veqecf</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzuvrni8r10b47jq56iqvh</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((753 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.630</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_1128.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[509, 319, 705, 255, 705, 632, 506, 616]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:20:22.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8s0anvm6kjs3ge</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzvm6xibyq089861ts75g5</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((585 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.653</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_1546.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[620, 444, 756, 452, 760, 606, 623, 606]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:20:56.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8w0anvcfa1y38p</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzwcfmi9t30b47ily7qitc</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((471 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.376</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "      <td>IMG_1580.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[511, 433, 710, 438, 706, 630, 508, 632]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Agreement                Created At               Created By  \\\n",
       "0        NaN  2019-02-06T08:35:37.000Z  alberto.galet@gmail.com   \n",
       "1        NaN  2019-02-06T08:36:22.000Z  alberto.galet@gmail.com   \n",
       "2        NaN  2019-02-06T08:36:55.000Z  alberto.galet@gmail.com   \n",
       "3        NaN  2019-02-07T02:17:15.000Z  alberto.galet@gmail.com   \n",
       "4        NaN  2019-02-07T02:18:01.000Z  alberto.galet@gmail.com   \n",
       "5        NaN  2019-02-07T02:18:42.000Z  alberto.galet@gmail.com   \n",
       "6        NaN  2019-02-07T02:19:13.000Z  alberto.galet@gmail.com   \n",
       "7        NaN  2019-02-07T02:19:47.000Z  alberto.galet@gmail.com   \n",
       "8        NaN  2019-02-07T02:20:22.000Z  alberto.galet@gmail.com   \n",
       "9        NaN  2019-02-07T02:20:56.000Z  alberto.galet@gmail.com   \n",
       "\n",
       "                  DataRow ID         Dataset Name  \\\n",
       "0  cjrsurb5r9p7w0anvd23j1pgg  Test2 AlphaPilot #2   \n",
       "1  cjrsurb5v9p800anv2xkrhfkw  Test2 AlphaPilot #2   \n",
       "2  cjrsurb5v9p840anv7ly4rt5s  Test2 AlphaPilot #2   \n",
       "3  cjrsurb5v9p880anvyjs4m1oj  Test2 AlphaPilot #2   \n",
       "4  cjrsurb5v9p8c0anvcve1d63y  Test2 AlphaPilot #2   \n",
       "5  cjrsurb5v9p8g0anv2ji1v57l  Test2 AlphaPilot #2   \n",
       "6  cjrsurb5v9p8k0anv1auzm8e0  Test2 AlphaPilot #2   \n",
       "7  cjrsurb5v9p8o0anv56veqecf  Test2 AlphaPilot #2   \n",
       "8  cjrsurb5v9p8s0anvm6kjs3ge  Test2 AlphaPilot #2   \n",
       "9  cjrsurb5v9p8w0anvcfa1y38p  Test2 AlphaPilot #2   \n",
       "\n",
       "                                         External ID  \\\n",
       "0  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "5  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "6  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "7  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "8  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "9  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                          ID  \\\n",
       "0  cjrsxucjqqkbd0b47j8vcjsua   \n",
       "1  cjrsxvb54qkw90b47dwa8uupg   \n",
       "2  cjrsxw0feqs9n08984nfshogi   \n",
       "3  cjrtzrm18i8ga08983qewu7rq   \n",
       "4  cjrtzslxpi69j0b4753lkl3ju   \n",
       "5  cjrtzth7bi7210b47l0yydz0t   \n",
       "6  cjrtzu5bziasw0898zn0xuaez   \n",
       "7  cjrtzuvrni8r10b47jq56iqvh   \n",
       "8  cjrtzvm6xibyq089861ts75g5   \n",
       "9  cjrtzwcfmi9t30b47ily7qitc   \n",
       "\n",
       "                                               Label  \\\n",
       "0  {'Outer Border': [{'geometry': 'POLYGON ((997 ...   \n",
       "1  {'Outer Border': [{'geometry': 'POLYGON ((894 ...   \n",
       "2  {'Outer Border': [{'geometry': 'POLYGON ((848 ...   \n",
       "3  {'Outer Border': [{'geometry': 'POLYGON ((597 ...   \n",
       "4  {'Outer Border': [{'geometry': 'POLYGON ((359 ...   \n",
       "5  {'Outer Border': [{'geometry': 'POLYGON ((567 ...   \n",
       "6  {'Outer Border': [{'geometry': 'POLYGON ((343 ...   \n",
       "7  {'Outer Border': [{'geometry': 'POLYGON ((753 ...   \n",
       "8  {'Outer Border': [{'geometry': 'POLYGON ((585 ...   \n",
       "9  {'Outer Border': [{'geometry': 'POLYGON ((471 ...   \n",
       "\n",
       "                                        Labeled Data      Project Name  \\\n",
       "0  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "1  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "2  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "3  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "4  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "5  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "6  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "7  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "8  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "9  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "\n",
       "  Reviews  Seconds to Label  \\\n",
       "0      []            33.832   \n",
       "1      []            44.299   \n",
       "2      []            31.955   \n",
       "3      []            39.032   \n",
       "4      []            46.003   \n",
       "5      []            39.919   \n",
       "6      []            30.653   \n",
       "7      []            33.630   \n",
       "8      []            33.653   \n",
       "9      []            33.376   \n",
       "\n",
       "                                          View Label        images  \\\n",
       "0  https://image-segmentation-v4.labelbox.com?pro...  IMG_0015.JPG   \n",
       "1  https://image-segmentation-v4.labelbox.com?pro...  IMG_0158.JPG   \n",
       "2  https://image-segmentation-v4.labelbox.com?pro...  IMG_0244.JPG   \n",
       "3  https://image-segmentation-v4.labelbox.com?pro...  IMG_0367.JPG   \n",
       "4  https://image-segmentation-v4.labelbox.com?pro...  IMG_0374.JPG   \n",
       "5  https://image-segmentation-v4.labelbox.com?pro...  IMG_0396.JPG   \n",
       "6  https://image-segmentation-v4.labelbox.com?pro...  IMG_0861.JPG   \n",
       "7  https://image-segmentation-v4.labelbox.com?pro...  IMG_1128.JPG   \n",
       "8  https://image-segmentation-v4.labelbox.com?pro...  IMG_1546.JPG   \n",
       "9  https://image-segmentation-v4.labelbox.com?pro...  IMG_1580.JPG   \n",
       "\n",
       "                                            img_path  \\\n",
       "0  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "5  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "6  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "7  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "8  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "9  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                             raw_inner_poly  \n",
       "0  [504, 191, 902, 177, 915, 580, 495, 584]  \n",
       "1  [454, 212, 803, 221, 808, 552, 454, 566]  \n",
       "2  [590, 376, 791, 371, 794, 589, 577, 601]  \n",
       "3  [836, 385, 641, 387, 635, 582, 841, 582]  \n",
       "4  [470, 221, 848, 231, 851, 613, 457, 609]  \n",
       "5  [585, 338, 684, 354, 672, 523, 592, 532]  \n",
       "6  [378, 468, 533, 480, 537, 646, 369, 646]  \n",
       "7  [509, 319, 705, 255, 705, 632, 506, 616]  \n",
       "8  [620, 444, 756, 452, 760, 606, 623, 606]  \n",
       "9  [511, 433, 710, 438, 706, 630, 508, 632]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#merge the our annotations and provided annotations\n",
    "df_all=pd.merge(df, raw_df, on='images')\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2534\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>img_path</th>\n",
       "      <th>Label</th>\n",
       "      <th>raw_inner_poly</th>\n",
       "      <th>outer_poly</th>\n",
       "      <th>inner_poly</th>\n",
       "      <th>outer_x_min</th>\n",
       "      <th>outer_y_min</th>\n",
       "      <th>outer_x_max</th>\n",
       "      <th>outer_y_max</th>\n",
       "      <th>inner_x_min</th>\n",
       "      <th>inner_y_min</th>\n",
       "      <th>inner_x_max</th>\n",
       "      <th>inner_y_max</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_0015.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((997 ...</td>\n",
       "      <td>[504, 191, 902, 177, 915, 580, 495, 584]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_0158.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((894 ...</td>\n",
       "      <td>[454, 212, 803, 221, 808, 552, 454, 566]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_0244.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((848 ...</td>\n",
       "      <td>[590, 376, 791, 371, 794, 589, 577, 601]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_0367.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((597 ...</td>\n",
       "      <td>[836, 385, 641, 387, 635, 582, 841, 582]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_0374.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((359 ...</td>\n",
       "      <td>[470, 221, 848, 231, 851, 613, 457, 609]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         images                                           img_path  \\\n",
       "0  IMG_0015.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  IMG_0158.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  IMG_0244.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  IMG_0367.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  IMG_0374.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                                               Label  \\\n",
       "0  {'Outer Border': [{'geometry': 'POLYGON ((997 ...   \n",
       "1  {'Outer Border': [{'geometry': 'POLYGON ((894 ...   \n",
       "2  {'Outer Border': [{'geometry': 'POLYGON ((848 ...   \n",
       "3  {'Outer Border': [{'geometry': 'POLYGON ((597 ...   \n",
       "4  {'Outer Border': [{'geometry': 'POLYGON ((359 ...   \n",
       "\n",
       "                             raw_inner_poly outer_poly inner_poly outer_x_min  \\\n",
       "0  [504, 191, 902, 177, 915, 580, 495, 584]                                     \n",
       "1  [454, 212, 803, 221, 808, 552, 454, 566]                                     \n",
       "2  [590, 376, 791, 371, 794, 589, 577, 601]                                     \n",
       "3  [836, 385, 641, 387, 635, 582, 841, 582]                                     \n",
       "4  [470, 221, 848, 231, 851, 613, 457, 609]                                     \n",
       "\n",
       "  outer_y_min outer_x_max outer_y_max inner_x_min inner_y_min inner_x_max  \\\n",
       "0                                                                           \n",
       "1                                                                           \n",
       "2                                                                           \n",
       "3                                                                           \n",
       "4                                                                           \n",
       "\n",
       "  inner_y_max class_id  \n",
       "0                       \n",
       "1                       \n",
       "2                       \n",
       "3                       \n",
       "4                       "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "keep_cols=['images', 'img_path','Label','raw_inner_poly']\n",
    "df_all=df_all[keep_cols]\n",
    "df_all['outer_poly']=''\n",
    "df_all['inner_poly']=''\n",
    "df_all['outer_x_min']=''\n",
    "df_all['outer_y_min']=''\n",
    "df_all['outer_x_max']=''\n",
    "df_all['outer_y_max']=''\n",
    "df_all['inner_x_min']=''\n",
    "df_all['inner_y_min']=''\n",
    "df_all['inner_x_max']=''\n",
    "df_all['inner_y_max']=''\n",
    "df_all['class_id']= ''\n",
    "print(len(df_all))\n",
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw_inner_poly [511, 247, 850, 271, 853, 609, 506, 616]\n",
      "poly [511, 247, 850, 271, 853, 609, 506, 616]\n",
      "raw_inner_poly [492, 400, 665, 390, 667, 596, 489, 590]\n",
      "poly [492, 400, 665, 390, 667, 596, 489, 590]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# checking the mask from the provided GT by the organizers\n",
    "\n",
    "\n",
    "\n",
    "#processing the polygone and creating a mask\n",
    "def get_mask_raw_data(img_shape, poly,display=False):\n",
    "    output_mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    print('poly',poly)\n",
    "\n",
    "    coords =  zip(*[iter(poly)] * 2) \n",
    "     \n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "    x = []\n",
    "    y = []\n",
    "    polygons = []\n",
    "\n",
    "    for pt in coords:\n",
    "        a = (int(pt[0]), int(pt[1]))\n",
    "        polygons.append(a)\n",
    "        init_x = (int(pt[0]))\n",
    "        init_y = (int(pt[1]))\n",
    "\n",
    "        x.append(init_x)\n",
    "        y.append(init_y)\n",
    "    proc_polygons=np.vstack((x,y)).T\n",
    "    x,y,w,h = cv2.boundingRect(proc_polygons) \n",
    "    draw.polygon(xy=polygons, outline=1, fill=1)\n",
    "    mask = np.array(mask, dtype=bool)\n",
    "    if display:\n",
    "        plt.imshow(mask)\n",
    "        plt.show\n",
    "    return mask\n",
    "for i in range(444,446):#len(df)):\n",
    "\n",
    "    img=cv2.imread(df_all['img_path'][i])\n",
    "    row=img.shape[0]\n",
    "    col=img.shape[1]\n",
    "    img_shape = (row,col)\n",
    "    #outer_poly=df['Label'][i] \n",
    "    inner_poly=df_all['raw_inner_poly'][i]\n",
    "    if inner_poly:\n",
    "        print('raw_inner_poly',inner_poly)\n",
    "    #outer_mask=get_mask(img_shape,outer_poly,display=False)\n",
    "        inner_mask=get_mask_raw_data(img_shape,inner_poly,display=False)\n",
    "        inner_mask.dtype='uint8'\n",
    "    #outer_mask.dtype='uint8'\n",
    "    #final_mask=cv2.subtract(outer_mask,inner_mask)\n",
    "        plt.imshow(cv2.bitwise_and(img,img,mask=inner_mask))\n",
    "        plt.show\n",
    "    else:\n",
    "        print('polygon data corruption detected for index:', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test_id=1\n",
    "test_poly=df['Label'][test_id]['Outer Border']#df['outer_poly'][1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2534/2534 [00:01<00:00, 1454.41it/s]\n"
     ]
    }
   ],
   "source": [
    "#convert the polygons into a format that can be convereted to bounding boxes \n",
    "from tqdm import tqdm\n",
    "#preprocessing our_dataset\n",
    "\n",
    "def convert_coordinates(poly):\n",
    "    proc_poly=poly[0]['geometry']\n",
    "    nums =  re.findall(r'\\d+(?:\\.\\d*)?', proc_poly.rpartition(',')[0])\n",
    "    coords =  zip(*[iter(nums)] * 2)\n",
    "    polygons = []\n",
    "    for pt in coords:\n",
    "        a = (int(pt[0]), int(pt[1]))\n",
    "        polygons.append(a)\n",
    "    \n",
    "    return polygons \n",
    "def convert_coordinates_raw(polygon):\n",
    "    poly=[]\n",
    "    polygon =  zip(*[iter(polygon)] * 2)\n",
    "    for p in polygon:\n",
    "        poly.append(p)\n",
    "    return poly\n",
    "def get_bbox(polygon):\n",
    "    polygon=polygon[0]['geometry']\n",
    "    polygon=(polygon)\n",
    "\n",
    "    polygon =  re.findall(r'\\d+(?:\\.\\d*)?', polygon)\n",
    "    polygon =  zip(*[iter(polygon)] * 2)\n",
    "    x = []\n",
    "    y = []\n",
    "    for pt in polygon:\n",
    "        init_x = (int(pt[0]))\n",
    "        init_y = (int(pt[1]))\n",
    "\n",
    "        x.append(init_x)\n",
    "        y.append(init_y)\n",
    "    polygons=np.vstack((x,y)).T\n",
    "   \n",
    "    x,y,w,h = cv2.boundingRect(polygons)\n",
    "    x_min=x\n",
    "    y_min=y\n",
    "    x_max=x+w\n",
    "    y_max=y+h\n",
    "    return x_min,y_min,x_max,y_max\n",
    "    #return x_min,x_max,y_min,y_max\n",
    "def get_bbox_raw_data(polygon):\n",
    "    polygon =  zip(*[iter(polygon)] * 2)\n",
    "    x = []\n",
    "    y = []\n",
    "    for pt in polygon:\n",
    " \n",
    "        init_x = (int(pt[0]))\n",
    "        init_y = (int(pt[1]))\n",
    "\n",
    "        x.append(init_x)\n",
    "        y.append(init_y)\n",
    "    polygons=np.vstack(((x,y))).T\n",
    "    \n",
    "    x,y,w,h = cv2.boundingRect(polygons)\n",
    "    x_min=x\n",
    "    y_min=y\n",
    "    x_max=x+w\n",
    "    y_max=y+h\n",
    "    return x_min,y_min,x_max,y_max\n",
    "    #return x_min,x_max,y_min,y_max\n",
    "for i in tqdm(range(0,len(df_all))):\n",
    "    #remove white spaces from image path\n",
    "   \n",
    "    df_all['img_path'][i]=re.sub(r\"\\s+\", \"\", df_all['img_path'][i]) # \\s matches all white spaces\n",
    "    outer_poly=df_all['Label'][i]['Outer Border']\n",
    "    inner_poly=df_all['raw_inner_poly'][i]#df['Label'][i]['inner flyable area']\n",
    "    if inner_poly and outer_poly:\n",
    "        df_all['outer_poly'][i] = convert_coordinates(outer_poly)\n",
    "        df_all['inner_poly'][i] = convert_coordinates_raw(inner_poly)\n",
    "        #df['inner_poly'][i] = convert_coordinates(inner_poly)\n",
    "\n",
    "        df_all['outer_x_min'][i],df_all['outer_y_min'][i], df_all['outer_x_max'][i],df_all['outer_y_max'][i]=get_bbox(outer_poly)\n",
    "        df_all['inner_x_min'][i],df_all['inner_y_min'][i], df_all['inner_x_max'][i],df_all['inner_y_max'][i]=get_bbox_raw_data(inner_poly)\n",
    "        #df_all['outer_x_min'][i],df_all['outer_x_max'][i], df_all['outer_y_min'][i],df_all['outer_y_max'][i]=get_bbox(outer_poly)\n",
    "        #df_all['inner_x_min'][i],df_all['inner_x_max'][i], df_all['inner_y_min'][i],df_all['inner_y_max'][i]=get_bbox_raw_data(inner_poly) \n",
    "    else:\n",
    "        print('corrupt data detected for index:', i )\n",
    "        continue\n",
    "    #df['outer_poly']= h\n",
    "   #df['inner_poly']= convert_coordinates(inner_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>img_path</th>\n",
       "      <th>Label</th>\n",
       "      <th>raw_inner_poly</th>\n",
       "      <th>outer_poly</th>\n",
       "      <th>inner_poly</th>\n",
       "      <th>outer_x_min</th>\n",
       "      <th>outer_y_min</th>\n",
       "      <th>outer_x_max</th>\n",
       "      <th>outer_y_max</th>\n",
       "      <th>inner_x_min</th>\n",
       "      <th>inner_y_min</th>\n",
       "      <th>inner_x_max</th>\n",
       "      <th>inner_y_max</th>\n",
       "      <th>class_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_0015.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((997 ...</td>\n",
       "      <td>[504, 191, 902, 177, 915, 580, 495, 584]</td>\n",
       "      <td>[(997, 65), (1014, 683), (402, 673), (416, 106)]</td>\n",
       "      <td>[(504, 191), (902, 177), (915, 580), (495, 584)]</td>\n",
       "      <td>402</td>\n",
       "      <td>65</td>\n",
       "      <td>1015</td>\n",
       "      <td>684</td>\n",
       "      <td>495</td>\n",
       "      <td>177</td>\n",
       "      <td>916</td>\n",
       "      <td>585</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_0158.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((894 ...</td>\n",
       "      <td>[454, 212, 803, 221, 808, 552, 454, 566]</td>\n",
       "      <td>[(894, 638), (375, 646), (383, 136), (882, 141)]</td>\n",
       "      <td>[(454, 212), (803, 221), (808, 552), (454, 566)]</td>\n",
       "      <td>375</td>\n",
       "      <td>136</td>\n",
       "      <td>895</td>\n",
       "      <td>647</td>\n",
       "      <td>454</td>\n",
       "      <td>212</td>\n",
       "      <td>809</td>\n",
       "      <td>567</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_0244.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((848 ...</td>\n",
       "      <td>[590, 376, 791, 371, 794, 589, 577, 601]</td>\n",
       "      <td>[(848, 312), (851, 649), (533, 639), (538, 328)]</td>\n",
       "      <td>[(590, 376), (791, 371), (794, 589), (577, 601)]</td>\n",
       "      <td>533</td>\n",
       "      <td>312</td>\n",
       "      <td>852</td>\n",
       "      <td>650</td>\n",
       "      <td>577</td>\n",
       "      <td>371</td>\n",
       "      <td>795</td>\n",
       "      <td>602</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_0367.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((597 ...</td>\n",
       "      <td>[836, 385, 641, 387, 635, 582, 841, 582]</td>\n",
       "      <td>[(597, 623), (880, 627), (881, 344), (603, 346)]</td>\n",
       "      <td>[(836, 385), (641, 387), (635, 582), (841, 582)]</td>\n",
       "      <td>597</td>\n",
       "      <td>344</td>\n",
       "      <td>882</td>\n",
       "      <td>628</td>\n",
       "      <td>635</td>\n",
       "      <td>385</td>\n",
       "      <td>842</td>\n",
       "      <td>583</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_0374.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((359 ...</td>\n",
       "      <td>[470, 221, 848, 231, 851, 613, 457, 609]</td>\n",
       "      <td>[(359, 703), (950, 711), (943, 141), (384, 128)]</td>\n",
       "      <td>[(470, 221), (848, 231), (851, 613), (457, 609)]</td>\n",
       "      <td>359</td>\n",
       "      <td>128</td>\n",
       "      <td>951</td>\n",
       "      <td>712</td>\n",
       "      <td>457</td>\n",
       "      <td>221</td>\n",
       "      <td>852</td>\n",
       "      <td>614</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         images                                           img_path  \\\n",
       "0  IMG_0015.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  IMG_0158.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  IMG_0244.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  IMG_0367.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  IMG_0374.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                                               Label  \\\n",
       "0  {'Outer Border': [{'geometry': 'POLYGON ((997 ...   \n",
       "1  {'Outer Border': [{'geometry': 'POLYGON ((894 ...   \n",
       "2  {'Outer Border': [{'geometry': 'POLYGON ((848 ...   \n",
       "3  {'Outer Border': [{'geometry': 'POLYGON ((597 ...   \n",
       "4  {'Outer Border': [{'geometry': 'POLYGON ((359 ...   \n",
       "\n",
       "                             raw_inner_poly  \\\n",
       "0  [504, 191, 902, 177, 915, 580, 495, 584]   \n",
       "1  [454, 212, 803, 221, 808, 552, 454, 566]   \n",
       "2  [590, 376, 791, 371, 794, 589, 577, 601]   \n",
       "3  [836, 385, 641, 387, 635, 582, 841, 582]   \n",
       "4  [470, 221, 848, 231, 851, 613, 457, 609]   \n",
       "\n",
       "                                         outer_poly  \\\n",
       "0  [(997, 65), (1014, 683), (402, 673), (416, 106)]   \n",
       "1  [(894, 638), (375, 646), (383, 136), (882, 141)]   \n",
       "2  [(848, 312), (851, 649), (533, 639), (538, 328)]   \n",
       "3  [(597, 623), (880, 627), (881, 344), (603, 346)]   \n",
       "4  [(359, 703), (950, 711), (943, 141), (384, 128)]   \n",
       "\n",
       "                                         inner_poly outer_x_min outer_y_min  \\\n",
       "0  [(504, 191), (902, 177), (915, 580), (495, 584)]         402          65   \n",
       "1  [(454, 212), (803, 221), (808, 552), (454, 566)]         375         136   \n",
       "2  [(590, 376), (791, 371), (794, 589), (577, 601)]         533         312   \n",
       "3  [(836, 385), (641, 387), (635, 582), (841, 582)]         597         344   \n",
       "4  [(470, 221), (848, 231), (851, 613), (457, 609)]         359         128   \n",
       "\n",
       "  outer_x_max outer_y_max inner_x_min inner_y_min inner_x_max inner_y_max  \\\n",
       "0        1015         684         495         177         916         585   \n",
       "1         895         647         454         212         809         567   \n",
       "2         852         650         577         371         795         602   \n",
       "3         882         628         635         385         842         583   \n",
       "4         951         712         457         221         852         614   \n",
       "\n",
       "  class_id  \n",
       "0           \n",
       "1           \n",
       "2           \n",
       "3           \n",
       "4           "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>outer_x_min</th>\n",
       "      <th>outer_y_min</th>\n",
       "      <th>outer_x_max</th>\n",
       "      <th>outer_y_max</th>\n",
       "      <th>outer_poly</th>\n",
       "      <th>class_id_x</th>\n",
       "      <th>inner_x_min</th>\n",
       "      <th>inner_y_min</th>\n",
       "      <th>inner_x_max</th>\n",
       "      <th>inner_y_max</th>\n",
       "      <th>inner_poly</th>\n",
       "      <th>class_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>402</td>\n",
       "      <td>65</td>\n",
       "      <td>1015</td>\n",
       "      <td>684</td>\n",
       "      <td>[(997, 65), (1014, 683), (402, 673), (416, 106)]</td>\n",
       "      <td>0</td>\n",
       "      <td>495</td>\n",
       "      <td>177</td>\n",
       "      <td>916</td>\n",
       "      <td>585</td>\n",
       "      <td>[(504, 191), (902, 177), (915, 580), (495, 584)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>375</td>\n",
       "      <td>136</td>\n",
       "      <td>895</td>\n",
       "      <td>647</td>\n",
       "      <td>[(894, 638), (375, 646), (383, 136), (882, 141)]</td>\n",
       "      <td>0</td>\n",
       "      <td>454</td>\n",
       "      <td>212</td>\n",
       "      <td>809</td>\n",
       "      <td>567</td>\n",
       "      <td>[(454, 212), (803, 221), (808, 552), (454, 566)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>533</td>\n",
       "      <td>312</td>\n",
       "      <td>852</td>\n",
       "      <td>650</td>\n",
       "      <td>[(848, 312), (851, 649), (533, 639), (538, 328)]</td>\n",
       "      <td>0</td>\n",
       "      <td>577</td>\n",
       "      <td>371</td>\n",
       "      <td>795</td>\n",
       "      <td>602</td>\n",
       "      <td>[(590, 376), (791, 371), (794, 589), (577, 601)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>597</td>\n",
       "      <td>344</td>\n",
       "      <td>882</td>\n",
       "      <td>628</td>\n",
       "      <td>[(597, 623), (880, 627), (881, 344), (603, 346)]</td>\n",
       "      <td>0</td>\n",
       "      <td>635</td>\n",
       "      <td>385</td>\n",
       "      <td>842</td>\n",
       "      <td>583</td>\n",
       "      <td>[(836, 385), (641, 387), (635, 582), (841, 582)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>359</td>\n",
       "      <td>128</td>\n",
       "      <td>951</td>\n",
       "      <td>712</td>\n",
       "      <td>[(359, 703), (950, 711), (943, 141), (384, 128)]</td>\n",
       "      <td>0</td>\n",
       "      <td>457</td>\n",
       "      <td>221</td>\n",
       "      <td>852</td>\n",
       "      <td>614</td>\n",
       "      <td>[(470, 221), (848, 231), (851, 613), (457, 609)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path outer_x_min outer_y_min  \\\n",
       "0  /media/a/D/lockheed-martin/dataset/LM_dataset/...         402          65   \n",
       "1  /media/a/D/lockheed-martin/dataset/LM_dataset/...         375         136   \n",
       "2  /media/a/D/lockheed-martin/dataset/LM_dataset/...         533         312   \n",
       "3  /media/a/D/lockheed-martin/dataset/LM_dataset/...         597         344   \n",
       "4  /media/a/D/lockheed-martin/dataset/LM_dataset/...         359         128   \n",
       "\n",
       "  outer_x_max outer_y_max                                        outer_poly  \\\n",
       "0        1015         684  [(997, 65), (1014, 683), (402, 673), (416, 106)]   \n",
       "1         895         647  [(894, 638), (375, 646), (383, 136), (882, 141)]   \n",
       "2         852         650  [(848, 312), (851, 649), (533, 639), (538, 328)]   \n",
       "3         882         628  [(597, 623), (880, 627), (881, 344), (603, 346)]   \n",
       "4         951         712  [(359, 703), (950, 711), (943, 141), (384, 128)]   \n",
       "\n",
       "   class_id_x inner_x_min inner_y_min inner_x_max inner_y_max  \\\n",
       "0           0         495         177         916         585   \n",
       "1           0         454         212         809         567   \n",
       "2           0         577         371         795         602   \n",
       "3           0         635         385         842         583   \n",
       "4           0         457         221         852         614   \n",
       "\n",
       "                                         inner_poly  class_id_y  \n",
       "0  [(504, 191), (902, 177), (915, 580), (495, 584)]           1  \n",
       "1  [(454, 212), (803, 221), (808, 552), (454, 566)]           1  \n",
       "2  [(590, 376), (791, 371), (794, 589), (577, 601)]           1  \n",
       "3  [(836, 385), (641, 387), (635, 582), (841, 582)]           1  \n",
       "4  [(470, 221), (848, 231), (851, 613), (457, 609)]           1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#keep only filed required by yolov3. Divide the dataframe into outer and inner bounding boxes and then assign a class to each one of them \n",
    "keep_cols_outer=['img_path', 'outer_x_min', 'outer_y_min', 'outer_x_max', 'outer_y_max','outer_poly','class_id']\n",
    "keep_cols_inner=['img_path', 'inner_x_min', 'inner_y_min', 'inner_x_max', 'inner_y_max', 'inner_poly','class_id']\n",
    "df_outer=df_all[keep_cols_outer]\n",
    "df_inner=df_all[keep_cols_inner]\n",
    "df_outer['class_id']=0\n",
    "df_inner['class_id']=1\n",
    "df_enet=pd.merge(df_outer, df_inner, on='img_path')\n",
    "df_enet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "outer poly [(997, 65), (1014, 683), (402, 673), (416, 106)]\n",
      "inner_poly [(504, 191), (902, 177), (915, 580), (495, 584)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# testing annotation all together \n",
    "\n",
    "def get_mask(img_shape, poly,display=False):\n",
    "     \n",
    "\n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "    polygons = []\n",
    "    for pt in poly:\n",
    "        a = (int(pt[0]), int(pt[1]))\n",
    "        polygons.append(a)\n",
    "    \n",
    "    draw.polygon(xy=polygons, outline=1, fill=1)\n",
    "    mask = np.array(mask, dtype=bool)\n",
    "    if display:\n",
    "        plt.imshow(mask)\n",
    "        plt.show\n",
    "    return mask\n",
    "#getting the final mask\n",
    "\n",
    "for i in range(0,1):#len(df)): # use one image only for testing\n",
    "\n",
    "    img=cv2.imread(df_enet['img_path'][i])\n",
    "    row=img.shape[0]\n",
    "    col=img.shape[1]\n",
    "    img_shape = (row,col)\n",
    "    outer_poly=df_enet['outer_poly'][i] \n",
    "    print('outer poly',outer_poly)\n",
    "    inner_poly=df_enet['inner_poly'][i]\n",
    "    print('inner_poly', list(inner_poly))\n",
    "    outer_mask=get_mask(img_shape,outer_poly,display=False)\n",
    "    inner_mask=get_mask(img_shape,inner_poly,display=False)\n",
    "    inner_mask.dtype='uint8'\n",
    "    outer_mask.dtype='uint8'\n",
    "    final_mask=cv2.subtract(outer_mask,inner_mask)\n",
    "    plt.imshow(cv2.bitwise_and(img,img,mask=final_mask))\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2534\n"
     ]
    }
   ],
   "source": [
    "print(len(df_enet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the ENet model\n",
    "We decided to to split the model to three sub classes:\n",
    "\n",
    "1) Initial block\n",
    "\n",
    "2) RDDNeck - class for regular, downsampling and dilated bottlenecks\n",
    "\n",
    "3) ASNeck - class for asymetric bottlenecks\n",
    "\n",
    "4) UBNeck - class for upsampling bottlenecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InitialBlock(nn.Module):\n",
    "  \n",
    "  # Initial block of the model:\n",
    "  #         Input\n",
    "  #        /     \\\n",
    "  #       /       \\\n",
    "  #maxpool2d    conv2d-3x3\n",
    "  #       \\       /  \n",
    "  #        \\     /\n",
    "  #      concatenate\n",
    "   \n",
    "    def __init__ (self,in_channels = 3,out_channels = 13):\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, \n",
    "                                      stride = 2, \n",
    "                                      padding = 0)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, \n",
    "                                out_channels,\n",
    "                                kernel_size = 3,\n",
    "                                stride = 2, \n",
    "                                padding = 1)\n",
    "\n",
    "        self.prelu = nn.PReLU(16)\n",
    "\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "  \n",
    "    def forward(self, x):\n",
    "        \n",
    "        main = self.conv(x)\n",
    "        main = self.batchnorm(main)\n",
    "        \n",
    "        side = self.maxpool(x)\n",
    "        \n",
    "        # concatenating on the channels axis\n",
    "        x = torch.cat((main, side), dim=1)\n",
    "        x = self.prelu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UBNeck(nn.Module):\n",
    "    \n",
    "  # Upsampling bottleneck:\n",
    "  #     Bottleneck Input\n",
    "  #        /        \\\n",
    "  #       /          \\\n",
    "  # conv2d-1x1     convTrans2d-1x1\n",
    "  #      |             | PReLU\n",
    "  #      |         convTrans2d-3x3\n",
    "  #      |             | PReLU\n",
    "  #      |         convTrans2d-1x1\n",
    "  #      |             |\n",
    "  # maxunpool2d    Regularizer\n",
    "  #       \\           /  \n",
    "  #        \\         /\n",
    "  #      Summing + PReLU\n",
    "  #\n",
    "  #  Params: \n",
    "  #  projection_ratio - ratio between input and output channels\n",
    "  #  relu - if True: relu used as the activation function else: Prelu us used\n",
    "  \n",
    "    def __init__(self, in_channels, out_channels, relu=False, projection_ratio=4):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        self.in_channels = in_channels\n",
    "        self.reduced_depth = int(in_channels / projection_ratio)\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        \n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "        \n",
    "        self.unpool = nn.MaxUnpool2d(kernel_size = 2,\n",
    "                                     stride = 2)\n",
    "        \n",
    "        self.main_conv = nn.Conv2d(in_channels = self.in_channels,\n",
    "                                    out_channels = self.out_channels,\n",
    "                                    kernel_size = 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        \n",
    "        \n",
    "        self.convt1 = nn.ConvTranspose2d(in_channels = self.in_channels,\n",
    "                               out_channels = self.reduced_depth,\n",
    "                               kernel_size = 1,\n",
    "                               padding = 0,\n",
    "                               bias = False)\n",
    "        \n",
    "        \n",
    "        self.prelu1 = activation\n",
    "        \n",
    "        # This layer used for Upsampling\n",
    "        self.convt2 = nn.ConvTranspose2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.reduced_depth,\n",
    "                                  kernel_size = 3,\n",
    "                                  stride = 2,\n",
    "                                  padding = 1,\n",
    "                                  output_padding = 1,\n",
    "                                  bias = False)\n",
    "        \n",
    "        self.prelu2 = activation\n",
    "        \n",
    "        self.convt3 = nn.ConvTranspose2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.out_channels,\n",
    "                                  kernel_size = 1,\n",
    "                                  padding = 0,\n",
    "                                  bias = False)\n",
    "        \n",
    "        self.prelu3 = activation\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "    def forward(self, x, indices):\n",
    "        x_copy = x\n",
    "        \n",
    "        # Side Branch\n",
    "        x = self.convt1(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu1(x)\n",
    "        \n",
    "        x = self.convt2(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu2(x)\n",
    "        \n",
    "        x = self.convt3(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Main Branch\n",
    "        \n",
    "        x_copy = self.main_conv(x_copy)\n",
    "        x_copy = self.unpool(x_copy, indices, output_size=x.size())\n",
    "        \n",
    "        # summing the main and side branches\n",
    "        x = x + x_copy\n",
    "        x = self.prelu3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RDDNeck(nn.Module):\n",
    "    def __init__(self, dilation, in_channels, out_channels, down_flag, relu=False, projection_ratio=4, p=0.1):\n",
    "      \n",
    "  # Regular|Dilated|Downsampling bottlenecks:\n",
    "  #\n",
    "  #     Bottleneck Input\n",
    "  #        /        \\\n",
    "  #       /          \\\n",
    "  # maxpooling2d   conv2d-1x1\n",
    "  #      |             | PReLU\n",
    "  #      |         conv2d-3x3\n",
    "  #      |             | PReLU\n",
    "  #      |         conv2d-1x1\n",
    "  #      |             |\n",
    "  #  Padding2d     Regularizer\n",
    "  #       \\           /  \n",
    "  #        \\         /\n",
    "  #      Summing + PReLU\n",
    "  #\n",
    "  # Params: \n",
    "  #  dilation (bool) - if True: creating dilation bottleneck\n",
    "  #  down_flag (bool) - if True: creating downsampling bottleneck\n",
    "  #  projection_ratio - ratio between input and output channels\n",
    "  #  relu - if True: relu used as the activation function else: Prelu us used\n",
    "  #  p - dropout ratio\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        self.in_channels = in_channels\n",
    "        \n",
    "        self.out_channels = out_channels\n",
    "        self.dilation = dilation\n",
    "        self.down_flag = down_flag\n",
    "        \n",
    "        # calculating the number of reduced channels\n",
    "        if down_flag:\n",
    "            self.stride = 2\n",
    "            self.reduced_depth = int(in_channels // projection_ratio)\n",
    "        else:\n",
    "            self.stride = 1\n",
    "            self.reduced_depth = int(out_channels // projection_ratio)\n",
    "        \n",
    "        if relu:\n",
    "            activation = nn.ReLU()\n",
    "        else:\n",
    "            activation = nn.PReLU()\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 2,\n",
    "                                      stride = 2,\n",
    "                                      padding = 0, return_indices=True)\n",
    "        \n",
    "\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(p=p)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels = self.in_channels,\n",
    "                               out_channels = self.reduced_depth,\n",
    "                               kernel_size = 1,\n",
    "                               stride = 1,\n",
    "                               padding = 0,\n",
    "                               bias = False,\n",
    "                               dilation = 1)\n",
    "        \n",
    "        self.prelu1 = activation\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.reduced_depth,\n",
    "                                  kernel_size = 3,\n",
    "                                  stride = self.stride,\n",
    "                                  padding = self.dilation,\n",
    "                                  bias = True,\n",
    "                                  dilation = self.dilation)\n",
    "                                  \n",
    "        self.prelu2 = activation\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.out_channels,\n",
    "                                  kernel_size = 1,\n",
    "                                  stride = 1,\n",
    "                                  padding = 0,\n",
    "                                  bias = False,\n",
    "                                  dilation = 1)\n",
    "        \n",
    "        self.prelu3 = activation\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        bs = x.size()[0]\n",
    "        x_copy = x\n",
    "        \n",
    "        # Side Branch\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu1(x)\n",
    "        \n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm2(x)\n",
    "                \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Main Branch\n",
    "        if self.down_flag:\n",
    "            x_copy, indices = self.maxpool(x_copy)\n",
    "          \n",
    "        if self.in_channels != self.out_channels:\n",
    "            out_shape = self.out_channels - self.in_channels\n",
    "            \n",
    "            #padding and concatenating in order to match the channels axis of the side and main branches\n",
    "            extras = torch.zeros((bs, out_shape, x.shape[2], x.shape[3]))\n",
    "            if torch.cuda.is_available():\n",
    "                extras = extras.cuda()\n",
    "            x_copy = torch.cat((x_copy, extras), dim = 1)\n",
    "\n",
    "        # Summing main and side branches\n",
    "        x = x + x_copy\n",
    "        x = self.prelu3(x)\n",
    "        \n",
    "        if self.down_flag:\n",
    "            return x, indices\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ASNeck(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, projection_ratio=4):\n",
    "      \n",
    "  # Asymetric bottleneck:\n",
    "  #\n",
    "  #     Bottleneck Input\n",
    "  #        /        \\\n",
    "  #       /          \\\n",
    "  #      |         conv2d-1x1\n",
    "  #      |             | PReLU\n",
    "  #      |         conv2d-1x5\n",
    "  #      |             |\n",
    "  #      |         conv2d-5x1\n",
    "  #      |             | PReLU\n",
    "  #      |         conv2d-1x1\n",
    "  #      |             |\n",
    "  #  Padding2d     Regularizer\n",
    "  #       \\           /  \n",
    "  #        \\         /\n",
    "  #      Summing + PReLU\n",
    "  #\n",
    "  # Params:    \n",
    "  #  projection_ratio - ratio between input and output channels\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        self.in_channels = in_channels\n",
    "        self.reduced_depth = int(in_channels / projection_ratio)\n",
    "        self.out_channels = out_channels\n",
    "        \n",
    "        self.dropout = nn.Dropout2d(p=0.1)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = self.in_channels,\n",
    "                               out_channels = self.reduced_depth,\n",
    "                               kernel_size = 1,\n",
    "                               stride = 1,\n",
    "                               padding = 0,\n",
    "                               bias = False)\n",
    "        \n",
    "        self.prelu1 = nn.PReLU()\n",
    "        \n",
    "        self.conv21 = nn.Conv2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.reduced_depth,\n",
    "                                  kernel_size = (1, 5),\n",
    "                                  stride = 1,\n",
    "                                  padding = (0, 2),\n",
    "                                  bias = False)\n",
    "        \n",
    "        self.conv22 = nn.Conv2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.reduced_depth,\n",
    "                                  kernel_size = (5, 1),\n",
    "                                  stride = 1,\n",
    "                                  padding = (2, 0),\n",
    "                                  bias = False)\n",
    "        \n",
    "        self.prelu2 = nn.PReLU()\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels = self.reduced_depth,\n",
    "                                  out_channels = self.out_channels,\n",
    "                                  kernel_size = 1,\n",
    "                                  stride = 1,\n",
    "                                  padding = 0,\n",
    "                                  bias = False)\n",
    "        \n",
    "        self.prelu3 = nn.PReLU()\n",
    "        \n",
    "        self.batchnorm = nn.BatchNorm2d(self.reduced_depth)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(self.out_channels)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        bs = x.size()[0]\n",
    "        x_copy = x\n",
    "        \n",
    "        # Side Branch\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu1(x)\n",
    "        \n",
    "        x = self.conv21(x)\n",
    "        x = self.conv22(x)\n",
    "        x = self.batchnorm(x)\n",
    "        x = self.prelu2(x)\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "                \n",
    "        x = self.dropout(x)\n",
    "        x = self.batchnorm2(x)\n",
    "        \n",
    "        # Main Branch\n",
    "        \n",
    "        if self.in_channels != self.out_channels:\n",
    "            out_shape = self.out_channels - self.in_channels\n",
    "            \n",
    "            #padding and concatenating in order to match the channels axis of the side and main branches\n",
    "            extras = torch.zeros((bs, out_shape, x.shape[2], x.shape[3]))\n",
    "            if torch.cuda.is_available():\n",
    "                extras = extras.cuda()\n",
    "            x_copy = torch.cat((x_copy, extras), dim = 1)\n",
    "        \n",
    "        # Summing main and side branches\n",
    "        x = x + x_copy\n",
    "        x = self.prelu3(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ENet(nn.Module):\n",
    "  \n",
    "  # Creating Enet model!\n",
    "  \n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        \n",
    "        # Define class variables\n",
    "        # C - number of classes\n",
    "        self.C = C\n",
    "        \n",
    "        # The initial block\n",
    "        self.init = InitialBlock()\n",
    "        \n",
    "        \n",
    "        # The first bottleneck\n",
    "        self.b10 = RDDNeck(dilation=1, \n",
    "                           in_channels=16, \n",
    "                           out_channels=64, \n",
    "                           down_flag=True, \n",
    "                           p=0.01)\n",
    "        \n",
    "        self.b11 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           p=0.01)\n",
    "        \n",
    "        self.b12 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           p=0.01)\n",
    "        \n",
    "        self.b13 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           p=0.01)\n",
    "        \n",
    "        self.b14 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           p=0.01)\n",
    "        \n",
    "        \n",
    "        # The second bottleneck\n",
    "        self.b20 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=128, \n",
    "                           down_flag=True)\n",
    "        \n",
    "        self.b21 = RDDNeck(dilation=1, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b22 = RDDNeck(dilation=2, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b23 = ASNeck(in_channels=128, \n",
    "                          out_channels=128)\n",
    "        \n",
    "        self.b24 = RDDNeck(dilation=4, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b25 = RDDNeck(dilation=1, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b26 = RDDNeck(dilation=8, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b27 = ASNeck(in_channels=128, \n",
    "                          out_channels=128)\n",
    "        \n",
    "        self.b28 = RDDNeck(dilation=16, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        \n",
    "        # The third bottleneck\n",
    "        self.b31 = RDDNeck(dilation=1, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b32 = RDDNeck(dilation=2, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b33 = ASNeck(in_channels=128, \n",
    "                          out_channels=128)\n",
    "        \n",
    "        self.b34 = RDDNeck(dilation=4, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b35 = RDDNeck(dilation=1, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b36 = RDDNeck(dilation=8, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        self.b37 = ASNeck(in_channels=128, \n",
    "                          out_channels=128)\n",
    "        \n",
    "        self.b38 = RDDNeck(dilation=16, \n",
    "                           in_channels=128, \n",
    "                           out_channels=128, \n",
    "                           down_flag=False)\n",
    "        \n",
    "        \n",
    "        # The fourth bottleneck\n",
    "        self.b40 = UBNeck(in_channels=128, \n",
    "                          out_channels=64, \n",
    "                          relu=True)\n",
    "        \n",
    "        self.b41 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           relu=True)\n",
    "        \n",
    "        self.b42 = RDDNeck(dilation=1, \n",
    "                           in_channels=64, \n",
    "                           out_channels=64, \n",
    "                           down_flag=False, \n",
    "                           relu=True)\n",
    "        \n",
    "        \n",
    "        # The fifth bottleneck\n",
    "        self.b50 = UBNeck(in_channels=64, \n",
    "                          out_channels=16, \n",
    "                          relu=True)\n",
    "        \n",
    "        self.b51 = RDDNeck(dilation=1, \n",
    "                           in_channels=16, \n",
    "                           out_channels=16, \n",
    "                           down_flag=False, \n",
    "                           relu=True)\n",
    "        \n",
    "        \n",
    "        # Final ConvTranspose Layer\n",
    "        self.fullconv = nn.ConvTranspose2d(in_channels=16, \n",
    "                                           out_channels=self.C, \n",
    "                                           kernel_size=3, \n",
    "                                           stride=2, \n",
    "                                           padding=1, \n",
    "                                           output_padding=1,\n",
    "                                           bias=False)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # The initial block\n",
    "        x = self.init(x)\n",
    "        \n",
    "        # The first bottleneck\n",
    "        x, i1 = self.b10(x)\n",
    "        x = self.b11(x)\n",
    "        x = self.b12(x)\n",
    "        x = self.b13(x)\n",
    "        x = self.b14(x)\n",
    "        \n",
    "        # The second bottleneck\n",
    "        x, i2 = self.b20(x)\n",
    "        x = self.b21(x)\n",
    "        x = self.b22(x)\n",
    "        x = self.b23(x)\n",
    "        x = self.b24(x)\n",
    "        x = self.b25(x)\n",
    "        x = self.b26(x)\n",
    "        x = self.b27(x)\n",
    "        x = self.b28(x)\n",
    "        \n",
    "        # The third bottleneck\n",
    "        x = self.b31(x)\n",
    "        x = self.b32(x)\n",
    "        x = self.b33(x)\n",
    "        x = self.b34(x)\n",
    "        x = self.b35(x)\n",
    "        x = self.b36(x)\n",
    "        x = self.b37(x)\n",
    "        x = self.b38(x)\n",
    "        \n",
    "        # The fourth bottleneck\n",
    "        x = self.b40(x, i2)\n",
    "        x = self.b41(x)\n",
    "        x = self.b42(x)\n",
    "        \n",
    "        # The fifth bottleneck\n",
    "        x = self.b50(x, i1)\n",
    "        x = self.b51(x)\n",
    "        \n",
    "        # Final ConvTranspose Layer\n",
    "        x = self.fullconv(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate the ENet model\n",
    "enet = ENet(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if there is any gpu available and pass the model to gpu or cpu\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "enet = enet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(864, 1296, 3)\n"
     ]
    }
   ],
   "source": [
    "img = plt.imread(df_enet['img_path'][8])\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a generater\n",
    "def loader(df, batch_size, im_size=(512,512)):\n",
    "    total_files_s=len(df)\n",
    "    if str(batch_size).lower() == 'all':\n",
    "        batch_size = total_files_s\n",
    "    idx = 0\n",
    "    while(1):\n",
    "      # Choosing random indexes of images and labels\n",
    "        batch_idxs = np.random.randint(0, total_files_s, batch_size)\n",
    "   \n",
    "        \n",
    "        inputs = []\n",
    "        labels = []\n",
    "        \n",
    "        for jj in batch_idxs:\n",
    "          # Reading normalized photo\n",
    "        \n",
    " \n",
    "            img = plt.imread(df['img_path'][jj])\n",
    "            \n",
    "          # Resizing using nearest neighbor method\n",
    "            \n",
    "            img = cv2.resize(img, (im_size[0], im_size[1]), cv2.INTER_NEAREST)\n",
    "            inputs.append(img)\n",
    "          \n",
    "          # creating semantic mask \n",
    "            outer_poly=df['outer_poly'][jj] \n",
    "            #print('outer poly',outer_poly)\n",
    "            inner_poly=df['inner_poly'][jj]\n",
    "            #print('inner_poly', list(inner_poly))\n",
    "            outer_mask=get_mask((im_size[0], im_size[1]),outer_poly,display=False)\n",
    "            inner_mask=get_mask((im_size[0], im_size[1]),inner_poly,display=False)\n",
    "            inner_mask.dtype='uint8'\n",
    "            outer_mask.dtype='uint8'\n",
    "            final_mask=cv2.subtract(outer_mask,inner_mask)\n",
    "          # Resizing using nearest neighbor method\n",
    "            #img = cv2.resize(img, (h, w), cv2.INTER_NEAREST)\n",
    "            labels.append(final_mask)\n",
    "         \n",
    "        inputs = np.stack(inputs, axis=2)\n",
    "      # Changing image format to C x H x W\n",
    "        inputs = torch.tensor(inputs).transpose(0, 2).transpose(1, 3)\n",
    "        \n",
    "        labels = torch.tensor(labels)\n",
    "        \n",
    "        yield inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test the generater\n",
    "batch_size=1\n",
    "training_gen=loader(df_enet, batch_size)\n",
    "batch_img,batch_mask = next(training_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(num_classes, c=1.02):\n",
    "    pipe = loader(df_enet, batch_size='all')\n",
    "    _, labels = next(pipe)\n",
    "    all_labels = labels.flatten()\n",
    "    each_class = np.bincount(all_labels, minlength=num_classes)\n",
    "    prospensity_score = each_class / len(all_labels)\n",
    "    class_weights = 1 / (np.log(c + prospensity_score))\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights = get_class_weights(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.46941647  15.86715257]\n"
     ]
    }
   ],
   "source": [
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 5e-4\n",
    "batch_size = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor(class_weights).to(device))\n",
    "optimizer = torch.optim.Adam(enet.parameters(), \n",
    "                             lr=lr,\n",
    "                             weight_decay=2e-4)\n",
    "\n",
    "print_every = 10\n",
    "eval_every = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2534\n"
     ]
    }
   ],
   "source": [
    "print(len(df_enet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2280\n",
      "254\n"
     ]
    }
   ],
   "source": [
    "#splitting the dataset into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_trn, df_tst = train_test_split(df_enet, test_size=0.1)\n",
    "print(len(df_trn))\n",
    "print(len(df_tst))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>outer_x_min</th>\n",
       "      <th>outer_y_min</th>\n",
       "      <th>outer_x_max</th>\n",
       "      <th>outer_y_max</th>\n",
       "      <th>outer_poly</th>\n",
       "      <th>class_id_x</th>\n",
       "      <th>inner_x_min</th>\n",
       "      <th>inner_y_min</th>\n",
       "      <th>inner_x_max</th>\n",
       "      <th>inner_y_max</th>\n",
       "      <th>inner_poly</th>\n",
       "      <th>class_id_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>560</td>\n",
       "      <td>340</td>\n",
       "      <td>790</td>\n",
       "      <td>589</td>\n",
       "      <td>[(560, 357), (787, 340), (789, 588), (564, 587)]</td>\n",
       "      <td>0</td>\n",
       "      <td>599</td>\n",
       "      <td>381</td>\n",
       "      <td>754</td>\n",
       "      <td>548</td>\n",
       "      <td>[(601, 392), (753, 381), (753, 546), (599, 547)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>447</td>\n",
       "      <td>191</td>\n",
       "      <td>841</td>\n",
       "      <td>642</td>\n",
       "      <td>[(447, 191), (840, 220), (840, 614), (451, 641)]</td>\n",
       "      <td>0</td>\n",
       "      <td>504</td>\n",
       "      <td>264</td>\n",
       "      <td>776</td>\n",
       "      <td>553</td>\n",
       "      <td>[(516, 264), (775, 267), (768, 544), (504, 552)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>286</td>\n",
       "      <td>158</td>\n",
       "      <td>833</td>\n",
       "      <td>707</td>\n",
       "      <td>[(289, 158), (823, 164), (832, 696), (286, 706)]</td>\n",
       "      <td>0</td>\n",
       "      <td>374</td>\n",
       "      <td>254</td>\n",
       "      <td>745</td>\n",
       "      <td>619</td>\n",
       "      <td>[(376, 254), (741, 254), (744, 613), (374, 618)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>544</td>\n",
       "      <td>390</td>\n",
       "      <td>691</td>\n",
       "      <td>637</td>\n",
       "      <td>[(544, 418), (687, 390), (690, 636), (546, 627)]</td>\n",
       "      <td>0</td>\n",
       "      <td>573</td>\n",
       "      <td>435</td>\n",
       "      <td>659</td>\n",
       "      <td>591</td>\n",
       "      <td>[(573, 447), (658, 435), (658, 590), (577, 590)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>565</td>\n",
       "      <td>292</td>\n",
       "      <td>802</td>\n",
       "      <td>658</td>\n",
       "      <td>[(567, 292), (797, 333), (801, 634), (565, 657)]</td>\n",
       "      <td>0</td>\n",
       "      <td>604</td>\n",
       "      <td>355</td>\n",
       "      <td>768</td>\n",
       "      <td>595</td>\n",
       "      <td>[(608, 355), (767, 374), (763, 577), (604, 594)]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            img_path outer_x_min outer_y_min  \\\n",
       "0  /media/a/D/lockheed-martin/dataset/LM_dataset/...         560         340   \n",
       "1  /media/a/D/lockheed-martin/dataset/LM_dataset/...         447         191   \n",
       "2  /media/a/D/lockheed-martin/dataset/LM_dataset/...         286         158   \n",
       "3  /media/a/D/lockheed-martin/dataset/LM_dataset/...         544         390   \n",
       "4  /media/a/D/lockheed-martin/dataset/LM_dataset/...         565         292   \n",
       "\n",
       "  outer_x_max outer_y_max                                        outer_poly  \\\n",
       "0         790         589  [(560, 357), (787, 340), (789, 588), (564, 587)]   \n",
       "1         841         642  [(447, 191), (840, 220), (840, 614), (451, 641)]   \n",
       "2         833         707  [(289, 158), (823, 164), (832, 696), (286, 706)]   \n",
       "3         691         637  [(544, 418), (687, 390), (690, 636), (546, 627)]   \n",
       "4         802         658  [(567, 292), (797, 333), (801, 634), (565, 657)]   \n",
       "\n",
       "   class_id_x inner_x_min inner_y_min inner_x_max inner_y_max  \\\n",
       "0           0         599         381         754         548   \n",
       "1           0         504         264         776         553   \n",
       "2           0         374         254         745         619   \n",
       "3           0         573         435         659         591   \n",
       "4           0         604         355         768         595   \n",
       "\n",
       "                                         inner_poly  class_id_y  \n",
       "0  [(601, 392), (753, 381), (753, 546), (599, 547)]           1  \n",
       "1  [(516, 264), (775, 267), (768, 544), (504, 552)]           1  \n",
       "2  [(376, 254), (741, 254), (744, 613), (374, 618)]           1  \n",
       "3  [(573, 447), (658, 435), (658, 590), (577, 590)]           1  \n",
       "4  [(608, 355), (767, 374), (763, 577), (604, 594)]           1  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_trn.reset_index(drop=True, inplace=True)\n",
    "df_tst.reset_index(drop=True, inplace=True)\n",
    "df_trn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- Epoch 1 ---------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [00:08<00:45,  1.86it/s]"
     ]
    }
   ],
   "source": [
    "train_losses = []\n",
    "eval_losses = []\n",
    "\n",
    "bc_train = 100# 1 // batch_size # mini_batch train\n",
    "bc_eval = 20# // batch_size  # mini_batch validation\n",
    "\n",
    "# Define pipeline objects\n",
    "pipe = loader(df_trn, batch_size)\n",
    "eval_pipe = loader(df_tst, batch_size)\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "# Train loop\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    \n",
    "    \n",
    "    train_loss = 0\n",
    "    print ('-'*15,'Epoch %d' % e, '-'*15)\n",
    "    \n",
    "    enet.train()\n",
    "    \n",
    "    for _ in tqdm(range(bc_train)):\n",
    "        X_batch, mask_batch = next(pipe)\n",
    "        \n",
    "        # assign data to cpu/gpu\n",
    "        X_batch, mask_batch = X_batch.to(device), mask_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = enet(X_batch.float())\n",
    "        #print(out.shape)\n",
    "        # loss calculation\n",
    "        loss = criterion(out, mask_batch.long())\n",
    "        # update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        \n",
    "    print ()\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    if (e+1) % print_every == 0:\n",
    "        print ('Epoch {}/{}...'.format(e, epochs),\n",
    "                'Loss {:6f}'.format(train_loss))\n",
    "    \n",
    "    if e % eval_every == 0:\n",
    "        with torch.no_grad():\n",
    "            enet.eval()\n",
    "            \n",
    "            eval_loss = 0\n",
    "\n",
    "            # Validation loop\n",
    "            for _ in tqdm(range(bc_eval)):\n",
    "                inputs, labels = next(eval_pipe)\n",
    "\n",
    "                \n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    \n",
    "                \n",
    "                out = enet(inputs)\n",
    "                \n",
    "                out = out.data.max(1)[1]\n",
    "                \n",
    "                eval_loss += (labels.long() - out.long()).sum()\n",
    "                \n",
    "            \n",
    "            print ()\n",
    "            print ('Loss {:6f}'.format(eval_loss))\n",
    "            \n",
    "            eval_losses.append(eval_loss)\n",
    "        \n",
    "    if e % print_every == 0:\n",
    "        checkpoint = {\n",
    "            'epochs' : e,\n",
    "            'state_dict' : enet.state_dict()\n",
    "        }\n",
    "        torch.save(checkpoint, 'ckpt-enet-{}-{}.pth'.format(e, train_loss))\n",
    "        print ('Model saved!')\n",
    "\n",
    "print ('Epoch {}/{}...'.format(e, epochs),\n",
    "       'Total Mean Loss: {:6f}'.format(sum(train_losses) / epochs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplearning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code for this part was adopted from https://github.com/YunYang1994/tensorflow-yolov3\n",
    "\n",
    "#I created 3 files for the training\n",
    "\n",
    "\n",
    "```\n",
    "/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates.names\n",
    "\n",
    "/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates.anchors\n",
    "\n",
    "/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_data.csv```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to generate the tf records for the training and testing dataset using the \n",
    "# following commands in shell\n",
    "\n",
    "# python /media/a/D/lockheed-martin/AlphaPilot_test2/object_segmentation_pipelines/tensorflow-yolov3/core/convert_tfrecord.py --dataset_txt /media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_data.csv --tfrecord_path_prefix gates_train\n",
    "# python /media/a/D/lockheed-martin/AlphaPilot_test2/object_segmentation_pipelines/tensorflow-yolov3/core/convert_tfrecord.py --dataset_txt /media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_data.csv --tfrecord_path_prefix gates_test\n",
    "# which yeilds\n",
    "#/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_train.tfrecords\n",
    "#/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_test.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and convert yolo weights from https://github.com/YunYang1994/tensorflow-yolov3/releases/download/v1.0/yolov3.weights\n",
    "#  python convert_weight.py --convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to read image. CV2 reads images in BGR and the simulator provides images in RGB. Therefore convert to \n",
    "#RGB domain\n",
    "def read_img(img):\n",
    "    img = cv2.imread(img)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "#Image brigtness changing method, based on Vivek Yadav's [2] approach for changing image brightness\n",
    "def brightness_images(img):\n",
    "    post_img = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    post_img[:,:,2] = np.multiply(post_img[:,:,2],random_bright)\n",
    "    post_img = cv2.cvtColor(post_img,cv2.COLOR_HSV2RGB)\n",
    "    return post_img\n",
    "# Another approach to adjust brightness used for experimentation \n",
    "def brightness_images_2(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  \n",
    "    h, s, v = cv2.split(hsv)\n",
    "    v += 255\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "# Resize the image to the givin dimensions \n",
    "def resize_img(image, col, row):\n",
    "    image = cv2.resize(image, (col,row), interpolation=cv2.INTER_AREA)\n",
    "    return image\n",
    "# Crop away the car hood from the orginal image  \n",
    "def crop_img(img):\n",
    "    shape = img.shape\n",
    "    img = img[0:shape[0]-20,0:shape[1]]\n",
    "    img = resize_img(img, 64, 64)\n",
    "    return img\n",
    "\n",
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "def gaussian_noise(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def transform(img):\n",
    "    imshape = img.shape\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    #src=np.float32([[160,imshape[0]],[imshape[1]/2-60, imshape[0]/2+90],[imshape[1]/2+100, imshape[0]/2+90], [imshape[1]-20,imshape[0]]])\n",
    "    #dst=np.float32([[(240,imshape[0]),(240, 0),(imshape[1]-130, 0), (imshape[1]-130,imshape[0])]])\n",
    "    src = np.float32([[490, 482],[810, 482],\n",
    "                     [1250, 720],[40, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    wraped =  cv2.warpPerspective(img,M,img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return  Minv, wraped\n",
    "\n",
    "\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "#Implement calibration on the images that will be used\n",
    "def undistort(img, read=True, display=True, write=False):\n",
    "\n",
    "# Test undistortion on an image\n",
    "    \n",
    "    if read:\n",
    "        img = cv2.imread(img)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "#img = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "    if write:\n",
    "        cv2.imwrite('Undistorted/test6.jpg',dst)\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "#dist_pickle = {}\n",
    "#dist_pickle[\"mtx\"] = mtx\n",
    "#dist_pickle[\"dist\"] = dist\n",
    "#pickle.dump( dist_pickle, open( \"calibration_wide/wide_dist_pickle.p\", \"wb\" ) )\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "    if display:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "        img_RGB=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax1.imshow(img_RGB)\n",
    "        ax1.set_title('Original Image', fontsize=30)\n",
    "        dst_RGB=cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "        ax2.imshow(dst_RGB)\n",
    "        ax2.set_title('Undistorted Image', fontsize=30)\n",
    "    else:\n",
    "        return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method to get the image and resize it if required\n",
    "def im_read(df,ID,resize = True, size=(640,300),augumentation=True, display=True):\n",
    "    #Return the index at which the image is first found in a list - Python\n",
    "    \n",
    "    file_name = df['File_Path'][ID]\n",
    "    #img = read_img(file_name)\n",
    "    img = cv2.imread(file_name)\n",
    "    img_size = np.shape(img)\n",
    "    #print(img_size )\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    if resize == True:\n",
    "        img = cv2.resize(img,size)\n",
    "    if augumentation == True:\n",
    "        img = brightness_images(img)\n",
    "    #str.split(str=\"\", num=string.count(str)).\n",
    "    img_name = df['Frame'][ID]#file_name.split('/',1)[1]\n",
    "    \n",
    "    bb_boxes = df[df['Frame'] == img_name].reset_index()\n",
    "    \n",
    "    img_size_post = np.shape(img)  \n",
    "    bb_boxes['xmin'] = np.round(bb_boxes['xmin']/img_size[1]*img_size_post[1])\n",
    "    bb_boxes['xmax'] = np.round(bb_boxes['xmax']/img_size[1]*img_size_post[1])\n",
    "    bb_boxes['ymin'] = np.round(bb_boxes['ymin']/img_size[0]*img_size_post[0])\n",
    "    bb_boxes['ymax'] = np.round(bb_boxes['ymax']/img_size[0]*img_size_post[0])\n",
    "    bb_boxes['Area'] = (bb_boxes['xmax']- bb_boxes['xmin'])*(bb_boxes['ymax']- bb_boxes['ymin'])\n",
    "   \n",
    "    if display == True:\n",
    "        plt.figure(figsize=(16,10))\n",
    "        plt.subplot(1,1,1)\n",
    "        plot_im_bbox(img,bb_boxes)\n",
    "    return img_name,img,bb_boxes\n",
    "\n",
    "def get_mask_seg(img,bb_boxes):\n",
    "    print(bb_boxes)\n",
    "    img_mask = np.zeros_like(img[:,:,0])\n",
    "    for i in range(len(bb_boxes)):\n",
    "        bb_box_i = [bb_boxes.iloc[i]['xmin'],bb_boxes.iloc[i]['ymin'],\n",
    "                bb_boxes.iloc[i]['xmax'],bb_boxes.iloc[i]['ymax']]\n",
    "        print(bb_box_i)\n",
    "        img_mask[int(bb_box_i[1]):int(bb_box_i[3]),int(bb_box_i[0]):int(bb_box_i[2])]= 1\n",
    "        img_mask = np.reshape(img_mask,(np.shape(img_mask)[0],np.shape(img_mask)[1],1))\n",
    "    return img_mask\n",
    "\n",
    "def plot_bbox(bb_boxes,ind_bb,color='r',linewidth=2):\n",
    "    bb_box_i = [bb_boxes.iloc[ind_bb]['xmin'],\n",
    "                bb_boxes.iloc[ind_bb]['ymin'],\n",
    "                bb_boxes.iloc[ind_bb]['xmax'],\n",
    "                bb_boxes.iloc[ind_bb]['ymax']]\n",
    "    plt.plot([bb_box_i[0],bb_box_i[2],bb_box_i[2],\n",
    "                  bb_box_i[0],bb_box_i[0]],\n",
    "             [bb_box_i[1],bb_box_i[1],bb_box_i[3],\n",
    "                  bb_box_i[3],bb_box_i[1]],\n",
    "             color,linewidth=linewidth)\n",
    "def plot_im_bbox(im,bb_boxes):\n",
    "    plt.imshow(im)\n",
    "    for i in range(len(bb_boxes)):\n",
    "        plot_bbox(bb_boxes,i,'g')\n",
    "\n",
    "        bb_box_i = [bb_boxes.iloc[i]['xmin'],bb_boxes.iloc[i]['ymin'],\n",
    "                bb_boxes.iloc[i]['xmax'],bb_boxes.iloc[i]['ymax']]\n",
    "    plt.axis('off'); \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_35GB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the mail function\n",
    "df=cars_35GB\n",
    "ID=660\n",
    "test_img_name,img,bb_boxes = im_read(cars_35GB,ID,resize = True, size=(640,300), augumentation=False, display = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test an image with it's bounding boxes\n",
    "#print (cars_15_35GB)\n",
    "df=cars_35GB\n",
    "ID=660\n",
    "test_img_name,img,bb_boxes = im_read(cars_35GB,ID,resize = True, size=(640,300), augumentation=False, display = False)\n",
    "img_masked = get_mask_seg(img,bb_boxes)\n",
    "print('img.shape',img.shape)\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.subplot(1,3,1)\n",
    "plot_im_bbox(img,bb_boxes)\n",
    "plt.title('Raw image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_masked[:,:,0])\n",
    "plt.title('Raw image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(cv2.bitwise_and(img,img,mask=img_masked))\n",
    "plt.title('Raw image')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_batch(data,batch_size):\n",
    "    #col=size[0]\n",
    "    #row=size[1]\n",
    "    batch_images = np.zeros((batch_size, row, col, 3))\n",
    "    #batch_steering = np.zeros(batch_size)\n",
    "    batch_masks = np.zeros((batch_size, row, col, 1))\n",
    "    training_batch = len(data)-100000\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            \n",
    "            process_line = np.random.randint(training_batch)\n",
    "            #generator_csv= data.iloc[[process_line]].reset_index()\n",
    "            #x,y = all_filters_train(generator_csv)\n",
    "            #print(data)\n",
    "            img_name,img,bb_boxes = im_read(data,process_line,resize = True, size=(col,row), augumentation=True, display = False)\n",
    "            img_masked = get_mask_seg(img,bb_boxes)\n",
    "            batch_images[i_batch] = img\n",
    "            batch_masks[i_batch] = img_masked\n",
    "        yield batch_images, batch_masks\n",
    "\n",
    "def generate_test_batch(data,batch_size):\n",
    "    batch_images = np.zeros((batch_size, row, col, 3))\n",
    "    #batch_steering = np.zeros(batch_size)\n",
    "    batch_masks = np.zeros((batch_size, row, col, 1))\n",
    "    training_batch = len(data)-100000\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            process_line = np.random.randint(training_batch)\n",
    "            process_line = process_line+training_batch\n",
    "            #generator_csv= data.iloc[[process_line]].reset_index()\n",
    "            #x,y = all_filters_train(generator_csv)\n",
    "            img_name,img,bb_boxes = im_read(data,process_line,resize = True, size=(col,row), augumentation=True, display = False)\n",
    "            img_masked = get_mask_seg(img,bb_boxes)\n",
    "            batch_images[i_batch] = img\n",
    "            batch_masks[i_batch] = img_masked\n",
    "        yield batch_images, batch_masks\n",
    "\"\"\"        \n",
    "def generate_validation_patch(data):\n",
    "    while 1:\n",
    "        for process_line in range(len(data)):\n",
    "            generator_csv = data.iloc[[process_line]].reset_index()\n",
    "            x = all_filters_validate(data)\n",
    "            x = x.reshape(1, x.shape[0], x.shape[1], x.shape[2])\n",
    "            y = generator_csv['steering'][0]\n",
    "            y = np.array([[y]])\n",
    "            yield x, y\n",
    "def save_model(fileModelJSON,fileWeights):\n",
    "    if Path(fileModelJSON).is_file():\n",
    "        os.remove(fileModelJSON)\n",
    "    json_string = model.to_json()\n",
    "    with open(fileModelJSON,'w' ) as f:\n",
    "        json.dump(json_string, f)\n",
    "    if Path(fileWeights).is_file():\n",
    "        os.remove(fileWeights)\n",
    "    model.save_weights(fileWeights)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 640\n",
    "col = 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for custom metrics\n",
    "#custom metrix source : https://keras.io/metrics/\n",
    "#Use this as a template\n",
    "#def mean_pred(y_true, y_pred):\n",
    "    #return K.mean(y_pred)\n",
    "\n",
    "#def false_rates(y_true, y_pred):\n",
    "    #false_neg = ...\n",
    "    #false_pos = ...\n",
    "    #return {\n",
    "        #'false_neg': false_neg,\n",
    "        #'false_pos': false_pos,\n",
    "    #}\n",
    "\n",
    "#model.compile(optimizer='rmsprop',\n",
    "              #loss='binary_crossentropy',\n",
    "             # metrics=['accuracy', mean_pred, false_rates])\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    # __author__ = Vladimir Iglovikov\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    # __author__ = Vladimir Iglovikov\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "#to do: fbeta_score(y_true, y_pred, beta=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras_yolov3_kitti.yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from keras_yolov3_kitti.yolo3.utils import get_random_data\n",
    "log_dir='logs'\n",
    "anchors_path = 'keras_yolov3_kitti/model_data/yolo_anchors.txt'\n",
    "classes_path = 'keras_yolov3_kitti/model_data/voc_classes.txt'\n",
    "num_classes=2#len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "input_shape =(300,640)\n",
    "is_tiny_version = len(anchors)==6 # default setting\n",
    "if is_tiny_version:\n",
    "    model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path='keras_yolov3_kitti/model_data/tiny_yolo_weights.h5')\n",
    "else:\n",
    "    model = create_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path='keras_yolov3_kitti/model_data/yolo_weights.h5') # make sure you know what you freeze\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "            # use custom yolo_loss Lambda layer.\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "batch_size = 32\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "                steps_per_epoch=max(1, num_train//batch_size),\n",
    "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "                validation_steps=max(1, num_val//batch_size),\n",
    "                epochs=25,\n",
    "                initial_epoch=0,\n",
    "                callbacks=[logging, checkpoint])\n",
    "model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "        print('Unfreeze all of the layers.')\n",
    "\n",
    "        batch_size = 4 # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=50,\n",
    "            initial_epoch=25,\n",
    "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        model.save_weights(log_dir + 'trained_weights_final.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing pipeline      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "heatmap_prev = np.zeros((640,960))\n",
    "heatmap_10 = [np.zeros((640,960))]*10\n",
    "def smooth_heatmap(heatmap):\n",
    "    #Credit Vive Yadav\n",
    "    # Smoothing heatmap as average of 10 previous frames\n",
    "    global heatmap_10\n",
    "    heatmap_10_1 = heatmap_10[1:]\n",
    "    heatmap_10_1.append(heatmap)\n",
    "    heatmap_10 = heatmap_10_1\n",
    "    heatmap = np.mean(heatmap_10,axis=0)\n",
    "    \n",
    "    #heatmap = heatmap_prev*.2 + heatmap*.8\n",
    "    #heatmap[heatmap>240] = 255\n",
    "    #heatmap[heatmap<240] = 0\n",
    "    return heatmap \n",
    " \n",
    "\n",
    "def next_img(img, resize=True):\n",
    "    if resize == True:\n",
    "        img = cv2.resize(img,(col,row))\n",
    "        img = np.reshape(img,(1,row, col,3))\n",
    "    pred = model.predict(img)\n",
    "    return pred,img[0]\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    \"\"\"Return image with bounding boxes drawn around the labelled regions.\n",
    "    \"\"\"\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        # increasing or reducing the sensetivity of bounding box noise\n",
    "        if ((np.max(nonzeroy)-np.min(nonzeroy)>70) & (np.max(nonzerox)-np.min(nonzerox)>70)):\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))      \n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255),6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def get_BB_new_img(img):\n",
    "    # Take in RGB image\n",
    "    pred,img = next_img(img)\n",
    "    img  = np.array(img,dtype= np.uint8)\n",
    "    img_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    heatmap = im_pred[:,:,0]\n",
    "    #Create an image with some features, then label it using the default (cross-shaped) structuring element:\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    return draw_img\n",
    "\n",
    "def get_labeled_bboxes(img, labels):\n",
    "    # Get labeled boxex\n",
    "    bbox_all = []\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        \n",
    "        # Define a bounding box based on min/max x and y\n",
    "        if ((np.max(nonzeroy)-np.min(nonzeroy)> 40) & (np.max(nonzerox)-np.min(nonzerox)> 40)):\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image       \n",
    "            #cv2.rectangle(img, bbox[0], bbox[1], (0,0,255),6)\n",
    "            bbox_all.append(bbox)\n",
    "    # Return the image\n",
    "    return bbox_all\n",
    "\n",
    "#credits Vivek Yadav\n",
    "def get_BB_new(img):\n",
    "    # Take in RGB image\n",
    "    pred,img = next_img(img)\n",
    "    img  = np.array(img,dtype= np.uint8)\n",
    "    img_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    heatmap = img_pred[:,:,0]\n",
    "    heatmap = smooth_heatmap(heatmap)\n",
    "    #print(np.max(heatmap))\n",
    "    heatmap[heatmap> 240] = 255\n",
    "    heatmap[heatmap<=240] = 0    \n",
    "    labels = label(heatmap)\n",
    "    \n",
    "    bbox_all = get_labeled_bboxes(np.copy(img), labels)\n",
    "    return bbox_all\n",
    "\n",
    "def get_Unet_mask(img):\n",
    "    \n",
    "    # Take in RGB image\n",
    "    pred,img = next_img(img)\n",
    "    img  = np.array(img,dtype= np.uint8)\n",
    "    img_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    heatmap = img_pred[:,:,0]\n",
    "    heatmap = smooth_heatmap(heatmap)\n",
    "    labels = label(heatmap)\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "training_gen = generate_train_batch(cars_15_35GB,1)\n",
    "batch_img,batch_mask = next(training_gen)\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sample_imgs=1 \n",
    "testing_gen = generate_test_batch(cars_15_35GB,sample_imgs)\n",
    "pre_final_predictions= model.predict(batch_img)\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Test on last frames of data\n",
    "start = time.time()\n",
    "batch_img,batch_mask = next(testing_gen)\n",
    "pre_final_predictions= model.predict(batch_img)\n",
    "np.shape(pre_final_predictions)\n",
    "for i in range(sample_imgs):\n",
    "    im=batch_img[i]\n",
    "    pred,im = next_img(im)\n",
    "    im  = np.array(im,dtype= np.uint8)\n",
    "    im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    im_mask = np.array(255*batch_mask[i],dtype=np.uint8)\n",
    "    rgb_mask_true= cv2.cvtColor(im_mask,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_true[:,:,0] = 0*rgb_mask_true[:,:,0]\n",
    "    rgb_mask_true[:,:,2] = 0*rgb_mask_true[:,:,2]\n",
    "    img_true = cv2.addWeighted(rgb_mask_true,0.70,im,0.70,0)\n",
    "    rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "    img_pred = cv2.addWeighted(rgb_mask_pred,0.70,im,1,0)\n",
    "    draw_img = get_BB_new_img(im)\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(img_pred)\n",
    "    plt.title('Segmented')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.title('Predicted')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(img_true)\n",
    "    plt.title('Gtruth')\n",
    "    plt.axis('off')\n",
    "\n",
    "end = time.time()\n",
    "end-start   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = 'scene01021.jpg'\n",
    "im = cv2.imread(test_img)\n",
    "im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "pred,im = next_img(im)\n",
    "im  = np.array(im,dtype= np.uint8)\n",
    "im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "\n",
    "img_pred = cv2.addWeighted(rgb_mask_pred,0.70,im,1,0)\n",
    "\n",
    "draw_img = get_BB_new_img(im)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_pred)\n",
    "plt.title('Segmentated')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Bounding Box')\n",
    "plt.axis('off');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing camera calibration\n",
    "Camera calibration is performed in order to correct the deformation in the images that is caused to the optic lens curvature. The first step is to print a chessboard and take random pictures of it. Then count the chess intersecting squires to provide \"objp\" which holds the (x,y,z) coordinates of these corners. Z=0 here and the object points are the same for all images in the calibration folder. The objpoints will be appended in \"objp\" every time the method successfully detect all chessboard corners in a test image. \"imgpoints\" will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection.\n",
    "\"objpoints\" and \"imgpoints\" were used to compute the camera calibration and distortion coefficients using the \"cv2.calibrateCamera()\" function on a test image in \"cv2.undistort()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare object points. The number of corners are 6x9\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "# Make a list of calibration images, all located in camera_cal\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    # imread reads images in BGR format\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        #Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "        #cv2.imwrite(write_name, img)\n",
    "        #cv2.imshow('img', img)\n",
    "        #cv2.waitKey(500)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform distortion removal on test images¶\n",
    "1. Has the distortion correction been correctly applied to each image?\n",
    "Undistortion is performed on the provided test images before they are used in the pipeline. This also applies to the video frames. \"dst\" holds undistorted frames from \"cv2.undistort\" that were computed using \"mtx\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in glob.glob(\"Frames/*\"):\n",
    "    im = cv2.imread(image_name)\n",
    "    im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "    im = undistort(im,read=False, display = False, write = False)\n",
    "    pred,im = next_img(im)\n",
    "    im  = np.array(im,dtype= np.uint8)\n",
    "    im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "    img_pred = cv2.addWeighted(rgb_mask_pred,0.50,im,1,0)\n",
    "    draw_img = get_BB_new_img(im)\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(img_pred)\n",
    "    plt.title('Segmentated')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.title('Bounding Box')\n",
    "    plt.axis('off');\n",
    "\n",
    "heatmap_10 = [np.zeros((640,960))]*10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_pipeline(image):\n",
    "    #test_img = 'scene01021.jpg'\n",
    "    #im = cv2.imread(im)\n",
    "    #im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "    #img = get_BB_new_img(im)\n",
    "    # Apply bounding box to image\n",
    "    image_bb = np.copy(image)\n",
    "    bbox_cars = get_BB_new(image_bb)\n",
    "    img_size = np.shape(image)\n",
    "    result = image\n",
    "    img_res_shape = result.shape\n",
    "    for bbox in bbox_cars:\n",
    "        cv2.rectangle(result,(np.int32(bbox[0][0]*img_res_shape[1]/960),np.int32(bbox[0][1]*img_res_shape[0]/640)), (np.int32(bbox[1][0]*img_res_shape[1]/960),np.int32(bbox[1][1]*img_res_shape[0]/640)),(0,255,0),6)\n",
    "    #heatmap = get_Unet_mask(image_bb)\n",
    "    #plt.imshow(img)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(video_pipeline) \n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('project_video_output.mp4'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras2]",
   "language": "python",
   "name": "conda-env-keras2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
