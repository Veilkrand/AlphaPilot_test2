{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Scene Understanding using Deep Learning\n",
    "## Introduction\n",
    "\n",
    "This Notebook was written for demonstrating scene understanding for the Lockheed Martin drone challange. The code consists of three pipelines pre-processing, FCN and post processing  The project is a corner stone for  \n",
    "\n",
    "\\<img style=\"float: center;\" src=\"readme_imgs/Img_groundtruth.png\">\n",
    "\n",
    "## Data Pre-processing \n",
    "\n",
    "We have implemented camera calibration routine to the video file.Each image was normalized and then smoothed with a Gaussian filter. The images were randomly processed with a brightness filter to help the network generalize to different lighting conditions. \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "## FCN\n",
    "\n",
    " \n",
    "\n",
    " \n",
    " \n",
    "\n",
    "##  Jaccard similarity coefficient \n",
    "\n",
    "In evaluating the model I've investigated several metrics including the Mean IU, Intersection over Union, and the Jaccard coefficient. The idea is to maximize the overlap between the predicted region and the ground truth bounding box.\n",
    " \n",
    "We eventually decided to use the Jaccard coeef. The Jaccard similarity coefficient is defined as the size of the intersection divided by the size of the union of two regions. This metric is used to compare the predicted labels to a set of labels in y_true  \n",
    "\n",
    "The coefficients are given by \n",
    "\n",
    "#### J(A,B) = |A∩B| / |A∪B|=|A∩B|/|A|+|B|-|A∩B| \n",
    "\n",
    "(If A and B are both empty, we define J(A,B) = 1.)\n",
    "\n",
    "<img style=\"float: center;\" src=\"readme_imgs/Intersection_of_sets_A_and_B.png\">\n",
    "<img style=\"float: center;\" src=\"readme_imgs/Intersection_of_sets_A_and_B_2.png\">\n",
    " \n",
    "\n",
    "## Training\n",
    "\n",
    "The Autti dataset was used and can be obtained from https://github.com/udacity/self-driving-car/tree/master/annotations .  \n",
    "\n",
    "## Results\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "import numpy as np\n",
    "import glob\n",
    "import time\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D,Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "from scipy.ndimage.measurements import label\n",
    "import pandas as pd\n",
    "import keras.backend as K\n",
    "from sklearn.metrics import jaccard_similarity_score\n",
    "from keras.layers import Input, Dense, BatchNormalization, merge, Activation\n",
    "import time\n",
    "import numpy\n",
    "from PIL import Image, ImageDraw\n",
    "import re\n",
    "from shapely.geometry import Polygon\n",
    "from pprint import pprint\n",
    "import PIL.ImageDraw\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import os\n",
    " \n",
    "#add a note for the class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and processing the wkt json format \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>images</th>\n",
       "      <th>img_path</th>\n",
       "      <th>inner_poly</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IMG_8378.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[616, 278, 948, 290, 945, 616, 609, 627]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IMG_3034.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[502, 255, 663, 373, 673, 696, 492, 677]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IMG_2082.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[504, 165, 829, 224, 819, 580, 489, 590]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMG_7209 (1).JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[409, 285, 774, 292, 781, 642, 387, 646]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IMG_5207.JPG</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>[494, 311, 765, 267, 768, 663, 495, 644]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             images                                           img_path  \\\n",
       "0      IMG_8378.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1      IMG_3034.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2      IMG_2082.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  IMG_7209 (1).JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4      IMG_5207.JPG  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                                 inner_poly  \n",
       "0  [616, 278, 948, 290, 945, 616, 609, 627]  \n",
       "1  [502, 255, 663, 373, 673, 696, 492, 677]  \n",
       "2  [504, 165, 829, 224, 819, 580, 489, 590]  \n",
       "3  [409, 285, 774, 292, 781, 642, 387, 646]  \n",
       "4  [494, 311, 765, 267, 768, 663, 495, 644]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df is the dataset that we are annotating\n",
    "#raw_df is the dataset that the organizers provided\n",
    "#adding path for json anf image folders respectively\n",
    "provided_data_file_dir='/media/a/D/lockheed-martin/dataset/LM_dataset/csv/training_GT_labels.json'#json provided by the organizers of the challange\n",
    "our_data_file_dir='/media/a/D/lockheed-martin/dataset/LM_dataset/csv/data_wkt.json'#our annotated dataset\n",
    "img_file_dir='/media/a/D/lockheed-martin/dataset/LM_dataset/Data_Training/'#folder where images are stored\n",
    "provided_df = pd.read_json(provided_data_file_dir)\n",
    "df = pd.read_json(our_data_file_dir)\n",
    "df.head(40)\n",
    " \n",
    "#adding a complete path for the image \n",
    "df['External ID']= [img_file_dir + u for u in df['External ID']]#iris_data_dir + new_df['parcel_id'].astype(str) + '.jpg'\n",
    " \n",
    "raw_df=pd.DataFrame()\n",
    "raw_df['images']=list(provided_df.columns.values)\n",
    "raw_df['img_path']=[img_file_dir +  u for u in raw_df['images']]\n",
    "\n",
    "raw_df['inner_poly']=[ provided_df[u][0] for u in raw_df['images']]\n",
    "\n",
    "raw_df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agreement</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Created By</th>\n",
       "      <th>DataRow ID</th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>External ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>Label</th>\n",
       "      <th>Labeled Data</th>\n",
       "      <th>Project Name</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Seconds to Label</th>\n",
       "      <th>View Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:35:37.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5r9p7w0anvd23j1pgg</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxucjqqkbd0b47j8vcjsua</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((997 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>33.832</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:36:22.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p800anv2xkrhfkw</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxvb54qkw90b47dwa8uupg</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((894 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>44.299</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-06T08:36:55.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p840anv7ly4rt5s</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrsxw0feqs9n08984nfshogi</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((848 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>31.955</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:17:15.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p880anvyjs4m1oj</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzrm18i8ga08983qewu7rq</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((597 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>39.032</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-02-07T02:18:01.000Z</td>\n",
       "      <td>alberto.galet@gmail.com</td>\n",
       "      <td>cjrsurb5v9p8c0anvcve1d63y</td>\n",
       "      <td>Test2 AlphaPilot #2</td>\n",
       "      <td>/media/a/D/lockheed-martin/dataset/LM_dataset/...</td>\n",
       "      <td>cjrtzslxpi69j0b4753lkl3ju</td>\n",
       "      <td>{'Outer Border': [{'geometry': 'POLYGON ((359 ...</td>\n",
       "      <td>https://storage.googleapis.com/labelbox-193903...</td>\n",
       "      <td>Test2 AlphaPilot</td>\n",
       "      <td>[]</td>\n",
       "      <td>46.003</td>\n",
       "      <td>https://image-segmentation-v4.labelbox.com?pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Agreement                Created At               Created By  \\\n",
       "0        NaN  2019-02-06T08:35:37.000Z  alberto.galet@gmail.com   \n",
       "1        NaN  2019-02-06T08:36:22.000Z  alberto.galet@gmail.com   \n",
       "2        NaN  2019-02-06T08:36:55.000Z  alberto.galet@gmail.com   \n",
       "3        NaN  2019-02-07T02:17:15.000Z  alberto.galet@gmail.com   \n",
       "4        NaN  2019-02-07T02:18:01.000Z  alberto.galet@gmail.com   \n",
       "\n",
       "                  DataRow ID         Dataset Name  \\\n",
       "0  cjrsurb5r9p7w0anvd23j1pgg  Test2 AlphaPilot #2   \n",
       "1  cjrsurb5v9p800anv2xkrhfkw  Test2 AlphaPilot #2   \n",
       "2  cjrsurb5v9p840anv7ly4rt5s  Test2 AlphaPilot #2   \n",
       "3  cjrsurb5v9p880anvyjs4m1oj  Test2 AlphaPilot #2   \n",
       "4  cjrsurb5v9p8c0anvcve1d63y  Test2 AlphaPilot #2   \n",
       "\n",
       "                                         External ID  \\\n",
       "0  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "1  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "2  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "3  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "4  /media/a/D/lockheed-martin/dataset/LM_dataset/...   \n",
       "\n",
       "                          ID  \\\n",
       "0  cjrsxucjqqkbd0b47j8vcjsua   \n",
       "1  cjrsxvb54qkw90b47dwa8uupg   \n",
       "2  cjrsxw0feqs9n08984nfshogi   \n",
       "3  cjrtzrm18i8ga08983qewu7rq   \n",
       "4  cjrtzslxpi69j0b4753lkl3ju   \n",
       "\n",
       "                                               Label  \\\n",
       "0  {'Outer Border': [{'geometry': 'POLYGON ((997 ...   \n",
       "1  {'Outer Border': [{'geometry': 'POLYGON ((894 ...   \n",
       "2  {'Outer Border': [{'geometry': 'POLYGON ((848 ...   \n",
       "3  {'Outer Border': [{'geometry': 'POLYGON ((597 ...   \n",
       "4  {'Outer Border': [{'geometry': 'POLYGON ((359 ...   \n",
       "\n",
       "                                        Labeled Data      Project Name  \\\n",
       "0  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "1  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "2  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "3  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "4  https://storage.googleapis.com/labelbox-193903...  Test2 AlphaPilot   \n",
       "\n",
       "  Reviews  Seconds to Label                                         View Label  \n",
       "0      []            33.832  https://image-segmentation-v4.labelbox.com?pro...  \n",
       "1      []            44.299  https://image-segmentation-v4.labelbox.com?pro...  \n",
       "2      []            31.955  https://image-segmentation-v4.labelbox.com?pro...  \n",
       "3      []            39.032  https://image-segmentation-v4.labelbox.com?pro...  \n",
       "4      []            46.003  https://image-segmentation-v4.labelbox.com?pro...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poly [616, 278, 948, 290, 945, 616, 609, 627]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# processing the provided dataset \n",
    "\n",
    "\n",
    "\n",
    "#processing the polygone and creating a mask\n",
    "def get_mask_raw_data(img_shape, poly,display=False):\n",
    "    output_mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    print('poly',poly)\n",
    "\n",
    "    coords =  zip(*[iter(poly)] * 2) \n",
    "     \n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "    polygons = []\n",
    "    for pt in coords:\n",
    "        a = (int(float(pt[0])), int(float(pt[1])))\n",
    "        polygons.append(a)\n",
    "     \n",
    "    draw.polygon(xy=polygons, outline=1, fill=1)\n",
    "    mask = np.array(mask, dtype=bool)\n",
    "    if display:\n",
    "        plt.imshow(mask)\n",
    "        plt.show\n",
    "    return mask\n",
    "for i in range(0,1):#len(df)):\n",
    "\n",
    "    img=cv2.imread(raw_df['img_path'][i])\n",
    "    row=img.shape[0]\n",
    "    col=img.shape[1]\n",
    "    img_shape = (row,col)\n",
    "    #outer_poly=df['Label'][i] \n",
    "    inner_poly=raw_df['inner_poly'][i] \n",
    "    #outer_mask=get_mask(img_shape,outer_poly,display=False)\n",
    "    inner_mask=get_mask_raw_data(img_shape,inner_poly,display=False)\n",
    "    inner_mask.dtype='uint8'\n",
    "    #outer_mask.dtype='uint8'\n",
    "    #final_mask=cv2.subtract(outer_mask,inner_mask)\n",
    "    plt.imshow(cv2.bitwise_and(img,img,mask=inner_mask))\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id=1\n",
    "test_poly=df['Label'][test_id]['Outer Border']#df['outer_poly'][1] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "#preprocessing our_dataset\n",
    "df['outer_poly']=''\n",
    "df['inner_poly']=''\n",
    "df['outer_x']=''\n",
    "df['outer_y']=''\n",
    "df['outer_width']=''\n",
    "df['outer_height']=''\n",
    "df['inner_x']=''\n",
    "df['inner_y']=''\n",
    "df['inner_width']=''\n",
    "df['inner_height']=''\n",
    "def convert_coordinates(poly):\n",
    "    proc_poly=poly[0]['geometry']\n",
    "    nums =  re.findall(r'\\d+(?:\\.\\d*)?', proc_poly.rpartition(',')[0])\n",
    "    coords =  zip(*[iter(nums)] * 2)\n",
    "    polygons = []\n",
    "    for pt in coords:\n",
    "        a = (int(float(pt[0])), int(float(pt[1])))\n",
    "        polygons.append(a)\n",
    "    \n",
    "    return polygons \n",
    "def get_bbox(polygon):\n",
    "    polygon=polygon[0]['geometry']\n",
    "    polygon=(polygon)\n",
    "\n",
    "    polygon =  re.findall(r'\\d+(?:\\.\\d*)?', polygon)\n",
    "    polygon =  zip(*[iter(polygon)] * 2)\n",
    "    x = []\n",
    "    y = []\n",
    "    for pt in polygon:\n",
    "        init_x = (int(float(pt[0])))\n",
    "        init_y = (int(float(pt[1])))\n",
    "\n",
    "        x.append(init_x)\n",
    "        y.append(init_y)\n",
    "    polygons=np.vstack((x,y)).T\n",
    "   \n",
    "    x,y,w,h = cv2.boundingRect(polygons)\n",
    "    return x,y,w,h\n",
    "\n",
    "for i in tqdm(range(0,len(df))):\n",
    "    outer_poly=df['Label'][i]['Outer Border']\n",
    "    inner_poly=df['Label'][i]['inner flyable area']\n",
    "    df['outer_poly'][i] = convert_coordinates(outer_poly)\n",
    " \n",
    "    df['inner_poly'][i] = convert_coordinates(inner_poly)\n",
    "    \n",
    "    df['outer_x'][i],df['outer_y'][i], df['outer_width'][i],df['outer_height'][i]=get_bbox(outer_poly)\n",
    "    df['inner_x'][i],df['inner_y'][i], df['inner_width'][i],df['inner_height'][i]=get_bbox(inner_poly)\n",
    "    #df['outer_poly']= h\n",
    "   #df['inner_poly']= convert_coordinates(inner_poly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing our annotation\n",
    "\n",
    "def get_mask(img_shape, poly,display=False):\n",
    "     \n",
    "\n",
    "    mask = np.zeros(img_shape[:2], dtype=np.uint8)\n",
    "    mask = PIL.Image.fromarray(mask)\n",
    "    draw = PIL.ImageDraw.Draw(mask)\n",
    "    polygons = []\n",
    "    for pt in poly:\n",
    "        a = (int(float(pt[0])), int(float(pt[1])))\n",
    "        polygons.append(a)\n",
    "    print(polygons)\n",
    "    draw.polygon(xy=polygons, outline=1, fill=1)\n",
    "    mask = np.array(mask, dtype=bool)\n",
    "    if display:\n",
    "        plt.imshow(mask)\n",
    "        plt.show\n",
    "    return mask\n",
    "#getting the final mask\n",
    "\n",
    "for i in range(0,1):#len(df)): # use one image only for testing\n",
    "\n",
    "    img=cv2.imread(df['External ID'][i])\n",
    "    row=img.shape[0]\n",
    "    col=img.shape[1]\n",
    "    img_shape = (row,col)\n",
    "    outer_poly=df['outer_poly'][i] \n",
    " \n",
    "    inner_poly=df['inner_poly'][i] \n",
    "    outer_mask=get_mask(img_shape,outer_poly,display=False)\n",
    "    inner_mask=get_mask(img_shape,inner_poly,display=False)\n",
    "    inner_mask.dtype='uint8'\n",
    "    outer_mask.dtype='uint8'\n",
    "    final_mask=cv2.subtract(outer_mask,inner_mask)\n",
    "    plt.imshow(cv2.bitwise_and(img,img,mask=final_mask))\n",
    "    plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended preprocessing pipeline for Yolo V3\n",
    "Data need to be of the following format and exported to a txt file\n",
    "image_path x_min y_min x_max y_max class_id  x_min y_min ... class_id\n",
    "```\n",
    "xxx/xxx.jpg 18.19 6.32 424.13 421.83 20 323.86 2.65 640.0 421.94 20 \n",
    "xxx/xxx.jpg 55.38 132.63 519.84 380.4 16\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_yolo = pd.DataFrame()\n",
    "df['class_id']= 1\n",
    "keep_cols=['External ID', 'outer_x', 'outer_y', 'outer_width', 'outer_height','class_id']\n",
    "df_yolo=df[keep_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yolo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yolo.to_csv('/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_data.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to txt as required by yolo v3\n",
    "#np.savetxt(r'gate_dataset.txt', df_yolo.values, fmt='%d')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deeplearning pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Code for this part was adopted from https://github.com/YunYang1994/tensorflow-yolov3\n",
    "\n",
    "#I created 3 files for the training\n",
    "\n",
    "\n",
    "```\n",
    "/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates.names\n",
    "\n",
    "/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates.anchors\n",
    "\n",
    "/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gate_dataset.txt```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to generate the tf records for the training and testing dataset using the \n",
    "# following commands in shell\n",
    "\n",
    "# python /media/a/D/lockheed-martin/ML-Pipeline/object_segmentation_pipelines/tensorflow-yolov3/core/convert_tfrecord.py --dataset_txt /media/a/D/lockheed-martin/dataset/LM_dataset/csv/gate_dataset.txt --tfrecord_path_prefix gates_train\n",
    "# python /media/a/D/lockheed-martin/ML-Pipeline/object_segmentation_pipelines/tensorflow-yolov3/core/convert_tfrecord.py --dataset_txt /media/a/D/lockheed-martin/dataset/LM_dataset/csv/gate_dataset.txt --tfrecord_path_prefix gates_test\n",
    "# which yeild\n",
    "#/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_train.tfrecords\n",
    "#/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_test.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display and check a random image  \n",
    "from core import utils\n",
    "import tensorflow as tf\n",
    "from core.dataset import Parser, dataset\n",
    "sess = tf.Session()\n",
    "\n",
    "IMAGE_H, IMAGE_W = 416, 416\n",
    "BATCH_SIZE = 1\n",
    "SHUFFLE_SIZE = 1\n",
    "\n",
    "train_tfrecord = \"/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_*.tfrecords\"\n",
    "anchors        = utils.get_anchors('/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_anchors.txt', IMAGE_H, IMAGE_W)\n",
    "classes = utils.read_coco_names('/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates.names')\n",
    "num_classes = len(classes)\n",
    "\n",
    "parser   = Parser(IMAGE_H, IMAGE_W, anchors, num_classes, debug=True)\n",
    "trainset = dataset(parser, train_tfrecord, BATCH_SIZE, shuffle=SHUFFLE_SIZE)\n",
    "\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "example = trainset.get_next()\n",
    "\n",
    "for l in range(10):\n",
    "    image, boxes = sess.run(example)\n",
    "    image, boxes = image[0], boxes[0]\n",
    "\n",
    "    n_box = len(boxes)\n",
    "    for i in range(n_box):\n",
    "        image = cv2.rectangle(image,(int(float(boxes[i][0])),\n",
    "                                     int(float(boxes[i][1]))),\n",
    "                                    (int(float(boxes[i][2])),\n",
    "                                     int(float(boxes[i][3]))), (255,0,0), 1)\n",
    "        label = classes[boxes[i][4]]\n",
    "        image = cv2.putText(image, label, (int(float(boxes[i][0])),int(float(boxes[i][1]))),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX,  .6, (0, 255, 0), 1, 2)\n",
    "\n",
    "    image = Image.fromarray(np.uint8(image))\n",
    "    image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and convert yolo weights from https://github.com/YunYang1994/tensorflow-yolov3/releases/download/v1.0/yolov3.weights\n",
    "#  python convert_weight.py --convert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./checkpoint/yolov3.ckpt\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python\n",
    "# coding=utf-8\n",
    "#================================================================\n",
    "#   Copyright (C) 2019 * Ltd. All rights reserved.\n",
    "#\n",
    "#   Editor      : VIM\n",
    "#   File name   : quick_train.py\n",
    "#   Author      : YunYang1994\n",
    "#   Created date: 2019-01-21 14:46:26\n",
    "#   Description :\n",
    "#\n",
    "#================================================================\n",
    "\n",
    "import tensorflow as tf\n",
    "from core import utils, yolov3\n",
    "from core.dataset import dataset, Parser\n",
    "sess = tf.Session()\n",
    "\n",
    "IMAGE_H, IMAGE_W = 256,256#416, 416\n",
    "BATCH_SIZE       = 1\n",
    "EPOCHS           = 2500\n",
    "LR               = 0.001 # if Nan, set 0.0005, 0.0001\n",
    "DECAY_STEPS      = 100\n",
    "DECAY_RATE       = 0.9\n",
    "SHUFFLE_SIZE     = 200\n",
    "CLASSES          = utils.read_coco_names('/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates.names')\n",
    "ANCHORS          = utils.get_anchors('/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_anchors.txt', IMAGE_H, IMAGE_W)\n",
    "NUM_CLASSES      = len(CLASSES)\n",
    "EVAL_INTERNAL    = 100\n",
    "\n",
    "train_tfrecord   = \"/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_train.tfrecords\"\n",
    "test_tfrecord    = \"/media/a/D/lockheed-martin/dataset/LM_dataset/csv/gates_test.tfrecords\"\n",
    "\n",
    "parser   = Parser(IMAGE_H, IMAGE_W, ANCHORS, NUM_CLASSES)\n",
    "trainset = dataset(parser, train_tfrecord, BATCH_SIZE, shuffle=SHUFFLE_SIZE)\n",
    "testset  = dataset(parser, test_tfrecord , BATCH_SIZE, shuffle=None)\n",
    "\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "example = tf.cond(is_training, lambda: trainset.get_next(), lambda: testset.get_next())\n",
    "\n",
    "images, *y_true = example\n",
    "model = yolov3.yolov3(NUM_CLASSES, ANCHORS)\n",
    "\n",
    "with tf.variable_scope('yolov3'):\n",
    "    pred_feature_map = model.forward(images, is_training=is_training)\n",
    "    loss             = model.compute_loss(pred_feature_map, y_true)\n",
    "    y_pred           = model.predict(pred_feature_map)\n",
    "\n",
    "tf.summary.scalar(\"loss/coord_loss\",   loss[1])\n",
    "tf.summary.scalar(\"loss/sizes_loss\",   loss[2])\n",
    "tf.summary.scalar(\"loss/confs_loss\",   loss[3])\n",
    "tf.summary.scalar(\"loss/class_loss\",   loss[4])\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, collections=[tf.GraphKeys.LOCAL_VARIABLES])\n",
    "write_op = tf.summary.merge_all()\n",
    "writer_train = tf.summary.FileWriter(\"./data/train\")\n",
    "writer_test  = tf.summary.FileWriter(\"./data/test\")\n",
    "\n",
    "saver_to_restore = tf.train.Saver(var_list=tf.contrib.framework.get_variables_to_restore(include=[\"yolov3/darknet-53\"]))\n",
    "update_vars = tf.contrib.framework.get_variables_to_restore(include=[\"yolov3/yolo-v3\"])\n",
    "learning_rate = tf.train.exponential_decay(LR, global_step, decay_steps=DECAY_STEPS, decay_rate=DECAY_RATE, staircase=True)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "\n",
    "# set dependencies for BN ops\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    train_op = optimizer.minimize(loss[0], var_list=update_vars, global_step=global_step)\n",
    "\n",
    "sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "saver_to_restore.restore(sess, \"./checkpoint/yolov3.ckpt\")\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    run_items = sess.run([train_op, write_op, y_pred, y_true] + loss, feed_dict={is_training:True})\n",
    "\n",
    "    if (epoch+1) % EVAL_INTERNAL == 0:\n",
    "        train_rec_value, train_prec_value = utils.evaluate(run_items[2], run_items[3])\n",
    "\n",
    "    writer_train.add_summary(run_items[1], global_step=epoch)\n",
    "    writer_train.flush() # Flushes the event file to disk\n",
    "    if (epoch+1) % 500 == 0: saver.save(sess, save_path=\"./checkpoint/yolov3.ckpt\", global_step=epoch+1)\n",
    "\n",
    "    print(\"=> EPOCH %10d [TRAIN]:\\tloss_xy:%7.4f \\tloss_wh:%7.4f \\tloss_conf:%7.4f \\tloss_class:%7.4f\"\n",
    "        %(epoch+1, run_items[5], run_items[6], run_items[7], run_items[8]))\n",
    "\n",
    "    run_items = sess.run([write_op, y_pred, y_true] + loss, feed_dict={is_training:False})\n",
    "    if (epoch+1) % EVAL_INTERNAL == 0:\n",
    "        test_rec_value, test_prec_value = utils.evaluate(run_items[1], run_items[2])\n",
    "        print(\"\\n=======================> evaluation result <================================\\n\")\n",
    "        print(\"=> EPOCH %10d [TRAIN]:\\trecall:%7.4f \\tprecision:%7.4f\" %(epoch+1, train_rec_value, train_prec_value))\n",
    "        print(\"=> EPOCH %10d [VALID]:\\trecall:%7.4f \\tprecision:%7.4f\" %(epoch+1, test_rec_value,  test_prec_value))\n",
    "        print(\"\\n=======================> evaluation result <================================\\n\")\n",
    "\n",
    "    writer_test.add_summary(run_items[0], global_step=epoch)\n",
    "    writer_test.flush() # Flushes the event file to disk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Method to read image. CV2 reads images in BGR and the simulator provides images in RGB. Therefore convert to \n",
    "#RGB domain\n",
    "def read_img(img):\n",
    "    img = cv2.imread(img)\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "#Image brigtness changing method, based on Vivek Yadav's [2] approach for changing image brightness\n",
    "def brightness_images(img):\n",
    "    post_img = cv2.cvtColor(img,cv2.COLOR_RGB2HSV)\n",
    "    random_bright = .25+np.random.uniform()\n",
    "    post_img[:,:,2] = np.multiply(post_img[:,:,2],random_bright)\n",
    "    post_img = cv2.cvtColor(post_img,cv2.COLOR_HSV2RGB)\n",
    "    return post_img\n",
    "# Another approach to adjust brightness used for experimentation \n",
    "def brightness_images_2(img):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  \n",
    "    h, s, v = cv2.split(hsv)\n",
    "    v += 255\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    img = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)\n",
    "    return img\n",
    "# Resize the image to the givin dimensions \n",
    "def resize_img(image, col, row):\n",
    "    image = cv2.resize(image, (col,row), interpolation=cv2.INTER_AREA)\n",
    "    return image\n",
    "# Crop away the car hood from the orginal image  \n",
    "def crop_img(img):\n",
    "    shape = img.shape\n",
    "    img = img[0:shape[0]-20,0:shape[1]]\n",
    "    img = resize_img(img, 64, 64)\n",
    "    return img\n",
    "\n",
    "# Define a function to draw bounding boxes\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "def gaussian_noise(img, kernel_size):\n",
    "    \"\"\"Applies a Gaussian Noise kernel\"\"\"\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)\n",
    "\n",
    "def transform(img):\n",
    "    imshape = img.shape\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    #src=np.float32([[160,imshape[0]],[imshape[1]/2-60, imshape[0]/2+90],[imshape[1]/2+100, imshape[0]/2+90], [imshape[1]-20,imshape[0]]])\n",
    "    #dst=np.float32([[(240,imshape[0]),(240, 0),(imshape[1]-130, 0), (imshape[1]-130,imshape[0])]])\n",
    "    src = np.float32([[490, 482],[810, 482],\n",
    "                     [1250, 720],[40, 720]])\n",
    "    dst = np.float32([[0, 0], [1280, 0], \n",
    "                     [1250, 720],[40, 720]])\n",
    "    \n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    wraped =  cv2.warpPerspective(img,M,img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return  Minv, wraped\n",
    "\n",
    "\n",
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "#Implement calibration on the images that will be used\n",
    "def undistort(img, read=True, display=True, write=False):\n",
    "\n",
    "# Test undistortion on an image\n",
    "    \n",
    "    if read:\n",
    "        img = cv2.imread(img)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "#img = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_RGB2BGR)\n",
    "    if write:\n",
    "        cv2.imwrite('Undistorted/test6.jpg',dst)\n",
    "# Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "#dist_pickle = {}\n",
    "#dist_pickle[\"mtx\"] = mtx\n",
    "#dist_pickle[\"dist\"] = dist\n",
    "#pickle.dump( dist_pickle, open( \"calibration_wide/wide_dist_pickle.p\", \"wb\" ) )\n",
    "#dst = cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "# Visualize undistortion\n",
    "    if display:\n",
    "        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "        img_RGB=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        ax1.imshow(img_RGB)\n",
    "        ax1.set_title('Original Image', fontsize=30)\n",
    "        dst_RGB=cv2.cvtColor(dst, cv2.COLOR_BGR2RGB)\n",
    "        ax2.imshow(dst_RGB)\n",
    "        ax2.set_title('Undistorted Image', fontsize=30)\n",
    "    else:\n",
    "        return dst\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Method to get the image and resize it if required\n",
    "def im_read(df,ID,resize = True, size=(640,300),augumentation=True, display=True):\n",
    "    #Return the index at which the image is first found in a list - Python\n",
    "    \n",
    "    file_name = df['File_Path'][ID]\n",
    "    #img = read_img(file_name)\n",
    "    img = cv2.imread(file_name)\n",
    "    img_size = np.shape(img)\n",
    "    #print(img_size )\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    if resize == True:\n",
    "        img = cv2.resize(img,size)\n",
    "    if augumentation == True:\n",
    "        img = brightness_images(img)\n",
    "    #str.split(str=\"\", num=string.count(str)).\n",
    "    img_name = df['Frame'][ID]#file_name.split('/',1)[1]\n",
    "    \n",
    "    bb_boxes = df[df['Frame'] == img_name].reset_index()\n",
    "    \n",
    "    img_size_post = np.shape(img)  \n",
    "    bb_boxes['xmin'] = np.round(bb_boxes['xmin']/img_size[1]*img_size_post[1])\n",
    "    bb_boxes['xmax'] = np.round(bb_boxes['xmax']/img_size[1]*img_size_post[1])\n",
    "    bb_boxes['ymin'] = np.round(bb_boxes['ymin']/img_size[0]*img_size_post[0])\n",
    "    bb_boxes['ymax'] = np.round(bb_boxes['ymax']/img_size[0]*img_size_post[0])\n",
    "    bb_boxes['Area'] = (bb_boxes['xmax']- bb_boxes['xmin'])*(bb_boxes['ymax']- bb_boxes['ymin'])\n",
    "   \n",
    "    if display == True:\n",
    "        plt.figure(figsize=(16,10))\n",
    "        plt.subplot(1,1,1)\n",
    "        plot_im_bbox(img,bb_boxes)\n",
    "    return img_name,img,bb_boxes\n",
    "\n",
    "def get_mask_seg(img,bb_boxes):\n",
    "    print(bb_boxes)\n",
    "    img_mask = np.zeros_like(img[:,:,0])\n",
    "    for i in range(len(bb_boxes)):\n",
    "        bb_box_i = [bb_boxes.iloc[i]['xmin'],bb_boxes.iloc[i]['ymin'],\n",
    "                bb_boxes.iloc[i]['xmax'],bb_boxes.iloc[i]['ymax']]\n",
    "        print(bb_box_i)\n",
    "        img_mask[int(bb_box_i[1]):int(bb_box_i[3]),int(bb_box_i[0]):int(bb_box_i[2])]= 1\n",
    "        img_mask = np.reshape(img_mask,(np.shape(img_mask)[0],np.shape(img_mask)[1],1))\n",
    "    return img_mask\n",
    "\n",
    "def plot_bbox(bb_boxes,ind_bb,color='r',linewidth=2):\n",
    "    bb_box_i = [bb_boxes.iloc[ind_bb]['xmin'],\n",
    "                bb_boxes.iloc[ind_bb]['ymin'],\n",
    "                bb_boxes.iloc[ind_bb]['xmax'],\n",
    "                bb_boxes.iloc[ind_bb]['ymax']]\n",
    "    plt.plot([bb_box_i[0],bb_box_i[2],bb_box_i[2],\n",
    "                  bb_box_i[0],bb_box_i[0]],\n",
    "             [bb_box_i[1],bb_box_i[1],bb_box_i[3],\n",
    "                  bb_box_i[3],bb_box_i[1]],\n",
    "             color,linewidth=linewidth)\n",
    "def plot_im_bbox(im,bb_boxes):\n",
    "    plt.imshow(im)\n",
    "    for i in range(len(bb_boxes)):\n",
    "        plot_bbox(bb_boxes,i,'g')\n",
    "\n",
    "        bb_box_i = [bb_boxes.iloc[i]['xmin'],bb_boxes.iloc[i]['ymin'],\n",
    "                bb_boxes.iloc[i]['xmax'],bb_boxes.iloc[i]['ymax']]\n",
    "    plt.axis('off'); \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_35GB.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the mail function\n",
    "df=cars_35GB\n",
    "ID=660\n",
    "test_img_name,img,bb_boxes = im_read(cars_35GB,ID,resize = True, size=(640,300), augumentation=False, display = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test an image with it's bounding boxes\n",
    "#print (cars_15_35GB)\n",
    "df=cars_35GB\n",
    "ID=660\n",
    "test_img_name,img,bb_boxes = im_read(cars_35GB,ID,resize = True, size=(640,300), augumentation=False, display = False)\n",
    "img_masked = get_mask_seg(img,bb_boxes)\n",
    "print('img.shape',img.shape)\n",
    "plt.figure(figsize=(14,8))\n",
    "plt.subplot(1,3,1)\n",
    "plot_im_bbox(img,bb_boxes)\n",
    "plt.title('Raw image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_masked[:,:,0])\n",
    "plt.title('Raw image')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(cv2.bitwise_and(img,img,mask=img_masked))\n",
    "plt.title('Raw image')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_train_batch(data,batch_size):\n",
    "    #col=size[0]\n",
    "    #row=size[1]\n",
    "    batch_images = np.zeros((batch_size, row, col, 3))\n",
    "    #batch_steering = np.zeros(batch_size)\n",
    "    batch_masks = np.zeros((batch_size, row, col, 1))\n",
    "    training_batch = len(data)-100000\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            \n",
    "            process_line = np.random.randint(training_batch)\n",
    "            #generator_csv= data.iloc[[process_line]].reset_index()\n",
    "            #x,y = all_filters_train(generator_csv)\n",
    "            #print(data)\n",
    "            img_name,img,bb_boxes = im_read(data,process_line,resize = True, size=(col,row), augumentation=True, display = False)\n",
    "            img_masked = get_mask_seg(img,bb_boxes)\n",
    "            batch_images[i_batch] = img\n",
    "            batch_masks[i_batch] = img_masked\n",
    "        yield batch_images, batch_masks\n",
    "\n",
    "def generate_test_batch(data,batch_size):\n",
    "    batch_images = np.zeros((batch_size, row, col, 3))\n",
    "    #batch_steering = np.zeros(batch_size)\n",
    "    batch_masks = np.zeros((batch_size, row, col, 1))\n",
    "    training_batch = len(data)-100000\n",
    "    while 1:\n",
    "        for i_batch in range(batch_size):\n",
    "            process_line = np.random.randint(training_batch)\n",
    "            process_line = process_line+training_batch\n",
    "            #generator_csv= data.iloc[[process_line]].reset_index()\n",
    "            #x,y = all_filters_train(generator_csv)\n",
    "            img_name,img,bb_boxes = im_read(data,process_line,resize = True, size=(col,row), augumentation=True, display = False)\n",
    "            img_masked = get_mask_seg(img,bb_boxes)\n",
    "            batch_images[i_batch] = img\n",
    "            batch_masks[i_batch] = img_masked\n",
    "        yield batch_images, batch_masks\n",
    "\"\"\"        \n",
    "def generate_validation_patch(data):\n",
    "    while 1:\n",
    "        for process_line in range(len(data)):\n",
    "            generator_csv = data.iloc[[process_line]].reset_index()\n",
    "            x = all_filters_validate(data)\n",
    "            x = x.reshape(1, x.shape[0], x.shape[1], x.shape[2])\n",
    "            y = generator_csv['steering'][0]\n",
    "            y = np.array([[y]])\n",
    "            yield x, y\n",
    "def save_model(fileModelJSON,fileWeights):\n",
    "    if Path(fileModelJSON).is_file():\n",
    "        os.remove(fileModelJSON)\n",
    "    json_string = model.to_json()\n",
    "    with open(fileModelJSON,'w' ) as f:\n",
    "        json.dump(json_string, f)\n",
    "    if Path(fileWeights).is_file():\n",
    "        os.remove(fileWeights)\n",
    "    model.save_weights(fileWeights)\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 640\n",
    "col = 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for custom metrics\n",
    "#custom metrix source : https://keras.io/metrics/\n",
    "#Use this as a template\n",
    "#def mean_pred(y_true, y_pred):\n",
    "    #return K.mean(y_pred)\n",
    "\n",
    "#def false_rates(y_true, y_pred):\n",
    "    #false_neg = ...\n",
    "    #false_pos = ...\n",
    "    #return {\n",
    "        #'false_neg': false_neg,\n",
    "        #'false_pos': false_pos,\n",
    "    #}\n",
    "\n",
    "#model.compile(optimizer='rmsprop',\n",
    "              #loss='binary_crossentropy',\n",
    "             # metrics=['accuracy', mean_pred, false_rates])\n",
    "\n",
    "def jaccard_coef(y_true, y_pred):\n",
    "    # __author__ = Vladimir Iglovikov\n",
    "    intersection = K.sum(y_true * y_pred, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "\n",
    "    return K.mean(jac)\n",
    "\n",
    "def jaccard_coef_int(y_true, y_pred):\n",
    "    # __author__ = Vladimir Iglovikov\n",
    "    y_pred_pos = K.round(K.clip(y_pred, 0, 1))\n",
    "\n",
    "    intersection = K.sum(y_true * y_pred_pos, axis=[0, -1, -2])\n",
    "    sum_ = K.sum(y_true + y_pred, axis=[0, -1, -2])\n",
    "    jac = (intersection + smooth) / (sum_ - intersection + smooth)\n",
    "    return K.mean(jac)\n",
    "\n",
    "#to do: fbeta_score(y_true, y_pred, beta=1) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(classes_path):\n",
    "    '''loads the classes'''\n",
    "    with open(classes_path) as f:\n",
    "        class_names = f.readlines()\n",
    "    class_names = [c.strip() for c in class_names]\n",
    "    return class_names\n",
    "\n",
    "def get_anchors(anchors_path):\n",
    "    '''loads the anchors from a file'''\n",
    "    with open(anchors_path) as f:\n",
    "        anchors = f.readline()\n",
    "    anchors = [float(x) for x in anchors.split(',')]\n",
    "    return np.array(anchors).reshape(-1, 2)\n",
    "\n",
    "\n",
    "def create_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/yolo_weights.h5'):\n",
    "    '''create the training model'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16, 2:8}[l], w//{0:32, 1:16, 2:8}[l], \\\n",
    "        num_anchors//3, num_classes+5)) for l in range(3)]\n",
    "\n",
    "    model_body = yolo_body(image_input, num_anchors//3, num_classes)\n",
    "    print('Create YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze darknet53 body or freeze all but 3 output layers.\n",
    "            num = (185, len(model_body.layers)-3)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.5})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_tiny_model(input_shape, anchors, num_classes, load_pretrained=True, freeze_body=2,\n",
    "            weights_path='model_data/tiny_yolo_weights.h5'):\n",
    "    '''create the training model, for Tiny YOLOv3'''\n",
    "    K.clear_session() # get a new session\n",
    "    image_input = Input(shape=(None, None, 3))\n",
    "    h, w = input_shape\n",
    "    num_anchors = len(anchors)\n",
    "\n",
    "    y_true = [Input(shape=(h//{0:32, 1:16}[l], w//{0:32, 1:16}[l], \\\n",
    "        num_anchors//2, num_classes+5)) for l in range(2)]\n",
    "\n",
    "    model_body = tiny_yolo_body(image_input, num_anchors//2, num_classes)\n",
    "    print('Create Tiny YOLOv3 model with {} anchors and {} classes.'.format(num_anchors, num_classes))\n",
    "\n",
    "    if load_pretrained:\n",
    "        model_body.load_weights(weights_path, by_name=True, skip_mismatch=True)\n",
    "        print('Load weights {}.'.format(weights_path))\n",
    "        if freeze_body in [1, 2]:\n",
    "            # Freeze the darknet body or freeze all but 2 output layers.\n",
    "            num = (20, len(model_body.layers)-2)[freeze_body-1]\n",
    "            for i in range(num): model_body.layers[i].trainable = False\n",
    "            print('Freeze the first {} layers of total {} layers.'.format(num, len(model_body.layers)))\n",
    "\n",
    "    model_loss = Lambda(yolo_loss, output_shape=(1,), name='yolo_loss',\n",
    "        arguments={'anchors': anchors, 'num_classes': num_classes, 'ignore_thresh': 0.7})(\n",
    "        [*model_body.output, *y_true])\n",
    "    model = Model([model_body.input, *y_true], model_loss)\n",
    "\n",
    "    return model\n",
    "\n",
    "def data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    '''data generator for fit_generator'''\n",
    "    n = len(annotation_lines)\n",
    "    i = 0\n",
    "    while True:\n",
    "        image_data = []\n",
    "        box_data = []\n",
    "        for b in range(batch_size):\n",
    "            if i==0:\n",
    "                np.random.shuffle(annotation_lines)\n",
    "            image, box = get_random_data(annotation_lines[i], input_shape, random=True)\n",
    "            image_data.append(image)\n",
    "            box_data.append(box)\n",
    "            i = (i+1) % n\n",
    "        image_data = np.array(image_data)\n",
    "        box_data = np.array(box_data)\n",
    "        y_true = preprocess_true_boxes(box_data, input_shape, anchors, num_classes)\n",
    "        yield [image_data, *y_true], np.zeros(batch_size)\n",
    "\n",
    "def data_generator_wrapper(annotation_lines, batch_size, input_shape, anchors, num_classes):\n",
    "    n = len(annotation_lines)\n",
    "    if n==0 or batch_size<=0: return None\n",
    "    return data_generator(annotation_lines, batch_size, input_shape, anchors, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from keras_yolov3_kitti.yolo3.model import preprocess_true_boxes, yolo_body, tiny_yolo_body, yolo_loss\n",
    "from keras_yolov3_kitti.yolo3.utils import get_random_data\n",
    "log_dir='logs'\n",
    "anchors_path = 'keras_yolov3_kitti/model_data/yolo_anchors.txt'\n",
    "classes_path = 'keras_yolov3_kitti/model_data/voc_classes.txt'\n",
    "num_classes=2#len(class_names)\n",
    "anchors = get_anchors(anchors_path)\n",
    "input_shape =(300,640)\n",
    "is_tiny_version = len(anchors)==6 # default setting\n",
    "if is_tiny_version:\n",
    "    model = create_tiny_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path='keras_yolov3_kitti/model_data/tiny_yolo_weights.h5')\n",
    "else:\n",
    "    model = create_model(input_shape, anchors, num_classes,\n",
    "        freeze_body=2, weights_path='keras_yolov3_kitti/model_data/yolo_weights.h5') # make sure you know what you freeze\n",
    "\n",
    "logging = TensorBoard(log_dir=log_dir)\n",
    "checkpoint = ModelCheckpoint(log_dir + 'ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5',\n",
    "    monitor='val_loss', save_weights_only=True, save_best_only=True, period=3)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=1e-3), loss={\n",
    "            # use custom yolo_loss Lambda layer.\n",
    "            'yolo_loss': lambda y_true, y_pred: y_pred})\n",
    "batch_size = 32\n",
    "print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "                steps_per_epoch=max(1, num_train//batch_size),\n",
    "                validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "                validation_steps=max(1, num_val//batch_size),\n",
    "                epochs=25,\n",
    "                initial_epoch=0,\n",
    "                callbacks=[logging, checkpoint])\n",
    "model.save_weights(log_dir + 'trained_weights_stage_1.h5')\n",
    "\n",
    "for i in range(len(model.layers)):\n",
    "            model.layers[i].trainable = True\n",
    "        model.compile(optimizer=Adam(lr=1e-4), loss={'yolo_loss': lambda y_true, y_pred: y_pred}) # recompile to apply the change\n",
    "        print('Unfreeze all of the layers.')\n",
    "\n",
    "        batch_size = 4 # note that more GPU memory is required after unfreezing the body\n",
    "        print('Train on {} samples, val on {} samples, with batch size {}.'.format(num_train, num_val, batch_size))\n",
    "        model.fit_generator(data_generator_wrapper(lines[:num_train], batch_size, input_shape, anchors, num_classes),\n",
    "            steps_per_epoch=max(1, num_train//batch_size),\n",
    "            validation_data=data_generator_wrapper(lines[num_train:], batch_size, input_shape, anchors, num_classes),\n",
    "            validation_steps=max(1, num_val//batch_size),\n",
    "            epochs=50,\n",
    "            initial_epoch=25,\n",
    "            callbacks=[logging, checkpoint, reduce_lr, early_stopping])\n",
    "        model.save_weights(log_dir + 'trained_weights_final.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post-processing pipeline      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smooth = 1.\n",
    "heatmap_prev = np.zeros((640,960))\n",
    "heatmap_10 = [np.zeros((640,960))]*10\n",
    "def smooth_heatmap(heatmap):\n",
    "    #Credit Vive Yadav\n",
    "    # Smoothing heatmap as average of 10 previous frames\n",
    "    global heatmap_10\n",
    "    heatmap_10_1 = heatmap_10[1:]\n",
    "    heatmap_10_1.append(heatmap)\n",
    "    heatmap_10 = heatmap_10_1\n",
    "    heatmap = np.mean(heatmap_10,axis=0)\n",
    "    \n",
    "    #heatmap = heatmap_prev*.2 + heatmap*.8\n",
    "    #heatmap[heatmap>240] = 255\n",
    "    #heatmap[heatmap<240] = 0\n",
    "    return heatmap \n",
    " \n",
    "\n",
    "def next_img(img, resize=True):\n",
    "    if resize == True:\n",
    "        img = cv2.resize(img,(col,row))\n",
    "        img = np.reshape(img,(1,row, col,3))\n",
    "    pred = model.predict(img)\n",
    "    return pred,img[0]\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    \"\"\"Return image with bounding boxes drawn around the labelled regions.\n",
    "    \"\"\"\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        # increasing or reducing the sensetivity of bounding box noise\n",
    "        if ((np.max(nonzeroy)-np.min(nonzeroy)>70) & (np.max(nonzerox)-np.min(nonzerox)>70)):\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))      \n",
    "            cv2.rectangle(img, bbox[0], bbox[1], (0,0,255),6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def get_BB_new_img(img):\n",
    "    # Take in RGB image\n",
    "    pred,img = next_img(img)\n",
    "    img  = np.array(img,dtype= np.uint8)\n",
    "    img_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    heatmap = im_pred[:,:,0]\n",
    "    #Create an image with some features, then label it using the default (cross-shaped) structuring element:\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    return draw_img\n",
    "\n",
    "def get_labeled_bboxes(img, labels):\n",
    "    # Get labeled boxex\n",
    "    bbox_all = []\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        \n",
    "        # Define a bounding box based on min/max x and y\n",
    "        if ((np.max(nonzeroy)-np.min(nonzeroy)> 40) & (np.max(nonzerox)-np.min(nonzerox)> 40)):\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            # Draw the box on the image       \n",
    "            #cv2.rectangle(img, bbox[0], bbox[1], (0,0,255),6)\n",
    "            bbox_all.append(bbox)\n",
    "    # Return the image\n",
    "    return bbox_all\n",
    "\n",
    "#credits Vivek Yadav\n",
    "def get_BB_new(img):\n",
    "    # Take in RGB image\n",
    "    pred,img = next_img(img)\n",
    "    img  = np.array(img,dtype= np.uint8)\n",
    "    img_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    heatmap = img_pred[:,:,0]\n",
    "    heatmap = smooth_heatmap(heatmap)\n",
    "    #print(np.max(heatmap))\n",
    "    heatmap[heatmap> 240] = 255\n",
    "    heatmap[heatmap<=240] = 0    \n",
    "    labels = label(heatmap)\n",
    "    \n",
    "    bbox_all = get_labeled_bboxes(np.copy(img), labels)\n",
    "    return bbox_all\n",
    "\n",
    "def get_Unet_mask(img):\n",
    "    \n",
    "    # Take in RGB image\n",
    "    pred,img = next_img(img)\n",
    "    img  = np.array(img,dtype= np.uint8)\n",
    "    img_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    heatmap = img_pred[:,:,0]\n",
    "    heatmap = smooth_heatmap(heatmap)\n",
    "    labels = label(heatmap)\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "training_gen = generate_train_batch(cars_15_35GB,1)\n",
    "batch_img,batch_mask = next(training_gen)\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "sample_imgs=1 \n",
    "testing_gen = generate_test_batch(cars_15_35GB,sample_imgs)\n",
    "pre_final_predictions= model.predict(batch_img)\n",
    "end = time.time()\n",
    "end-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### Test on last frames of data\n",
    "start = time.time()\n",
    "batch_img,batch_mask = next(testing_gen)\n",
    "pre_final_predictions= model.predict(batch_img)\n",
    "np.shape(pre_final_predictions)\n",
    "for i in range(sample_imgs):\n",
    "    im=batch_img[i]\n",
    "    pred,im = next_img(im)\n",
    "    im  = np.array(im,dtype= np.uint8)\n",
    "    im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    im_mask = np.array(255*batch_mask[i],dtype=np.uint8)\n",
    "    rgb_mask_true= cv2.cvtColor(im_mask,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_true[:,:,0] = 0*rgb_mask_true[:,:,0]\n",
    "    rgb_mask_true[:,:,2] = 0*rgb_mask_true[:,:,2]\n",
    "    img_true = cv2.addWeighted(rgb_mask_true,0.70,im,0.70,0)\n",
    "    rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "    img_pred = cv2.addWeighted(rgb_mask_pred,0.70,im,1,0)\n",
    "    draw_img = get_BB_new_img(im)\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,4,1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,2)\n",
    "    plt.imshow(img_pred)\n",
    "    plt.title('Segmented')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,3)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.title('Predicted')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,4,4)\n",
    "    plt.imshow(img_true)\n",
    "    plt.title('Gtruth')\n",
    "    plt.axis('off')\n",
    "\n",
    "end = time.time()\n",
    "end-start   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = 'scene01021.jpg'\n",
    "im = cv2.imread(test_img)\n",
    "im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "pred,im = next_img(im)\n",
    "im  = np.array(im,dtype= np.uint8)\n",
    "im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "\n",
    "img_pred = cv2.addWeighted(rgb_mask_pred,0.70,im,1,0)\n",
    "\n",
    "draw_img = get_BB_new_img(im)\n",
    "\n",
    "plt.figure(figsize=(14,5))\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(im)\n",
    "plt.title('Original')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(img_pred)\n",
    "plt.title('Segmentated')\n",
    "plt.axis('off')\n",
    "plt.subplot(1,3,3)\n",
    "plt.imshow(draw_img)\n",
    "plt.title('Bounding Box')\n",
    "plt.axis('off');\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing camera calibration\n",
    "Camera calibration is performed in order to correct the deformation in the images that is caused to the optic lens curvature. The first step is to print a chessboard and take random pictures of it. Then count the chess intersecting squires to provide \"objp\" which holds the (x,y,z) coordinates of these corners. Z=0 here and the object points are the same for all images in the calibration folder. The objpoints will be appended in \"objp\" every time the method successfully detect all chessboard corners in a test image. \"imgpoints\" will be appended with the (x, y) pixel position of each of the corners in the image plane with each successful chessboard detection.\n",
    "\"objpoints\" and \"imgpoints\" were used to compute the camera calibration and distortion coefficients using the \"cv2.calibrateCamera()\" function on a test image in \"cv2.undistort()\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare object points. The number of corners are 6x9\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "# Make a list of calibration images, all located in camera_cal\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    # imread reads images in BGR format\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        #Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        #write_name = 'corners_found'+str(idx)+'.jpg'\n",
    "        #cv2.imwrite(write_name, img)\n",
    "        #cv2.imshow('img', img)\n",
    "        #cv2.waitKey(500)\n",
    "#cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform distortion removal on test images¶\n",
    "1. Has the distortion correction been correctly applied to each image?\n",
    "Undistortion is performed on the provided test images before they are used in the pipeline. This also applies to the video frames. \"dst\" holds undistorted frames from \"cv2.undistort\" that were computed using \"mtx\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image_name in glob.glob(\"Frames/*\"):\n",
    "    im = cv2.imread(image_name)\n",
    "    im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "    im = undistort(im,read=False, display = False, write = False)\n",
    "    pred,im = next_img(im)\n",
    "    im  = np.array(im,dtype= np.uint8)\n",
    "    im_pred = np.array(255*pred[0],dtype=np.uint8)\n",
    "    rgb_mask_pred = cv2.cvtColor(im_pred,cv2.COLOR_GRAY2RGB)\n",
    "    rgb_mask_pred[:,:,1:3] = 0*rgb_mask_pred[:,:,1:2]\n",
    "    img_pred = cv2.addWeighted(rgb_mask_pred,0.50,im,1,0)\n",
    "    draw_img = get_BB_new_img(im)\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Original')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,2)\n",
    "    plt.imshow(img_pred)\n",
    "    plt.title('Segmentated')\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1,3,3)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.title('Bounding Box')\n",
    "    plt.axis('off');\n",
    "\n",
    "heatmap_10 = [np.zeros((640,960))]*10\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_pipeline(image):\n",
    "    #test_img = 'scene01021.jpg'\n",
    "    #im = cv2.imread(im)\n",
    "    #im = cv2.cvtColor(im,cv2.COLOR_BGR2RGB)\n",
    "    #img = get_BB_new_img(im)\n",
    "    # Apply bounding box to image\n",
    "    image_bb = np.copy(image)\n",
    "    bbox_cars = get_BB_new(image_bb)\n",
    "    img_size = np.shape(image)\n",
    "    result = image\n",
    "    img_res_shape = result.shape\n",
    "    for bbox in bbox_cars:\n",
    "        cv2.rectangle(result,(np.int32(bbox[0][0]*img_res_shape[1]/960),np.int32(bbox[0][1]*img_res_shape[0]/640)), (np.int32(bbox[1][0]*img_res_shape[1]/960),np.int32(bbox[1][1]*img_res_shape[0]/640)),(0,255,0),6)\n",
    "    #heatmap = get_Unet_mask(image_bb)\n",
    "    #plt.imshow(img)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_output = 'project_video_output.mp4'\n",
    "clip1 = VideoFileClip(\"project_video.mp4\")\n",
    "white_clip = clip1.fl_image(video_pipeline) \n",
    "white_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"360\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format('project_video_output.mp4'))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:keras2]",
   "language": "python",
   "name": "conda-env-keras2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
