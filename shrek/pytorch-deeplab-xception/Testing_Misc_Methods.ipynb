{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Misc Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader with augmentation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torch.nn as nn\n",
    "import glob\n",
    "\n",
    "label_images_path = 'data/dataset/train/labels/*.png'\n",
    "masks_images_path = 'data/dataset/train/masks'\n",
    "\n",
    "filenames = sorted(glob.glob(label_images_path))\n",
    "\n",
    "for filename in filenames:\n",
    "    print(filename)\n",
    "    img = imageio.imread(filename)\n",
    "    img = img.astype(np.uint8)\n",
    "    img = img * 255\n",
    "    \n",
    "    img = np.stack((img,img,img), axis=-1)\n",
    "    print(img.shape)\n",
    "    \n",
    "    output_name = os.path.join(masks_images_path, os.path.basename(filename))\n",
    "    imageio.imwrite(output_name, img)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torch.nn as nn\n",
    "\n",
    "from imgaug import parameters as iap\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Custom includes\n",
    "from dataloaders.alphapilot import AlphaPilotSegmentation\n",
    "from dataloaders import utils\n",
    "\n",
    "class Args():\n",
    "    input_images_path = 'data/dataset/train/images'\n",
    "    label_images_path = 'data/dataset/train/labels'\n",
    "\n",
    "args = Args()\n",
    "testBatchSize = 32\n",
    "results_store_dir = 'data/test-aug'\n",
    "imsize = 512\n",
    "\n",
    "# augs_test = iaa.Sequential([\n",
    "#     # Geometric Augs\n",
    "#     iaa.Resize((imsize, imsize), interpolation='cubic'),\n",
    "# #     iaa.Fliplr(0.5),\n",
    "# #     iaa.Flipud(0.5),\n",
    "# #     iaa.Rot90((0, 4)),\n",
    "    \n",
    "#     # Blur and Noise\n",
    "# #     iaa.Sometimes(0.15, iaa.OneOf([iaa.GaussianBlur(sigma=(1.5, 2.5), name=\"gaus-blur\"),\n",
    "# #                                    iaa.MotionBlur(k=13, angle=[0, 180, 270, 360], direction=[-1.0, 1.0],\n",
    "# #                                                  name='motion-blur'),\n",
    "# #                                   ])),\n",
    "\n",
    "#     # Color, Contrast, etc\n",
    "# #     iaa.Sometimes(0.5, iaa.CoarseDropout(0.05, size_px=(2,4), per_channel=1.0, min_size=2, name='dropout')),\n",
    "# #     iaa.SomeOf((0, None), [ iaa.Sometimes(0.5, iaa.GammaContrast((0.5, 1.5), name=\"contrast\")),    \n",
    "# #                             iaa.Sometimes(0.5, iaa.Multiply((0.40, 1.60), per_channel=1.0, name=\"brightness\")),\n",
    "# #                             iaa.Sometimes(0.5, iaa.AddToHueAndSaturation((-30, 30), name=\"hue-sat\")),\n",
    "# #                           ]),\n",
    "    \n",
    "#     # Affine\n",
    "#     iaa.Sometimes(0.99, iaa.Affine(scale={\"x\": (0.3, 0.7), \"y\": 1.0})),\n",
    "#     iaa.Sometimes(0.99, iaa.Affine(scale=(0.3, 0.7))),\n",
    "# ])\n",
    "\n",
    "augs_test = iaa.Sequential([\n",
    "        # Geometric Augs\n",
    "        iaa.Resize((imsize, imsize), 0),\n",
    "        iaa.Fliplr(0.5),\n",
    "        iaa.Flipud(0.5),\n",
    "        iaa.Rot90((0, 4)),\n",
    "\n",
    "        # Blur and Noise\n",
    "        iaa.Sometimes(0.5, iaa.OneOf([iaa.GaussianBlur(sigma=(1.5, 2.5), name=\"gaus_blur\"),\n",
    "                                    iaa.MotionBlur(k=13, angle=[0, 180, 270, 360], direction=[-1.0, 1.0],\n",
    "                                                    name='motion_blur'),\n",
    "                                    ])),\n",
    "\n",
    "        # Color, Contrast, etc\n",
    "        iaa.Sometimes(0.90, iaa.CoarseDropout(0.05, size_px=(2, 4), per_channel=0.5, min_size=2, name='dropout')),\n",
    "\n",
    "        iaa.SomeOf((0, None), [ iaa.Sometimes(0.9, iaa.GammaContrast((0.5, 1.5), name=\"contrast\")),\n",
    "                                iaa.Sometimes(0.9, iaa.Multiply((0.40, 1.60), per_channel=1.0, name=\"multiply\")),\n",
    "                                iaa.Sometimes(0.9, iaa.AddToHueAndSaturation((-30, 30), name=\"hue_sat\")),\n",
    "                            ]),\n",
    "\n",
    "        # Affine\n",
    "        iaa.Sometimes(0.5, iaa.Affine(scale={\"x\": (0.5, 0.7), \"y\": 1.0})),\n",
    "        iaa.Sometimes(0.5, iaa.Affine(scale=(0.5, 0.7))),\n",
    "        ])\n",
    "\n",
    "db_test = AlphaPilotSegmentation(\n",
    "    input_dir=args.input_images_path, label_dir=args.label_images_path,\n",
    "    transform=augs_test,\n",
    "    input_only=[\"gaus_blur\", \"motion_blur\", \"dropout\", \"contrast\", \"multiply\",  \"hue_sat\"]\n",
    ")\n",
    "testloader = DataLoader(db_test, batch_size=testBatchSize, shuffle=False, num_workers=1, drop_last=True)\n",
    "\n",
    "for ii, sample_batched in enumerate(testloader):\n",
    "    inputs, labels, sample_filename = sample_batched\n",
    "    print(sample_filename)\n",
    "    \n",
    "    labels_colormap = utils.decode_seg_map_sequence(labels.squeeze(1).numpy()).type(torch.FloatTensor)    \n",
    "    \n",
    "#     sample = torch.cat((inputs, labels_colormap), 0)\n",
    "#     img_grid = make_grid(sample, nrow=4, padding=2)\n",
    "\n",
    "    imgs_per_row = 8\n",
    "    images = []\n",
    "    for i in range (0, testBatchSize):\n",
    "        images.append(inputs[i])\n",
    "        images.append(labels_colormap[i])\n",
    "    \n",
    "    img_grid = make_grid(images, nrow=imgs_per_row, padding=2)\n",
    "    \n",
    "    save_image(img_grid, os.path.join(results_store_dir, sample_filename[0] + '-results.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference AlphaPilot Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "from random import shuffle\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from inference_alphapilot import inferenceAlphaPilot\n",
    "\n",
    "\n",
    "folder = 'data/dataset/test/images/'\n",
    "img_file = glob.glob(folder + '*.JPG')\n",
    "img_keys = [img_i.split('/')[-1] for img_i in img_file]\n",
    "\n",
    "inference = inferenceAlphaPilot(checkpoint_path = 'checkpoint/checkpoint.pth')\n",
    "\n",
    "time_all = []\n",
    "pred_dict = {}\n",
    "for img_key in img_keys:\n",
    "    img =cv2.imread(folder+img_key)\n",
    "    img =cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    tic = time.monotonic()\n",
    "\n",
    "    # Run inference\n",
    "    mask = inference.inferenceOnNumpy(img)\n",
    "    \n",
    "#     # Resize Mask\n",
    "    h, w = img.shape[:2]\n",
    "    resized_mask = cv2.resize(mask, (w, h))\n",
    "    print('resized:', resized_mask.shape)\n",
    "    \n",
    "    toc = time.monotonic()\n",
    "    pred_dict[img_key] = resized_mask\n",
    "    time_all.append(toc-tic)\n",
    "\n",
    "mean_time = np.mean(time_all)\n",
    "ci_time = 1.96*np.std(time_all)\n",
    "freq = np.round(1/mean_time,2)\n",
    "    \n",
    "print('95% confidence interval for inference time is {0:.2f} +/- {1:.4f}.'.format(mean_time,ci_time))\n",
    "print('Operating frequency from loading image to getting results is {0:.2f}.'.format(freq))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "folder = 'data/dataset/test/images/'\n",
    "img_file = glob.glob(folder + '*.JPG')\n",
    "img_keys = [img_i.split('/')[-1] for img_i in img_file]\n",
    "\n",
    "time_all = []\n",
    "pred_dict = {}\n",
    "tic1 = time.monotonic()\n",
    "for img_key in img_keys:\n",
    "    img =cv2.imread(folder+img_key)\n",
    "    img =cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    tic = time.monotonic()\n",
    "\n",
    "    h, w = img.shape[:2]\n",
    "    mask = cv2.resize(img, (512, 512))\n",
    "    print(mask.shape)\n",
    "    resized_mask = cv2.resize(mask, (w, h))\n",
    "    print(resized_mask.shape)\n",
    "    \n",
    "    toc = time.monotonic()\n",
    "    pred_dict[img_key] = resized_mask\n",
    "    time_all.append(toc-tic)\n",
    "\n",
    "mean_time = np.mean(time_all)\n",
    "ci_time = 1.96*np.std(time_all)\n",
    "freq = np.round(1/mean_time,2)\n",
    "\n",
    "toc1 = time.monotonic()\n",
    "print('Total time taken:', toc1-tic1)\n",
    "\n",
    "print('95% confidence interval for inference time is {0:.2f} +/- {1:.4f}.'.format(mean_time,ci_time))\n",
    "print('Operating frequency from loading image to getting results is {0:.2f}.'.format(freq))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
