{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Misc Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader with augmentation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('IMG_1001-rgb', 'IMG_1003-rgb', 'IMG_1004-rgb', 'IMG_1008-rgb', 'IMG_1116-rgb', 'IMG_1122-rgb', 'IMG_1123-rgb', 'IMG_1124-rgb', 'IMG_1125-rgb', 'IMG_1126-rgb', 'IMG_1127-rgb', 'IMG_1128-rgb', 'IMG_1129-rgb', 'IMG_1134-rgb', 'IMG_1140-rgb', 'IMG_1141-rgb')\n",
      "('IMG_1143-rgb', 'IMG_1145-rgb', 'IMG_1146-rgb', 'IMG_1148-rgb', 'IMG_1152-rgb', 'IMG_1154-rgb', 'IMG_1155-rgb', 'IMG_1156-rgb', 'IMG_1158-rgb', 'IMG_1159-rgb', 'IMG_1160-rgb', 'IMG_1162-rgb', 'IMG_1165-rgb', 'IMG_1169-rgb', 'IMG_1181-rgb', 'IMG_1186-rgb')\n",
      "('IMG_1187-rgb', 'IMG_1188-rgb', 'IMG_1191-rgb', 'IMG_1193-rgb', 'IMG_1196-rgb', 'IMG_1199-rgb', 'IMG_1200-rgb', 'IMG_1201-rgb', 'IMG_1203-rgb', 'IMG_1206-rgb', 'IMG_1209-rgb', 'IMG_1211-rgb', 'IMG_1212-rgb', 'IMG_1213-rgb', 'IMG_1214-rgb', 'IMG_1215-rgb')\n",
      "('IMG_1217-rgb', 'IMG_1219-rgb', 'IMG_1220-rgb', 'IMG_1221-rgb', 'IMG_1223-rgb', 'IMG_1226-rgb', 'IMG_1227-rgb', 'IMG_1231-rgb', 'IMG_1234-rgb', 'IMG_1236-rgb', 'IMG_1238-rgb', 'IMG_1239-rgb', 'IMG_1240-rgb', 'IMG_1241-rgb', 'IMG_1244-rgb', 'IMG_1246-rgb')\n",
      "('IMG_1247-rgb', 'IMG_1248-rgb', 'IMG_1253-rgb', 'IMG_1255-rgb', 'IMG_1257-rgb', 'IMG_1259-rgb', 'IMG_1260-rgb', 'IMG_1261-rgb', 'IMG_1263-rgb', 'IMG_1265-rgb', 'IMG_1269-rgb', 'IMG_1270-rgb', 'IMG_1271-rgb', 'IMG_1273-rgb', 'IMG_1274-rgb', 'IMG_1275-rgb')\n",
      "('IMG_1276-rgb', 'IMG_1277-rgb', 'IMG_1279-rgb', 'IMG_1280-rgb', 'IMG_1281-rgb', 'IMG_1282-rgb', 'IMG_1283-rgb', 'IMG_1284-rgb', 'IMG_1286-rgb', 'IMG_1288-rgb', 'IMG_1295-rgb', 'IMG_1299-rgb', 'IMG_1300-rgb', 'IMG_1306-rgb', 'IMG_1309-rgb', 'IMG_1311-rgb')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileno\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_idat' object has no attribute 'fileno'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e121cd6f14cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mimg_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimgs_per_row\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0msave_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_store_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_filename\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'-results.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/torchvision/utils.py\u001b[0m in \u001b[0;36msave_image\u001b[0;34m(tensor, filename, nrow, padding, normalize, range, scale_each, pad_value)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0mndarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyte\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m     \u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   1992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1993\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1994\u001b[0;31m             \u001b[0msave_handler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1995\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1996\u001b[0m             \u001b[0;31m# do what we can to clean up\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/PIL/PngImagePlugin.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, filename, chunk)\u001b[0m\n\u001b[1;32m    866\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m     ImageFile._save(im, _idat(fp, chunk),\n\u001b[0;32m--> 868\u001b[0;31m                     [(\"zip\", (0, 0)+im.size, 0, rawmode)])\n\u001b[0m\u001b[1;32m    869\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m     \u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"IEND\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.6/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(im, fp, tile, bufsize)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m                     \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbufsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m                     \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torch.nn as nn\n",
    "\n",
    "from imgaug import parameters as iap\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Custom includes\n",
    "from dataloaders.alphapilot import AlphaPilotSegmentation\n",
    "from dataloaders import utils\n",
    "\n",
    "class Args():\n",
    "    input_images_path = 'data/dataset/train/images'\n",
    "    label_images_path = 'data/dataset/train/labels'\n",
    "\n",
    "args = Args()\n",
    "testBatchSize = 16\n",
    "results_store_dir = 'data/test-aug'\n",
    "imsize = 512\n",
    "\n",
    "augs_test = iaa.Sequential([\n",
    "    # Geometric Augs\n",
    "    iaa.Resize((imsize, imsize), interpolation='cubic'),\n",
    "#     iaa.Fliplr(0.5),\n",
    "#     iaa.Flipud(0.5),\n",
    "#     iaa.Rot90((0, 4)),\n",
    "    \n",
    "    # Blur and Noise\n",
    "#     iaa.Sometimes(0.15, iaa.OneOf([iaa.GaussianBlur(sigma=(1.5, 2.5), name=\"gaus-blur\"),\n",
    "#                                    iaa.MotionBlur(k=13, angle=[0, 180, 270, 360], direction=[-1.0, 1.0],\n",
    "#                                                  name='motion-blur'),\n",
    "#                                   ])),\n",
    "\n",
    "    # Color, Contrast, etc\n",
    "#     iaa.Sometimes(0.5, iaa.CoarseDropout(0.05, size_px=(2,4), per_channel=1.0, min_size=2, name='dropout')),\n",
    "#     iaa.SomeOf((0, None), [ iaa.Sometimes(0.5, iaa.GammaContrast((0.5, 1.5), name=\"contrast\")),    \n",
    "#                             iaa.Sometimes(0.5, iaa.Multiply((0.40, 1.60), per_channel=1.0, name=\"brightness\")),\n",
    "#                             iaa.Sometimes(0.5, iaa.AddToHueAndSaturation((-30, 30), name=\"hue-sat\")),\n",
    "#                           ]),\n",
    "    \n",
    "    # Affine\n",
    "    iaa.Sometimes(0.99, iaa.Affine(scale={\"x\": (0.3, 0.5), \"y\": 1.0})),\n",
    "    iaa.Sometimes(0.99, iaa.Affine(scale=(0.3, 0.5))),\n",
    "])\n",
    "\n",
    "db_test = AlphaPilotSegmentation(\n",
    "    input_dir=args.input_images_path, label_dir=args.label_images_path,\n",
    "    transform=augs_test,\n",
    "    input_only=[\"gaus-blur\", \"motion-blur\", \"brightness\", \"contrast\",\n",
    "                \"hue-sat\", \"dropout\"]\n",
    ")\n",
    "testloader = DataLoader(db_test, batch_size=testBatchSize, shuffle=False, num_workers=4, drop_last=True)\n",
    "\n",
    "for ii, sample_batched in enumerate(testloader):\n",
    "    inputs, labels, sample_filename = sample_batched\n",
    "    print(sample_filename)\n",
    "    \n",
    "    labels_colormap = utils.decode_seg_map_sequence(labels.squeeze(1).numpy()).type(torch.FloatTensor)    \n",
    "    \n",
    "#     sample = torch.cat((inputs, labels_colormap), 0)\n",
    "#     img_grid = make_grid(sample, nrow=4, padding=2)\n",
    "\n",
    "    imgs_per_row = 8\n",
    "    images = []\n",
    "    for i in range (0, testBatchSize):\n",
    "        images.append(inputs[i])\n",
    "        images.append(labels_colormap[i])\n",
    "    \n",
    "    img_grid = make_grid(images, nrow=imgs_per_row, padding=2)\n",
    "    \n",
    "    save_image(img_grid, os.path.join(results_store_dir, sample_filename[0] + '-results.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference AlphaPilot Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from inference_alphapilot import inferenceAlphaPilot\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "inference = inferenceAlphaPilot(checkpoint_path = 'checkpoint/checkpoint.pth'\n",
    "                                )\n",
    "pathInputImage = 'data/dataset/test/images/IMG_0008.JPG'\n",
    "img =cv2.imread(pathInputImage)\n",
    "img =cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask = inference.inferenceOnNumpy(img)\n",
    "print('mask shape:', mask.shape, 'mask dtype:', mask.dtype,'mask max value:', np.amax(mask))\n",
    "\n",
    "plt.imshow(mask)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
