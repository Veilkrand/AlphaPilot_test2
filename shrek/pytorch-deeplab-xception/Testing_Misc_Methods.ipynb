{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Misc Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader with augmentation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid, save_image\n",
    "import torch.nn as nn\n",
    "\n",
    "from imgaug import parameters as iap\n",
    "from imgaug import augmenters as iaa\n",
    "import imgaug as ia\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Custom includes\n",
    "from dataloaders.alphapilot import AlphaPilotSegmentation\n",
    "from dataloaders import utils\n",
    "\n",
    "class Args():\n",
    "    input_images_path = 'data/dataset/train/images'\n",
    "    label_images_path = 'data/dataset/train/labels'\n",
    "\n",
    "args = Args()\n",
    "testBatchSize = 16\n",
    "results_store_dir = 'data/test-aug'\n",
    "imsize = 512\n",
    "\n",
    "augs_test = iaa.Sequential([\n",
    "    # Geometric Augs\n",
    "    iaa.Resize((imsize, imsize), interpolation='cubic'),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Flipud(0.5),\n",
    "    iaa.Rot90((0, 4)),\n",
    "    \n",
    "    # Blur and Noise\n",
    "    iaa.Sometimes(0.15, iaa.OneOf([iaa.GaussianBlur(sigma=(1.5, 2.5), name=\"gaus-blur\"),\n",
    "                                   iaa.MotionBlur(k=13, angle=[0, 180, 270, 360], direction=[-1.0, 1.0],\n",
    "                                                 name='motion-blur'),\n",
    "                                  ])),\n",
    "\n",
    "    # Color, Contrast, etc\n",
    "    iaa.Sometimes(0.5, iaa.CoarseDropout(0.05, size_px=(2,4), per_channel=1.0, min_size=2, name='dropout')),\n",
    "    iaa.SomeOf((0, None), [ iaa.Sometimes(0.5, iaa.GammaContrast((0.5, 1.5), name=\"contrast\")),    \n",
    "                            iaa.Sometimes(0.5, iaa.Multiply((0.40, 1.60), per_channel=1.0, name=\"brightness\")),\n",
    "                            iaa.Sometimes(0.5, iaa.AddToHueAndSaturation((-30, 30), name=\"hue-sat\")),\n",
    "                          ]),\n",
    "])\n",
    "\n",
    "db_test = AlphaPilotSegmentation(\n",
    "    input_dir=args.input_images_path, label_dir=args.label_images_path,\n",
    "    transform=augs_test,\n",
    "    input_only=[\"gaus-blur\", \"motion-blur\", \"brightness\", \"contrast\",\n",
    "                \"hue-sat\", \"dropout\"]\n",
    ")\n",
    "testloader = DataLoader(db_test, batch_size=testBatchSize, shuffle=False, num_workers=4, drop_last=True)\n",
    "\n",
    "for ii, sample_batched in enumerate(testloader):\n",
    "    inputs, labels, sample_filename = sample_batched\n",
    "    print(sample_filename)\n",
    "    \n",
    "    labels_colormap = utils.decode_seg_map_sequence(labels.squeeze(1).numpy()).type(torch.FloatTensor)    \n",
    "    \n",
    "#     sample = torch.cat((inputs, labels_colormap), 0)\n",
    "#     img_grid = make_grid(sample, nrow=4, padding=2)\n",
    "\n",
    "    imgs_per_row = 8\n",
    "    images = []\n",
    "    for i in range (0, testBatchSize):\n",
    "        images.append(inputs[i])\n",
    "        images.append(labels_colormap[i])\n",
    "    \n",
    "    img_grid = make_grid(images, nrow=imgs_per_row, padding=2)\n",
    "    \n",
    "    save_image(img_grid, os.path.join(results_store_dir, sample_filename[0] + '-results.png'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference AlphaPilot Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from inference_alphapilot import inferenceAlphaPilot\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "inference = inferenceAlphaPilot(checkpoint_path = 'checkpoint/checkpoint.pth'\n",
    "                                )\n",
    "pathInputImage = 'data/dataset/test/images/IMG_0008.JPG'\n",
    "img =cv2.imread(pathInputImage)\n",
    "img =cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "mask = inference.inferenceOnNumpy(img)\n",
    "print('mask shape:', mask.shape, 'mask dtype:', mask.dtype,'mask max value:', np.amax(mask))\n",
    "\n",
    "plt.imshow(mask)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
